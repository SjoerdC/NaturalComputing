{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def q_error(centroids, cluster, data):\n",
    "    error = 0.0\n",
    "    for i, c in enumerate(centroids):\n",
    "        idx = np.where(np.asarray(cluster) == i)\n",
    "        dist = np.linalg.norm(data[idx] - c)\n",
    "        dist = dist/len(idx)\n",
    "        error = error + dist\n",
    "    error = error/len(centroids)\n",
    "    return error\n",
    "\n",
    "def get_velocity(gbest, w, c1, c2, velocity, position, centroids):\n",
    "    inertia = w * velocity\n",
    "    personal = c1 * random.uniform(0,1) * (position - centroids)\n",
    "    social = c2 * random.uniform(0,1) * (gbest - centroids)\n",
    "    velocity = inertia + personal + social\n",
    "    return velocity\n",
    "\n",
    "def calculate_m(n, cluster, datapoints):\n",
    "    mj = []\n",
    "    for i in range(n):\n",
    "        idx = np.where(np.asarray(cluster) == i)\n",
    "        data = datapoints[idx]\n",
    "        mj.append(np.mean(data, axis=0))\n",
    "    return mj\n",
    "\n",
    "def pso(datapoints, n, text, w=0.72, particles=10, iterations=30, c1=1.49, c2=1.49):\n",
    "    index = np.random.choice(list(range(len(datapoints))), n)\n",
    "    centroids = datapoints[index]     \n",
    "    cluster = [0] * len(datapoints)\n",
    "    best_score = [99999] * particles\n",
    "    gbest_pos = centroids\n",
    "    gbest_error = 99999\n",
    "\n",
    "    # Create swarm (Step 1 in paper)\n",
    "    swarm_centroids = []\n",
    "    swarm_velocities = []\n",
    "    for i in range(particles):\n",
    "        index = np.random.choice(list(range(len(datapoints))), n)\n",
    "        centroids = datapoints[index]                           # Randomly select centroids\n",
    "        swarm_centroids.append(centroids)                       # Append centoids to swarm\n",
    "        swarm_velocities.append(np.zeros_like(centroids))       # Append velocities of same shape to swarm\n",
    "    best_pos = swarm_centroids\n",
    "\n",
    "    # Loop and update (Step 2 in paper)\n",
    "    for t in range(iterations):\n",
    "        for particle in range(particles):\n",
    "            for j in range(datapoints.shape[0]):\n",
    "                dist = np.linalg.norm((datapoints[j]-swarm_centroids[particle]), axis=1)\n",
    "                cluster[j] = np.argmin(dist)\n",
    "\n",
    "            velocity = get_velocity(np.asarray(gbest_pos), w, c1, c2, np.asarray(swarm_velocities[particle]), np.asarray(best_pos[particle]), np.asarray(swarm_centroids[particle]))\n",
    "            swarm_centroids[particle] = swarm_centroids[particle] + velocity\n",
    "            \n",
    "            mj = calculate_m(n, cluster, datapoints)\n",
    "            err = q_error(mj, cluster, datapoints)\n",
    "\n",
    "            # Update local best position and score\n",
    "            if err < best_score[particle]:\n",
    "                best_score[particle] = err\n",
    "                swarm_centroids[particle] = mj\n",
    "\n",
    "            # Update global best bosition and score\n",
    "            if err < gbest_error:\n",
    "                gbest_error = err\n",
    "                gbest_pos = mj\n",
    "    print(\"(PSO, \" + text + \") Error: \", q_error(mj, cluster, datapoints))          \n",
    "    return 0\n",
    "\n",
    "def kmeans(datapoints, k):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=30, random_state=0)\n",
    "    predictions = kmeans.fit_predict(datapoints)\n",
    "    return predictions, kmeans\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(kMeans, Iris) Error:  5.02982569656552\n",
      "(kMeans, Artificial) Error:  9.245853449777584\n",
      "(PSO, Iris) Error:  5.02982569656552\n",
      "(PSO, Artificial) Error:  8.982198757277216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Create the artificial dataset\n",
    "get_y_value = lambda x: 1 if ((x[0]>=0.7) or (x[0]<=0.3 and x[1]>= -0.2-x[0])) else 0\n",
    "X_artificial = np.random.uniform(-1,1,(400,2))\n",
    "y_artificial = np.apply_along_axis(get_y_value, 1, X_artificial)\n",
    "\n",
    "# kMeans\n",
    "y_kmeans, kmeans_iris = kmeans(X_iris, k=3)\n",
    "print(\"(kMeans, Iris) Error: \" , q_error(kmeans_iris.cluster_centers_, y_kmeans, X_iris))\n",
    "y_kmeans, kmeans_art = kmeans(X_artificial, k=2)\n",
    "print(\"(kMeans, Artificial) Error: \" , q_error(kmeans_art.cluster_centers_, y_kmeans, X_artificial))\n",
    "\n",
    "# PSO \n",
    "pso(X_iris, 3, \"Iris\")\n",
    "pso(X_artificial, 2, \"Artificial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Visualising the clusters\n",
    "# plt.scatter(X_iris[y_kmeans == 0, 0], X_iris[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Iris-setosa')\n",
    "# plt.scatter(X_iris[y_kmeans == 1, 0], X_iris[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Iris-versicolour')\n",
    "# plt.scatter(X_iris[y_kmeans == 2, 0], X_iris[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Iris-virginica')\n",
    "\n",
    "# #Plotting the centroids of the clusters\n",
    "# plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# # Apply kmeans\n",
    "# predictions = KMeans(n_clusters=3, random_state=0).fit_predict(X)\n",
    "# print(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
