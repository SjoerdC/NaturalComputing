{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----\n",
    "Splitting the snd-unm test data into normal test data and anomaly test data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = open(\"snd-unm/normal.txt\",'a')\n",
    "anomaly = open(\"snd-unm/anomaly.txt\",'a')\n",
    "\n",
    "for i in range(3):\n",
    "    unm = open(\"snd-unm/snd-unm.{}.test\".format(i+1),'r')\n",
    "    unm_labels = open(\"snd-unm/snd-unm.{}.labels\".format(i+1),'r')\n",
    "    for line in unm:\n",
    "        label = unm_labels.readline()\n",
    "        if int(label) == 0:\n",
    "            normal.write(line)\n",
    "        else:\n",
    "            anomaly.write(line)\n",
    "    unm.close()\n",
    "    unm_labels.close()\n",
    "    \n",
    "normal.close()\n",
    "anomaly.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding shortest string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of shortest string: 7\n"
     ]
    }
   ],
   "source": [
    "normal = open(\"snd-unm/normal.txt\",'r')\n",
    "anomaly = open(\"snd-unm/anomaly.txt\",'r')\n",
    "train = open(\"snd-unm/snd-unm.train\",\"r\")\n",
    "\n",
    "min_training = min(train.read().splitlines(), key = len)\n",
    "min_normal = min(normal.read().splitlines(), key = len)\n",
    "min_anomaly = min(anomaly.read().splitlines(), key = len)\n",
    "min_overall = min(min_training,min_normal,min_anomaly, key = len)\n",
    "\n",
    "min_length = len(min_overall)\n",
    "print(\"Length of shortest string:\", min_length)\n",
    "\n",
    "train.close()\n",
    "normal.close()\n",
    "anomaly.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Creating chunks of fixed length from file\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(input_file,output_file,chunk_size, chunklist):\n",
    "    input_file = open(input_file,'r')\n",
    "    output_file = open(output_file,'a')\n",
    "    for line in input_file:\n",
    "        size = len(line)-1 # -1 because of \\n\n",
    "        start = 0\n",
    "        substrings = []\n",
    "        number_of_chunks = 0 # for merging the counts later\n",
    "        while size >= chunk_size:\n",
    "            chunk = line[start:start+chunk_size]\n",
    "            if chunk not in substrings:\n",
    "                output_file.write(chunk+\"\\n\")\n",
    "                substrings.append(chunk)\n",
    "                number_of_chunks += 1\n",
    "            start += chunk_size\n",
    "            size -= chunk_size\n",
    "        chunklist.append(number_of_chunks)\n",
    "    input_file.close()\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"snd-unm/snd-unm.train\"\n",
    "normal = \"snd-unm/normal.txt\"\n",
    "anomaly = \"snd-unm/anomaly.txt\"\n",
    "\n",
    "fixed_train = \"snd-unm/fixed_train.txt\"\n",
    "fixed_normal = \"snd-unm/fixed_normal.txt\"\n",
    "fixed_anomaly = \"snd-unm/fixed_anomaly.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chunks = []\n",
    "normal_chunks = []\n",
    "anomaly_chunks = []\n",
    "\n",
    "split_into_chunks(train,fixed_train,min_length,train_chunks)\n",
    "split_into_chunks(normal,fixed_normal,min_length,normal_chunks)\n",
    "split_into_chunks(anomaly,fixed_anomaly, min_length,anomaly_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the repertoire and testing against normal and anomalous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "working_dir = r'' # the absolute path to the negative_selection folder between the quotes should be added\n",
    "encoding = 'utf-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing normal calls and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bashCommand = '''java -jar negsel2.jar -alphabet syscalls/snd-unm/snd-unm.alpha \n",
    "                -self syscalls/snd-unm/fixed_train.txt -n 7 -r 5 -c -l \n",
    "                < syscalls/snd-unm/fixed_normal.txt'''\n",
    "\n",
    "\n",
    "process = subprocess.check_output(bashCommand.split(), shell = True, cwd = working_dir)\n",
    "normalOutput = process.decode(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing anomalous calls and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bashCommand = '''java -jar negsel2.jar -alphabet syscalls/snd-unm/snd-unm.alpha \n",
    "                -self syscalls/snd-unm/fixed_train.txt -n 7 -r 5 -c -l\n",
    "                < syscalls/snd-unm/fixed_anomaly.txt'''\n",
    "\n",
    "process = subprocess.check_output(bashCommand.split(), shell = True, cwd = working_dir)\n",
    "anomalyOutput = process.decode(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting results for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "anomaly_preds = np.array(anomalyOutput.splitlines(), dtype = np.float64)\n",
    "normal_preds = np.array(normalOutput.splitlines(), dtype = np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing final scores by merging counts and averaging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores = []\n",
    "normal_scores = []\n",
    "\n",
    "for i in range(np.size(anomaly_chunks)):\n",
    "    start = int(np.sum(anomaly_chunks[:i]))\n",
    "    finish = int(start + anomaly_chunks[i])\n",
    "    pred_mean = np.mean(anomaly_preds[start:finish])\n",
    "    anomaly_scores.append(pred_mean)\n",
    "\n",
    "for i in range(np.size(normal_chunks)):\n",
    "    start = int(np.sum(normal_chunks[:i]))\n",
    "    finish = int(start + normal_chunks[i])\n",
    "    pred_mean = np.mean(normal_preds[start:finish])\n",
    "    normal_scores.append(pred_mean) \n",
    "    \n",
    "scores = normal_scores + anomaly_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalLabels = np.zeros((len(normal_scores),), dtype = np.int8)\n",
    "anomalyLabels = np.ones((len(anomaly_scores),), dtype = np.int8)\n",
    "targets = np.concatenate((normalLabels,anomalyLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score: 0.8936107526881719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"The AUC score:\",roc_auc_score(targets,scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Doing the same process for the snd-cert files\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = open(\"snd-cert/normal.txt\",'a')\n",
    "anomaly = open(\"snd-cert/anomaly.txt\",'a')\n",
    "\n",
    "for i in range(3):\n",
    "    cert = open(\"snd-cert/snd-cert.{}.test\".format(i+1),'r')\n",
    "    cert_labels = open(\"snd-cert/snd-cert.{}.labels\".format(i+1),'r')\n",
    "    for line in cert:\n",
    "        label = cert_labels.readline()\n",
    "        if int(label) == 0:\n",
    "            normal.write(line)\n",
    "        else:\n",
    "            anomaly.write(line)\n",
    "    cert.close()\n",
    "    cert_labels.close()\n",
    "    \n",
    "normal.close()\n",
    "anomaly.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the shortest string: 7\n"
     ]
    }
   ],
   "source": [
    "train = open(\"snd-cert/snd-cert.train\",\"r\")\n",
    "normal = open(\"snd-cert/normal.txt\",'r')\n",
    "anomaly = open(\"snd-cert/anomaly.txt\",'r')\n",
    "\n",
    "\n",
    "min_training = min(train.read().splitlines(), key = len)\n",
    "min_normal = min(normal.read().splitlines(), key = len)\n",
    "min_anomaly = min(anomaly.read().splitlines(), key = len)\n",
    "min_overall = min(min_training,min_normal,min_anomaly, key = len)\n",
    "\n",
    "min_length = len(min_overall)\n",
    "print(\"Length of the shortest string:\", min_length)\n",
    "\n",
    "train.close()\n",
    "normal.close()\n",
    "anomaly.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"snd-cert/snd-cert.train\"\n",
    "normal = \"snd-cert/normal.txt\"\n",
    "anomaly = \"snd-cert/anomaly.txt\"\n",
    "\n",
    "fixed_train = \"snd-cert/fixed_train.txt\"\n",
    "fixed_normal = \"snd-cert/fixed_normal.txt\"\n",
    "fixed_anomaly = \"snd-cert/fixed_anomaly.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chunks = []\n",
    "normal_chunks = []\n",
    "anomaly_chunks = []\n",
    "\n",
    "split_into_chunks(train,fixed_train,min_length,train_chunks)\n",
    "split_into_chunks(normal,fixed_normal,min_length,normal_chunks)\n",
    "split_into_chunks(anomaly,fixed_anomaly, min_length,anomaly_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bashCommand = '''java -jar negsel2.jar -alphabet syscalls/snd-cert/snd-cert.alpha \n",
    "                -self syscalls/snd-cert/fixed_train.txt -n 7 -r 5 -c -l \n",
    "                < syscalls/snd-cert/fixed_normal.txt'''\n",
    "\n",
    "process = subprocess.check_output(bashCommand.split(), shell = True, cwd = working_dir)\n",
    "normalOutput = process.decode(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bashCommand = '''java -jar negsel2.jar -alphabet syscalls/snd-cert/snd-cert.alpha \n",
    "                -self syscalls/snd-cert/fixed_train.txt -n 7 -r 5 -c -l\n",
    "                < syscalls/snd-cert/fixed_anomaly.txt'''\n",
    "\n",
    "process = subprocess.check_output(bashCommand.split(), shell = True, cwd = working_dir)\n",
    "anomalyOutput = process.decode(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_preds = np.array(anomalyOutput.splitlines(), dtype = np.float64)\n",
    "normal_preds = np.array(normalOutput.splitlines(), dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores = []\n",
    "normal_scores = []\n",
    "\n",
    "for i in range(np.size(anomaly_chunks)):\n",
    "    start = int(np.sum(anomaly_chunks[:i]))\n",
    "    finish = int(start + anomaly_chunks[i])\n",
    "    pred_mean = np.mean(anomaly_preds[start:finish])\n",
    "    anomaly_scores.append(pred_mean)\n",
    "\n",
    "for i in range(np.size(normal_chunks)):\n",
    "    start = int(np.sum(normal_chunks[:i]))\n",
    "    finish = int(start + normal_chunks[i])\n",
    "    pred_mean = np.mean(normal_preds[start:finish])\n",
    "    normal_scores.append(pred_mean) \n",
    "    \n",
    "scores = normal_scores + anomaly_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalLabels = np.zeros((len(normal_scores),), dtype = np.int8)\n",
    "anomalyLabels = np.ones((len(anomaly_scores),), dtype = np.int8)\n",
    "targets = np.concatenate((normalLabels,anomalyLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score: 0.8210537634408602\n"
     ]
    }
   ],
   "source": [
    "print(\"The AUC score:\",roc_auc_score(targets,scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
