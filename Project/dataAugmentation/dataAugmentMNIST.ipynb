{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dataAugmentMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import count\n",
        "from scipy import ndimage\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 9999\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"MNIST_augment\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9M4_-IaBOsn",
        "colab_type": "text"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n9nJGd_BQ-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8QvEt97vF52",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtJIUBsFKeRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "ed824563-b0f8-480d-b65b-c3aabf58c019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SYRuKZaIwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLQOYIh0OW84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIBGIrlkvOt0",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbiuqESLvTOY",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFkx19XmqKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(models, X, Y):\n",
        "    predictions = []\n",
        "\n",
        "    for m in tqdm(models):\n",
        "        predictions.append(np.argmax(m.predict(X), axis=1))\n",
        "\n",
        "    prediction = np.transpose(predictions)\n",
        "    prediction = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=prediction)\n",
        "\n",
        "    return accuracy_score(prediction, np.argmax(Y, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnusOrCMhvQE",
        "colab_type": "text"
      },
      "source": [
        "# Data augmentation functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SWzBrFkgsAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flip_image(image):\n",
        "    if np.random.rand() < 0.2:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gBhejyuh0qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate_image(image):\n",
        "    if np.random.rand() < 0.2:\n",
        "        angles = np.linspace(1,10,10)\n",
        "        rotation_angle = np.random.choice(angles)\n",
        "        if np.random.rand() < 0.5:\n",
        "            image = ndimage.rotate(image, rotation_angle, reshape = False)\n",
        "        else:\n",
        "            image = ndimage.rotate(image, -rotation_angle, reshape = False) \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-tkwzLAi6rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def horizontal_shift(image):\n",
        "    if np.random.rand() < 0.2:\n",
        "        num_rows, num_cols = image.shape[:2]\n",
        "        if np.random.rand() < 0.5:\n",
        "            translation_matrix = np.float32([ [1,0,3], [0,1,0] ])\n",
        "            image = cv2.warpAffine(image, translation_matrix, (num_cols, num_rows))\n",
        "            image = image.reshape((IMAGE_SIZE,IMAGE_SIZE,1))\n",
        "        else:\n",
        "            translation_matrix = np.float32([ [1,0,-3], [0,1,0] ])\n",
        "            image = cv2.warpAffine(image, translation_matrix, (num_cols, num_rows))\n",
        "            image = image.reshape((IMAGE_SIZE,IMAGE_SIZE,1))\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNk5MJD9_dV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vertical_shift(image):\n",
        "    if np.random.rand() < 0.2:\n",
        "        num_rows, num_cols = image.shape[:2]\n",
        "        if np.random.rand() < 0.5:\n",
        "            translation_matrix = np.float32([ [1,0,0], [0,1,2] ])\n",
        "            image = cv2.warpAffine(image, translation_matrix, (num_cols, num_rows))\n",
        "            image = image.reshape((IMAGE_SIZE,IMAGE_SIZE,1))\n",
        "        else:\n",
        "            translation_matrix = np.float32([ [1,0,0], [0,1,-2] ])\n",
        "            image = cv2.warpAffine(image, translation_matrix, (num_cols, num_rows))\n",
        "            image = image.reshape((IMAGE_SIZE,IMAGE_SIZE,1))\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkGlwKLGxJi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "funcs = [rotate_image,\n",
        "         horizontal_shift, \n",
        "         vertical_shift]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVqdcrD_vQ-Q",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "249d4b06-8330-44c1-a314-2531fbfc0ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = [0]\n",
        "\n",
        "for i in range(len(funcs)):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "\n",
        "    preprocessing_function = funcs[i]\n",
        "    datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
        "    datagen = datagen.flow(x_train,y_train, batch_size = BATCH_SIZE)\n",
        "\n",
        "    model = FashionMNISTmodel(IMAGE_SIZE, NUM_CLASSES, 1)\n",
        "\n",
        "    es = EarlyStopping(min_delta = 0.01, patience=3)\n",
        "    model.fit_generator(datagen,\n",
        "                        epochs = EPOCHS,\n",
        "                        validation_data = (x_test,y_test),\n",
        "                        shuffle = True,\n",
        "                        callbacks=[es])\n",
        "    \n",
        "    model.save_weights(PATH + MODEL_NAME + f\"_weights-{i}.h5\" )\n",
        "    models.append(model)\n",
        "\n",
        "    acc = predict(models, x_val, y_val)\n",
        "    delta = acc - accuracies[-1]\n",
        "\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 0\n",
            "Epoch 1/9999\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 2.2553 - accuracy: 0.1421 - val_loss: 2.2529 - val_accuracy: 0.2697\n",
            "Epoch 2/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 2.0980 - accuracy: 0.3293 - val_loss: 2.0270 - val_accuracy: 0.3573\n",
            "Epoch 3/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.9488 - accuracy: 0.3727 - val_loss: 1.8662 - val_accuracy: 0.4096\n",
            "Epoch 4/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.8234 - accuracy: 0.4013 - val_loss: 1.7494 - val_accuracy: 0.4436\n",
            "Epoch 5/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.7269 - accuracy: 0.4227 - val_loss: 1.6620 - val_accuracy: 0.4651\n",
            "Epoch 6/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.6520 - accuracy: 0.4472 - val_loss: 1.5902 - val_accuracy: 0.4674\n",
            "Epoch 7/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.5912 - accuracy: 0.4684 - val_loss: 1.5336 - val_accuracy: 0.4993\n",
            "Epoch 8/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.5432 - accuracy: 0.4819 - val_loss: 1.4895 - val_accuracy: 0.5177\n",
            "Epoch 9/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.5041 - accuracy: 0.4956 - val_loss: 1.4505 - val_accuracy: 0.5302\n",
            "Epoch 10/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.4698 - accuracy: 0.5049 - val_loss: 1.4153 - val_accuracy: 0.5370\n",
            "Epoch 11/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.4382 - accuracy: 0.5155 - val_loss: 1.3849 - val_accuracy: 0.5443\n",
            "Epoch 12/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.4096 - accuracy: 0.5260 - val_loss: 1.3561 - val_accuracy: 0.5565\n",
            "Epoch 13/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.3835 - accuracy: 0.5390 - val_loss: 1.3276 - val_accuracy: 0.5647\n",
            "Epoch 14/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.3579 - accuracy: 0.5458 - val_loss: 1.3024 - val_accuracy: 0.5738\n",
            "Epoch 15/9999\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 1.3349 - accuracy: 0.5569 - val_loss: 1.2786 - val_accuracy: 0.5852\n",
            "Epoch 16/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.3146 - accuracy: 0.5645 - val_loss: 1.2614 - val_accuracy: 0.5798\n",
            "Epoch 17/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.2927 - accuracy: 0.5700 - val_loss: 1.2374 - val_accuracy: 0.5923\n",
            "Epoch 18/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.2736 - accuracy: 0.5756 - val_loss: 1.2171 - val_accuracy: 0.5991\n",
            "Epoch 19/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.2556 - accuracy: 0.5824 - val_loss: 1.1985 - val_accuracy: 0.6096\n",
            "Epoch 20/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.2388 - accuracy: 0.5870 - val_loss: 1.1797 - val_accuracy: 0.6081\n",
            "Epoch 21/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.2213 - accuracy: 0.5934 - val_loss: 1.1646 - val_accuracy: 0.6121\n",
            "Epoch 22/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.2061 - accuracy: 0.5986 - val_loss: 1.1464 - val_accuracy: 0.6203\n",
            "Epoch 23/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.1925 - accuracy: 0.6054 - val_loss: 1.1309 - val_accuracy: 0.6296\n",
            "Epoch 24/9999\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 1.1777 - accuracy: 0.6093 - val_loss: 1.1169 - val_accuracy: 0.6349\n",
            "Epoch 25/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.1661 - accuracy: 0.6128 - val_loss: 1.1041 - val_accuracy: 0.6353\n",
            "Epoch 26/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.1502 - accuracy: 0.6206 - val_loss: 1.0893 - val_accuracy: 0.6435\n",
            "Epoch 27/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.1385 - accuracy: 0.6244 - val_loss: 1.0764 - val_accuracy: 0.6458\n",
            "Epoch 28/9999\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 1.1271 - accuracy: 0.6288 - val_loss: 1.0657 - val_accuracy: 0.6501\n",
            "Epoch 29/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.1148 - accuracy: 0.6309 - val_loss: 1.0541 - val_accuracy: 0.6600\n",
            "Epoch 30/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.1056 - accuracy: 0.6371 - val_loss: 1.0423 - val_accuracy: 0.6651\n",
            "Epoch 31/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0944 - accuracy: 0.6401 - val_loss: 1.0345 - val_accuracy: 0.6631\n",
            "Epoch 32/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0846 - accuracy: 0.6441 - val_loss: 1.0211 - val_accuracy: 0.6715\n",
            "Epoch 33/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0728 - accuracy: 0.6507 - val_loss: 1.0096 - val_accuracy: 0.6756\n",
            "Epoch 34/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0617 - accuracy: 0.6542 - val_loss: 1.0008 - val_accuracy: 0.6773\n",
            "Epoch 35/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0552 - accuracy: 0.6563 - val_loss: 0.9903 - val_accuracy: 0.6863\n",
            "Epoch 36/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0436 - accuracy: 0.6622 - val_loss: 0.9807 - val_accuracy: 0.6859\n",
            "Epoch 37/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0355 - accuracy: 0.6630 - val_loss: 0.9715 - val_accuracy: 0.6941\n",
            "Epoch 38/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0255 - accuracy: 0.6701 - val_loss: 0.9655 - val_accuracy: 0.6951\n",
            "Epoch 39/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0165 - accuracy: 0.6724 - val_loss: 0.9528 - val_accuracy: 0.6972\n",
            "Epoch 40/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 1.0068 - accuracy: 0.6776 - val_loss: 0.9446 - val_accuracy: 0.7033\n",
            "Epoch 41/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9985 - accuracy: 0.6794 - val_loss: 0.9360 - val_accuracy: 0.7054\n",
            "Epoch 42/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9900 - accuracy: 0.6820 - val_loss: 0.9265 - val_accuracy: 0.7102\n",
            "Epoch 43/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9817 - accuracy: 0.6852 - val_loss: 0.9199 - val_accuracy: 0.7128\n",
            "Epoch 44/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9721 - accuracy: 0.6888 - val_loss: 0.9098 - val_accuracy: 0.7186\n",
            "Epoch 45/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9672 - accuracy: 0.6900 - val_loss: 0.9035 - val_accuracy: 0.7168\n",
            "Epoch 46/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9574 - accuracy: 0.6955 - val_loss: 0.8968 - val_accuracy: 0.7157\n",
            "Epoch 47/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9517 - accuracy: 0.6978 - val_loss: 0.8878 - val_accuracy: 0.7263\n",
            "Epoch 48/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9435 - accuracy: 0.7005 - val_loss: 0.8817 - val_accuracy: 0.7225\n",
            "Epoch 49/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9380 - accuracy: 0.7003 - val_loss: 0.8756 - val_accuracy: 0.7233\n",
            "Epoch 50/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9308 - accuracy: 0.7055 - val_loss: 0.8714 - val_accuracy: 0.7238\n",
            "Epoch 51/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9255 - accuracy: 0.7047 - val_loss: 0.8625 - val_accuracy: 0.7295\n",
            "Epoch 52/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9167 - accuracy: 0.7094 - val_loss: 0.8554 - val_accuracy: 0.7299\n",
            "Epoch 53/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9134 - accuracy: 0.7098 - val_loss: 0.8486 - val_accuracy: 0.7329\n",
            "Epoch 54/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.9038 - accuracy: 0.7138 - val_loss: 0.8427 - val_accuracy: 0.7335\n",
            "Epoch 55/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.8987 - accuracy: 0.7155 - val_loss: 0.8405 - val_accuracy: 0.7377\n",
            "Epoch 56/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.8927 - accuracy: 0.7176 - val_loss: 0.8334 - val_accuracy: 0.7374\n",
            "Epoch 57/9999\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.8895 - accuracy: 0.7183 - val_loss: 0.8328 - val_accuracy: 0.7327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 0 added. Resulting score: 0.721\n",
            "Train model 1\n",
            "Epoch 1/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.2548 - accuracy: 0.1556 - val_loss: 2.2652 - val_accuracy: 0.2379\n",
            "Epoch 2/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 2.1354 - accuracy: 0.3148 - val_loss: 2.0791 - val_accuracy: 0.3405\n",
            "Epoch 3/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.9996 - accuracy: 0.3577 - val_loss: 1.9201 - val_accuracy: 0.3598\n",
            "Epoch 4/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.8656 - accuracy: 0.3929 - val_loss: 1.7913 - val_accuracy: 0.4136\n",
            "Epoch 5/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.7545 - accuracy: 0.4283 - val_loss: 1.6912 - val_accuracy: 0.4411\n",
            "Epoch 6/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.6677 - accuracy: 0.4512 - val_loss: 1.6121 - val_accuracy: 0.4742\n",
            "Epoch 7/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.5998 - accuracy: 0.4711 - val_loss: 1.5512 - val_accuracy: 0.4714\n",
            "Epoch 8/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.5443 - accuracy: 0.4829 - val_loss: 1.4960 - val_accuracy: 0.5044\n",
            "Epoch 9/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4983 - accuracy: 0.4937 - val_loss: 1.4537 - val_accuracy: 0.5099\n",
            "Epoch 10/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4609 - accuracy: 0.5036 - val_loss: 1.4162 - val_accuracy: 0.5242\n",
            "Epoch 11/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4282 - accuracy: 0.5141 - val_loss: 1.3842 - val_accuracy: 0.5342\n",
            "Epoch 12/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4003 - accuracy: 0.5195 - val_loss: 1.3569 - val_accuracy: 0.5395\n",
            "Epoch 13/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.3744 - accuracy: 0.5283 - val_loss: 1.3323 - val_accuracy: 0.5453\n",
            "Epoch 14/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.3499 - accuracy: 0.5363 - val_loss: 1.3074 - val_accuracy: 0.5595\n",
            "Epoch 15/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.3301 - accuracy: 0.5422 - val_loss: 1.2856 - val_accuracy: 0.5607\n",
            "Epoch 16/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.3097 - accuracy: 0.5490 - val_loss: 1.2666 - val_accuracy: 0.5664\n",
            "Epoch 17/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.2931 - accuracy: 0.5539 - val_loss: 1.2501 - val_accuracy: 0.5656\n",
            "Epoch 18/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.2752 - accuracy: 0.5597 - val_loss: 1.2309 - val_accuracy: 0.5755\n",
            "Epoch 19/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.2594 - accuracy: 0.5666 - val_loss: 1.2141 - val_accuracy: 0.5803\n",
            "Epoch 20/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.2441 - accuracy: 0.5695 - val_loss: 1.1993 - val_accuracy: 0.5877\n",
            "Epoch 21/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.2297 - accuracy: 0.5776 - val_loss: 1.1856 - val_accuracy: 0.5882\n",
            "Epoch 22/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.2158 - accuracy: 0.5798 - val_loss: 1.1700 - val_accuracy: 0.5994\n",
            "Epoch 23/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.2032 - accuracy: 0.5849 - val_loss: 1.1582 - val_accuracy: 0.6077\n",
            "Epoch 24/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1908 - accuracy: 0.5899 - val_loss: 1.1441 - val_accuracy: 0.6042\n",
            "Epoch 25/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1784 - accuracy: 0.5955 - val_loss: 1.1352 - val_accuracy: 0.6109\n",
            "Epoch 26/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1668 - accuracy: 0.6014 - val_loss: 1.1206 - val_accuracy: 0.6182\n",
            "Epoch 27/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1553 - accuracy: 0.6050 - val_loss: 1.1096 - val_accuracy: 0.6216\n",
            "Epoch 28/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1442 - accuracy: 0.6080 - val_loss: 1.0986 - val_accuracy: 0.6276\n",
            "Epoch 29/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1355 - accuracy: 0.6100 - val_loss: 1.0873 - val_accuracy: 0.6321\n",
            "Epoch 30/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1254 - accuracy: 0.6160 - val_loss: 1.0762 - val_accuracy: 0.6418\n",
            "Epoch 31/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1150 - accuracy: 0.6185 - val_loss: 1.0669 - val_accuracy: 0.6416\n",
            "Epoch 32/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1046 - accuracy: 0.6259 - val_loss: 1.0581 - val_accuracy: 0.6429\n",
            "Epoch 33/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0962 - accuracy: 0.6266 - val_loss: 1.0481 - val_accuracy: 0.6484\n",
            "Epoch 34/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.0866 - accuracy: 0.6327 - val_loss: 1.0452 - val_accuracy: 0.6506\n",
            "Epoch 35/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0787 - accuracy: 0.6339 - val_loss: 1.0295 - val_accuracy: 0.6592\n",
            "Epoch 36/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0708 - accuracy: 0.6393 - val_loss: 1.0211 - val_accuracy: 0.6601\n",
            "Epoch 37/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0620 - accuracy: 0.6415 - val_loss: 1.0141 - val_accuracy: 0.6624\n",
            "Epoch 38/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.0550 - accuracy: 0.6446 - val_loss: 1.0066 - val_accuracy: 0.6649\n",
            "Epoch 39/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0459 - accuracy: 0.6461 - val_loss: 0.9983 - val_accuracy: 0.6705\n",
            "Epoch 40/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0376 - accuracy: 0.6519 - val_loss: 0.9903 - val_accuracy: 0.6745\n",
            "Epoch 41/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0313 - accuracy: 0.6540 - val_loss: 0.9828 - val_accuracy: 0.6775\n",
            "Epoch 42/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0231 - accuracy: 0.6579 - val_loss: 0.9750 - val_accuracy: 0.6792\n",
            "Epoch 43/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0163 - accuracy: 0.6600 - val_loss: 0.9675 - val_accuracy: 0.6857\n",
            "Epoch 44/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0077 - accuracy: 0.6641 - val_loss: 0.9613 - val_accuracy: 0.6886\n",
            "Epoch 45/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0006 - accuracy: 0.6665 - val_loss: 0.9527 - val_accuracy: 0.6912\n",
            "Epoch 46/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.9934 - accuracy: 0.6708 - val_loss: 0.9457 - val_accuracy: 0.6924\n",
            "Epoch 47/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9861 - accuracy: 0.6747 - val_loss: 0.9386 - val_accuracy: 0.6925\n",
            "Epoch 48/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9810 - accuracy: 0.6772 - val_loss: 0.9325 - val_accuracy: 0.6967\n",
            "Epoch 49/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9724 - accuracy: 0.6798 - val_loss: 0.9255 - val_accuracy: 0.6965\n",
            "Epoch 50/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9669 - accuracy: 0.6818 - val_loss: 0.9185 - val_accuracy: 0.7018\n",
            "Epoch 51/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9600 - accuracy: 0.6853 - val_loss: 0.9130 - val_accuracy: 0.7048\n",
            "Epoch 52/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9519 - accuracy: 0.6889 - val_loss: 0.9057 - val_accuracy: 0.7078\n",
            "Epoch 53/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9474 - accuracy: 0.6909 - val_loss: 0.8997 - val_accuracy: 0.7101\n",
            "Epoch 54/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9397 - accuracy: 0.6938 - val_loss: 0.8957 - val_accuracy: 0.7092\n",
            "Epoch 55/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9343 - accuracy: 0.6950 - val_loss: 0.8928 - val_accuracy: 0.7107\n",
            "Epoch 56/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9281 - accuracy: 0.6979 - val_loss: 0.8828 - val_accuracy: 0.7177\n",
            "Epoch 57/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9204 - accuracy: 0.7016 - val_loss: 0.8763 - val_accuracy: 0.7197\n",
            "Epoch 58/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9162 - accuracy: 0.7029 - val_loss: 0.8716 - val_accuracy: 0.7152\n",
            "Epoch 59/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9117 - accuracy: 0.7049 - val_loss: 0.8681 - val_accuracy: 0.7155\n",
            "Epoch 60/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9044 - accuracy: 0.7074 - val_loss: 0.8623 - val_accuracy: 0.7196\n",
            "Epoch 61/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8993 - accuracy: 0.7085 - val_loss: 0.8549 - val_accuracy: 0.7236\n",
            "Epoch 62/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.8936 - accuracy: 0.7120 - val_loss: 0.8502 - val_accuracy: 0.7271\n",
            "Epoch 63/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.8873 - accuracy: 0.7144 - val_loss: 0.8467 - val_accuracy: 0.7288\n",
            "Epoch 64/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.8840 - accuracy: 0.7155 - val_loss: 0.8406 - val_accuracy: 0.7283\n",
            "Epoch 65/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8789 - accuracy: 0.7175 - val_loss: 0.8359 - val_accuracy: 0.7314\n",
            "Epoch 66/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8743 - accuracy: 0.7199 - val_loss: 0.8367 - val_accuracy: 0.7267\n",
            "Epoch 67/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8680 - accuracy: 0.7197 - val_loss: 0.8256 - val_accuracy: 0.7342\n",
            "Epoch 68/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8638 - accuracy: 0.7218 - val_loss: 0.8235 - val_accuracy: 0.7340\n",
            "Epoch 69/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8586 - accuracy: 0.7259 - val_loss: 0.8191 - val_accuracy: 0.7386\n",
            "Epoch 70/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8527 - accuracy: 0.7269 - val_loss: 0.8175 - val_accuracy: 0.7364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 1 added. Resulting score: 0.7176666666666667\n",
            "Train model 2\n",
            "Epoch 1/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.2929 - accuracy: 0.1362 - val_loss: 2.2781 - val_accuracy: 0.1652\n",
            "Epoch 2/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 2.1979 - accuracy: 0.2953 - val_loss: 2.1459 - val_accuracy: 0.3466\n",
            "Epoch 3/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.0751 - accuracy: 0.3833 - val_loss: 1.9809 - val_accuracy: 0.3800\n",
            "Epoch 4/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.9242 - accuracy: 0.3988 - val_loss: 1.8298 - val_accuracy: 0.4282\n",
            "Epoch 5/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.7907 - accuracy: 0.4261 - val_loss: 1.7105 - val_accuracy: 0.4673\n",
            "Epoch 6/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.6890 - accuracy: 0.4520 - val_loss: 1.6202 - val_accuracy: 0.4765\n",
            "Epoch 7/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.6117 - accuracy: 0.4766 - val_loss: 1.5507 - val_accuracy: 0.5045\n",
            "Epoch 8/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.5517 - accuracy: 0.4963 - val_loss: 1.4933 - val_accuracy: 0.5160\n",
            "Epoch 9/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.5021 - accuracy: 0.5115 - val_loss: 1.4433 - val_accuracy: 0.5448\n",
            "Epoch 10/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4597 - accuracy: 0.5251 - val_loss: 1.4018 - val_accuracy: 0.5500\n",
            "Epoch 11/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.4225 - accuracy: 0.5369 - val_loss: 1.3667 - val_accuracy: 0.5497\n",
            "Epoch 12/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.3901 - accuracy: 0.5455 - val_loss: 1.3313 - val_accuracy: 0.5672\n",
            "Epoch 13/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3594 - accuracy: 0.5577 - val_loss: 1.2998 - val_accuracy: 0.5818\n",
            "Epoch 14/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.3318 - accuracy: 0.5648 - val_loss: 1.2722 - val_accuracy: 0.5959\n",
            "Epoch 15/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3066 - accuracy: 0.5736 - val_loss: 1.2461 - val_accuracy: 0.6041\n",
            "Epoch 16/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2836 - accuracy: 0.5815 - val_loss: 1.2226 - val_accuracy: 0.6068\n",
            "Epoch 17/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2612 - accuracy: 0.5890 - val_loss: 1.1990 - val_accuracy: 0.6224\n",
            "Epoch 18/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2401 - accuracy: 0.5978 - val_loss: 1.1806 - val_accuracy: 0.6238\n",
            "Epoch 19/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2205 - accuracy: 0.6056 - val_loss: 1.1607 - val_accuracy: 0.6326\n",
            "Epoch 20/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.2029 - accuracy: 0.6103 - val_loss: 1.1415 - val_accuracy: 0.6368\n",
            "Epoch 21/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1867 - accuracy: 0.6157 - val_loss: 1.1228 - val_accuracy: 0.6406\n",
            "Epoch 22/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1692 - accuracy: 0.6239 - val_loss: 1.1071 - val_accuracy: 0.6474\n",
            "Epoch 23/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1547 - accuracy: 0.6303 - val_loss: 1.0920 - val_accuracy: 0.6500\n",
            "Epoch 24/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1399 - accuracy: 0.6317 - val_loss: 1.0780 - val_accuracy: 0.6575\n",
            "Epoch 25/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1280 - accuracy: 0.6361 - val_loss: 1.0620 - val_accuracy: 0.6537\n",
            "Epoch 26/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.1124 - accuracy: 0.6414 - val_loss: 1.0525 - val_accuracy: 0.6606\n",
            "Epoch 27/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0991 - accuracy: 0.6473 - val_loss: 1.0344 - val_accuracy: 0.6741\n",
            "Epoch 28/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0857 - accuracy: 0.6525 - val_loss: 1.0211 - val_accuracy: 0.6746\n",
            "Epoch 29/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.0742 - accuracy: 0.6558 - val_loss: 1.0088 - val_accuracy: 0.6778\n",
            "Epoch 30/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0638 - accuracy: 0.6586 - val_loss: 1.0031 - val_accuracy: 0.6762\n",
            "Epoch 31/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.0518 - accuracy: 0.6645 - val_loss: 0.9895 - val_accuracy: 0.6853\n",
            "Epoch 32/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0407 - accuracy: 0.6680 - val_loss: 0.9775 - val_accuracy: 0.6879\n",
            "Epoch 33/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0295 - accuracy: 0.6722 - val_loss: 0.9648 - val_accuracy: 0.6940\n",
            "Epoch 34/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0187 - accuracy: 0.6750 - val_loss: 0.9559 - val_accuracy: 0.7003\n",
            "Epoch 35/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.0115 - accuracy: 0.6774 - val_loss: 0.9440 - val_accuracy: 0.7001\n",
            "Epoch 36/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9993 - accuracy: 0.6826 - val_loss: 0.9329 - val_accuracy: 0.7047\n",
            "Epoch 37/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9919 - accuracy: 0.6833 - val_loss: 0.9261 - val_accuracy: 0.7060\n",
            "Epoch 38/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9802 - accuracy: 0.6900 - val_loss: 0.9164 - val_accuracy: 0.7082\n",
            "Epoch 39/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9713 - accuracy: 0.6916 - val_loss: 0.9057 - val_accuracy: 0.7144\n",
            "Epoch 40/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9640 - accuracy: 0.6942 - val_loss: 0.8992 - val_accuracy: 0.7132\n",
            "Epoch 41/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9546 - accuracy: 0.6971 - val_loss: 0.8890 - val_accuracy: 0.7174\n",
            "Epoch 42/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9465 - accuracy: 0.7003 - val_loss: 0.8823 - val_accuracy: 0.7213\n",
            "Epoch 43/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9373 - accuracy: 0.7037 - val_loss: 0.8734 - val_accuracy: 0.7241\n",
            "Epoch 44/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9314 - accuracy: 0.7051 - val_loss: 0.8683 - val_accuracy: 0.7249\n",
            "Epoch 45/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9232 - accuracy: 0.7065 - val_loss: 0.8632 - val_accuracy: 0.7245\n",
            "Epoch 46/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9160 - accuracy: 0.7097 - val_loss: 0.8515 - val_accuracy: 0.7304\n",
            "Epoch 47/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.9089 - accuracy: 0.7118 - val_loss: 0.8451 - val_accuracy: 0.7330\n",
            "Epoch 48/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9017 - accuracy: 0.7150 - val_loss: 0.8382 - val_accuracy: 0.7374\n",
            "Epoch 49/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8935 - accuracy: 0.7177 - val_loss: 0.8322 - val_accuracy: 0.7368\n",
            "Epoch 50/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8871 - accuracy: 0.7208 - val_loss: 0.8267 - val_accuracy: 0.7430\n",
            "Epoch 51/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8816 - accuracy: 0.7214 - val_loss: 0.8171 - val_accuracy: 0.7436\n",
            "Epoch 52/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8746 - accuracy: 0.7224 - val_loss: 0.8125 - val_accuracy: 0.7469\n",
            "Epoch 53/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.8707 - accuracy: 0.7234 - val_loss: 0.8088 - val_accuracy: 0.7498\n",
            "Epoch 54/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8648 - accuracy: 0.7272 - val_loss: 0.8001 - val_accuracy: 0.7512\n",
            "Epoch 55/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8569 - accuracy: 0.7290 - val_loss: 0.7942 - val_accuracy: 0.7523\n",
            "Epoch 56/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8519 - accuracy: 0.7312 - val_loss: 0.7909 - val_accuracy: 0.7549\n",
            "Epoch 57/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8464 - accuracy: 0.7324 - val_loss: 0.7849 - val_accuracy: 0.7536\n",
            "Epoch 58/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8407 - accuracy: 0.7334 - val_loss: 0.7779 - val_accuracy: 0.7567\n",
            "Epoch 59/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8341 - accuracy: 0.7354 - val_loss: 0.7745 - val_accuracy: 0.7581\n",
            "Epoch 60/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8290 - accuracy: 0.7377 - val_loss: 0.7676 - val_accuracy: 0.7581\n",
            "Epoch 61/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8246 - accuracy: 0.7399 - val_loss: 0.7639 - val_accuracy: 0.7621\n",
            "Epoch 62/9999\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.8207 - accuracy: 0.7396 - val_loss: 0.7568 - val_accuracy: 0.7650\n",
            "Epoch 63/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8147 - accuracy: 0.7413 - val_loss: 0.7534 - val_accuracy: 0.7666\n",
            "Epoch 64/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8089 - accuracy: 0.7438 - val_loss: 0.7517 - val_accuracy: 0.7650\n",
            "Epoch 65/9999\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.8051 - accuracy: 0.7454 - val_loss: 0.7449 - val_accuracy: 0.7680\n",
            "Epoch 66/9999\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8010 - accuracy: 0.7455 - val_loss: 0.7439 - val_accuracy: 0.7648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 2 added. Resulting score: 0.74975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGT6jV-hcLbJ",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CurcmjMCcrJI",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy vs nr of models\n",
        "Visualizing the accuracy vs the number of models in the ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvZLQyb5cg7R",
        "colab_type": "code",
        "outputId": "b05dbe17-6380-4cda-fe40-5dccb31c608d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "accuracy_df.insert(1, \"Nr of models\", accuracy_df.index)\n",
        "\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Nr of models</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.721000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.717667</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.749750</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Nr of models\n",
              "0  0.000000             0\n",
              "1  0.721000             1\n",
              "2  0.717667             2\n",
              "3  0.749750             3"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXq8Uj3lenzH",
        "colab_type": "code",
        "outputId": "f0db6672-eb5d-4678-9cf4-e9669923b083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# remove first row\n",
        "accuracy_df = accuracy_df.iloc[1:]\n",
        "\n",
        "accuracy_df.plot(x=\"Nr of models\", y=\"Accuracy\", xticks=accuracy_df[\"Nr of models\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51rnX_l7Pfdr",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy\n",
        "The final accuracy of the ensamble on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwNmmvSFPlVx",
        "colab_type": "code",
        "outputId": "51aab002-bf79-498b-c240-209e99833edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Accuracy: \" + str(predict(models, x_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpiA_XQUbye8",
        "colab_type": "code",
        "outputId": "bb3a1b8a-7255-4106-dd36-ee579a8740d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = []\n",
        "\n",
        "for m in tqdm(models):\n",
        "    predictions.append(np.argmax(m.predict(x_test), axis=1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMfc-h8xAYQu",
        "colab_type": "text"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N9wSXF1iSp3",
        "colab_type": "code",
        "outputId": "47b2b125-f761-44b1-ab60-46b8263ca6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classified = []\n",
        "\n",
        "for prediction in tqdm(predictions):\n",
        "    classified.append([1 if i==j else 0 for i,j in zip(prediction,np.argmax(y_test, axis = 1))])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 214.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAky42lMV102",
        "colab_type": "code",
        "outputId": "243a2636-4fcf-471d-9319-aef1262407e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(predictions):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(predictions):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "display(pd.DataFrame(correlation_matrix))\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.839513</td>\n",
              "      <td>0.845599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.839513</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.831005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.845599</td>\n",
              "      <td>0.831005</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2\n",
              "0       NaN  0.839513  0.845599\n",
              "1  0.839513       NaN  0.831005\n",
              "2  0.845599  0.831005       NaN"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.8387056180281784\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}