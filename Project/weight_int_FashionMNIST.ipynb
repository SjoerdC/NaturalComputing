{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weight_int_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed2ac9fc-d82d-4744-eee2-bb875d6b9ebd"
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "NUM_CHANNELS = 1\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"MNIST_weight_init\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9M4_-IaBOsn"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n9nJGd_BQ-r",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8QvEt97vF52"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JtJIUBsFKeRO",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "9a3e94fb-983d-4950-daf3-54beb99cda80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4SYRuKZaIwb",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBci5ba9hiaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIBGIrlkvOt0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EbiuqESLvTOY"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXFkx19XmqKe",
        "colab": {}
      },
      "source": [
        "def predict(models):\n",
        "    predictions = []\n",
        "\n",
        "    for m in tqdm(models):\n",
        "        predictions.append(np.argmax(m.predict(x_test), axis=1))\n",
        "\n",
        "    prediction = np.transpose(predictions)\n",
        "    prediction = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=prediction)\n",
        "\n",
        "    return accuracy_score(prediction, np.argmax(y_test, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqdcrD_vQ-Q"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "40c25dc0-0580-4f46-de08-95c37aa0e147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = [0]\n",
        "initializer = [\"Zero\",\"Ones\",\"Random Normal\",\"Random Unifrom\",\"Identity\",\"Orthogonal\",\"Glorot Normal\",\"Glorot Uniform\"]\n",
        "for i in range(len(initializer)):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "    print(f\"Weight init method: {initializer[i]} \")\n",
        "    model = FashionMNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
        "    \n",
        "    for layer in model.layers: \n",
        "        if hasattr(layer, 'kernel_initializer'):\n",
        "            if(initializer[i] == \"Zero\"):\n",
        "                layer.kernel_initializer = initializers.Zeros()\n",
        "            elif(initializer[i] == \"Ones\"):\n",
        "                layer.kernel_initializer = initializers.Ones()\n",
        "            elif(initializer[i] == \"Random Normal\"):\n",
        "                layer.kernel_initializer = initializers.RandomNormal()\n",
        "            elif(initializer[i] == \"Random Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.RandomUniform()\n",
        "            elif(initializer[i] == \"Identity\"):\n",
        "                layer.kernel_initializer = initializers.Identity()\n",
        "            elif(initializer[i] == \"Orthogonal\"):\n",
        "                layer.kernel_initializer = initializers.Orthogonal()\n",
        "            elif(initializer[i] == \"Glorot Normal\"):\n",
        "                layer.kernel_initializer = initializers.GlorotNormal()\n",
        "            elif(initializer[i] == \"Glorot Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.GlorotUnifrom()\n",
        "          \n",
        "    es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', min_delta=0.01, patience=3)\n",
        "    model.fit(x_train,y_train,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = EPOCHS,\n",
        "              validation_data = (x_test,y_test),\n",
        "              shuffle = True,\n",
        "              callbacks=[es])\n",
        "    models.append(model)\n",
        "\n",
        "    acc = predict(models)\n",
        "\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 0\n",
            "Weight init method: Zero \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 10s 203us/step - loss: 2.1487 - accuracy: 0.2455 - val_loss: 2.1708 - val_accuracy: 0.2841\n",
            "Epoch 2/20\n",
            " 2432/48000 [>.............................] - ETA: 3s - loss: 1.9953 - accuracy: 0.3573"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8997 - accuracy: 0.3768 - val_loss: 1.8102 - val_accuracy: 0.4124\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.7049 - accuracy: 0.4332 - val_loss: 1.6138 - val_accuracy: 0.4573\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.5538 - accuracy: 0.4789 - val_loss: 1.4793 - val_accuracy: 0.5064\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4304 - accuracy: 0.5273 - val_loss: 1.3724 - val_accuracy: 0.5483\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.3392 - accuracy: 0.5654 - val_loss: 1.2922 - val_accuracy: 0.5834\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2675 - accuracy: 0.5879 - val_loss: 1.2317 - val_accuracy: 0.6032\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2105 - accuracy: 0.6040 - val_loss: 1.1830 - val_accuracy: 0.6148\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1630 - accuracy: 0.6165 - val_loss: 1.1413 - val_accuracy: 0.6202\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1241 - accuracy: 0.6252 - val_loss: 1.1038 - val_accuracy: 0.6317\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0904 - accuracy: 0.6346 - val_loss: 1.0768 - val_accuracy: 0.6371\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0611 - accuracy: 0.6418 - val_loss: 1.0487 - val_accuracy: 0.6465\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0359 - accuracy: 0.6499 - val_loss: 1.0249 - val_accuracy: 0.6502\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0117 - accuracy: 0.6579 - val_loss: 1.0065 - val_accuracy: 0.6508\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9920 - accuracy: 0.6622 - val_loss: 0.9843 - val_accuracy: 0.6633\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 0.9738 - accuracy: 0.6682 - val_loss: 0.9687 - val_accuracy: 0.6701\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 0.9564 - accuracy: 0.6771 - val_loss: 0.9584 - val_accuracy: 0.6718\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 0.9403 - accuracy: 0.6811 - val_loss: 0.9372 - val_accuracy: 0.6780\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9259 - accuracy: 0.6844 - val_loss: 0.9258 - val_accuracy: 0.6814\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9133 - accuracy: 0.6892 - val_loss: 0.9126 - val_accuracy: 0.6840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 0 added. Resulting score: 0.684\n",
            "Train model 1\n",
            "Weight init method: Ones \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.2546 - accuracy: 0.2019 - val_loss: 2.2334 - val_accuracy: 0.3373\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.9715 - accuracy: 0.3614 - val_loss: 1.8556 - val_accuracy: 0.4184\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7264 - accuracy: 0.4407 - val_loss: 1.6146 - val_accuracy: 0.4839\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.5381 - accuracy: 0.5052 - val_loss: 1.4571 - val_accuracy: 0.5396\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 1.4011 - accuracy: 0.5479 - val_loss: 1.3431 - val_accuracy: 0.5672\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3037 - accuracy: 0.5785 - val_loss: 1.2626 - val_accuracy: 0.5902\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2304 - accuracy: 0.6001 - val_loss: 1.1995 - val_accuracy: 0.6138\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1712 - accuracy: 0.6180 - val_loss: 1.1491 - val_accuracy: 0.6232\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1252 - accuracy: 0.6299 - val_loss: 1.1071 - val_accuracy: 0.6350\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0864 - accuracy: 0.6416 - val_loss: 1.0739 - val_accuracy: 0.6432\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0520 - accuracy: 0.6525 - val_loss: 1.0424 - val_accuracy: 0.6559\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0238 - accuracy: 0.6601 - val_loss: 1.0182 - val_accuracy: 0.6546\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9992 - accuracy: 0.6671 - val_loss: 0.9938 - val_accuracy: 0.6674\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9770 - accuracy: 0.6743 - val_loss: 0.9748 - val_accuracy: 0.6747\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9562 - accuracy: 0.6805 - val_loss: 0.9539 - val_accuracy: 0.6827\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9385 - accuracy: 0.6856 - val_loss: 0.9373 - val_accuracy: 0.6890\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9207 - accuracy: 0.6933 - val_loss: 0.9216 - val_accuracy: 0.6955\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9059 - accuracy: 0.6977 - val_loss: 0.9092 - val_accuracy: 0.6969\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.8906 - accuracy: 0.7054 - val_loss: 0.8940 - val_accuracy: 0.7073\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8775 - accuracy: 0.7107 - val_loss: 0.8812 - val_accuracy: 0.7117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 1 added. Resulting score: 0.6987\n",
            "Train model 2\n",
            "Weight init method: Random Normal \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.1713 - accuracy: 0.1981 - val_loss: 2.1893 - val_accuracy: 0.3017\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.8716 - accuracy: 0.4382 - val_loss: 1.7423 - val_accuracy: 0.4626\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6188 - accuracy: 0.4941 - val_loss: 1.5204 - val_accuracy: 0.5150\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4609 - accuracy: 0.5376 - val_loss: 1.3975 - val_accuracy: 0.5486\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3521 - accuracy: 0.5684 - val_loss: 1.3043 - val_accuracy: 0.5802\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2705 - accuracy: 0.5914 - val_loss: 1.2318 - val_accuracy: 0.6032\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2044 - accuracy: 0.6115 - val_loss: 1.1754 - val_accuracy: 0.6183\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1494 - accuracy: 0.6270 - val_loss: 1.1264 - val_accuracy: 0.6344\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1032 - accuracy: 0.6425 - val_loss: 1.0826 - val_accuracy: 0.6453\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0627 - accuracy: 0.6535 - val_loss: 1.0476 - val_accuracy: 0.6555\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0284 - accuracy: 0.6647 - val_loss: 1.0169 - val_accuracy: 0.6686\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9984 - accuracy: 0.6732 - val_loss: 0.9883 - val_accuracy: 0.6771\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9710 - accuracy: 0.6831 - val_loss: 0.9649 - val_accuracy: 0.6826\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9476 - accuracy: 0.6910 - val_loss: 0.9434 - val_accuracy: 0.6897\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9250 - accuracy: 0.6983 - val_loss: 0.9226 - val_accuracy: 0.6960\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9042 - accuracy: 0.7048 - val_loss: 0.9027 - val_accuracy: 0.6997\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.8872 - accuracy: 0.7102 - val_loss: 0.8871 - val_accuracy: 0.7054\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.8701 - accuracy: 0.7151 - val_loss: 0.8717 - val_accuracy: 0.7126\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.8561 - accuracy: 0.7189 - val_loss: 0.8578 - val_accuracy: 0.7181\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8416 - accuracy: 0.7233 - val_loss: 0.8501 - val_accuracy: 0.7177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 2 added. Resulting score: 0.717\n",
            "Train model 3\n",
            "Weight init method: Random Unifrom \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 2.1491 - accuracy: 0.2372 - val_loss: 2.1718 - val_accuracy: 0.3124\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.8905 - accuracy: 0.4095 - val_loss: 1.7846 - val_accuracy: 0.4421\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.6600 - accuracy: 0.4795 - val_loss: 1.5538 - val_accuracy: 0.5004\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.4873 - accuracy: 0.5284 - val_loss: 1.4132 - val_accuracy: 0.5571\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.3679 - accuracy: 0.5661 - val_loss: 1.3173 - val_accuracy: 0.5773\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2830 - accuracy: 0.5864 - val_loss: 1.2463 - val_accuracy: 0.5929\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2182 - accuracy: 0.6026 - val_loss: 1.1917 - val_accuracy: 0.6024\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.1658 - accuracy: 0.6132 - val_loss: 1.1456 - val_accuracy: 0.6135\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1263 - accuracy: 0.6215 - val_loss: 1.1116 - val_accuracy: 0.6221\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.0927 - accuracy: 0.6308 - val_loss: 1.0790 - val_accuracy: 0.6306\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.0661 - accuracy: 0.6374 - val_loss: 1.0553 - val_accuracy: 0.6362\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0432 - accuracy: 0.6443 - val_loss: 1.0336 - val_accuracy: 0.6424\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0225 - accuracy: 0.6484 - val_loss: 1.0169 - val_accuracy: 0.6457\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0056 - accuracy: 0.6538 - val_loss: 0.9995 - val_accuracy: 0.6528\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9901 - accuracy: 0.6587 - val_loss: 0.9847 - val_accuracy: 0.6567\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9762 - accuracy: 0.6635 - val_loss: 0.9708 - val_accuracy: 0.6627\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9626 - accuracy: 0.6669 - val_loss: 0.9592 - val_accuracy: 0.6656\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9507 - accuracy: 0.6717 - val_loss: 0.9469 - val_accuracy: 0.6658\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9395 - accuracy: 0.6760 - val_loss: 0.9370 - val_accuracy: 0.6776\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9297 - accuracy: 0.6802 - val_loss: 0.9262 - val_accuracy: 0.6803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:02<00:00,  1.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 3 added. Resulting score: 0.7118\n",
            "Train model 4\n",
            "Weight init method: Identity \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 84us/step - loss: 2.1553 - accuracy: 0.2131 - val_loss: 2.1742 - val_accuracy: 0.2281\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8659 - accuracy: 0.3871 - val_loss: 1.7598 - val_accuracy: 0.4280\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.6311 - accuracy: 0.4780 - val_loss: 1.5296 - val_accuracy: 0.5047\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.4639 - accuracy: 0.5305 - val_loss: 1.3891 - val_accuracy: 0.5523\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.3457 - accuracy: 0.5679 - val_loss: 1.2935 - val_accuracy: 0.5817\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2604 - accuracy: 0.5893 - val_loss: 1.2186 - val_accuracy: 0.5971\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1964 - accuracy: 0.6036 - val_loss: 1.1640 - val_accuracy: 0.6115\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.1464 - accuracy: 0.6159 - val_loss: 1.1220 - val_accuracy: 0.6229\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.1068 - accuracy: 0.6270 - val_loss: 1.0864 - val_accuracy: 0.6304\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0726 - accuracy: 0.6345 - val_loss: 1.0569 - val_accuracy: 0.6379\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0446 - accuracy: 0.6433 - val_loss: 1.0326 - val_accuracy: 0.6449\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0199 - accuracy: 0.6509 - val_loss: 1.0082 - val_accuracy: 0.6496\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9970 - accuracy: 0.6573 - val_loss: 0.9891 - val_accuracy: 0.6546\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9761 - accuracy: 0.6638 - val_loss: 0.9715 - val_accuracy: 0.6665\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9571 - accuracy: 0.6716 - val_loss: 0.9495 - val_accuracy: 0.6736\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9395 - accuracy: 0.6778 - val_loss: 0.9324 - val_accuracy: 0.6782\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9224 - accuracy: 0.6843 - val_loss: 0.9182 - val_accuracy: 0.6818\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 0.9060 - accuracy: 0.6908 - val_loss: 0.9031 - val_accuracy: 0.6882\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 0.8918 - accuracy: 0.6960 - val_loss: 0.8861 - val_accuracy: 0.6971\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 0.8760 - accuracy: 0.7014 - val_loss: 0.8737 - val_accuracy: 0.7015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:02<00:00,  1.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 4 added. Resulting score: 0.7145\n",
            "Train model 5\n",
            "Weight init method: Orthogonal \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.2271 - accuracy: 0.2100 - val_loss: 2.2119 - val_accuracy: 0.1924\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.9787 - accuracy: 0.4407 - val_loss: 1.8755 - val_accuracy: 0.4601\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7214 - accuracy: 0.4897 - val_loss: 1.5990 - val_accuracy: 0.5052\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.5135 - accuracy: 0.5258 - val_loss: 1.4285 - val_accuracy: 0.5496\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 1.3808 - accuracy: 0.5615 - val_loss: 1.3201 - val_accuracy: 0.5882\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2868 - accuracy: 0.5920 - val_loss: 1.2424 - val_accuracy: 0.6065\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2153 - accuracy: 0.6141 - val_loss: 1.1808 - val_accuracy: 0.6295\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1579 - accuracy: 0.6308 - val_loss: 1.1293 - val_accuracy: 0.6369\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1111 - accuracy: 0.6437 - val_loss: 1.0882 - val_accuracy: 0.6481\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0725 - accuracy: 0.6539 - val_loss: 1.0532 - val_accuracy: 0.6556\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0388 - accuracy: 0.6645 - val_loss: 1.0247 - val_accuracy: 0.6650\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0113 - accuracy: 0.6713 - val_loss: 0.9988 - val_accuracy: 0.6719\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9868 - accuracy: 0.6782 - val_loss: 0.9791 - val_accuracy: 0.6743\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9646 - accuracy: 0.6861 - val_loss: 0.9575 - val_accuracy: 0.6857\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9462 - accuracy: 0.6910 - val_loss: 0.9374 - val_accuracy: 0.6942\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9278 - accuracy: 0.6953 - val_loss: 0.9209 - val_accuracy: 0.6969\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9107 - accuracy: 0.7017 - val_loss: 0.9057 - val_accuracy: 0.7016\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8952 - accuracy: 0.7047 - val_loss: 0.8934 - val_accuracy: 0.7049\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 0.8813 - accuracy: 0.7107 - val_loss: 0.8800 - val_accuracy: 0.7083\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.8686 - accuracy: 0.7139 - val_loss: 0.8678 - val_accuracy: 0.7147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 5 added. Resulting score: 0.7177\n",
            "Train model 6\n",
            "Weight init method: Glorot Normal \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 83us/step - loss: 2.1850 - accuracy: 0.2416 - val_loss: 2.1911 - val_accuracy: 0.3165\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.9054 - accuracy: 0.3821 - val_loss: 1.7935 - val_accuracy: 0.4465\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6647 - accuracy: 0.4481 - val_loss: 1.5595 - val_accuracy: 0.4838\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.4961 - accuracy: 0.5094 - val_loss: 1.4239 - val_accuracy: 0.5352\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3773 - accuracy: 0.5587 - val_loss: 1.3249 - val_accuracy: 0.5745\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2919 - accuracy: 0.5818 - val_loss: 1.2521 - val_accuracy: 0.5949\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2269 - accuracy: 0.5975 - val_loss: 1.1950 - val_accuracy: 0.6027\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1758 - accuracy: 0.6084 - val_loss: 1.1513 - val_accuracy: 0.6115\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1332 - accuracy: 0.6190 - val_loss: 1.1139 - val_accuracy: 0.6183\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0995 - accuracy: 0.6253 - val_loss: 1.0833 - val_accuracy: 0.6272\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0696 - accuracy: 0.6324 - val_loss: 1.0561 - val_accuracy: 0.6338\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0445 - accuracy: 0.6387 - val_loss: 1.0348 - val_accuracy: 0.6409\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0221 - accuracy: 0.6460 - val_loss: 1.0129 - val_accuracy: 0.6486\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0020 - accuracy: 0.6525 - val_loss: 0.9949 - val_accuracy: 0.6546\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9841 - accuracy: 0.6593 - val_loss: 0.9777 - val_accuracy: 0.6604\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9676 - accuracy: 0.6646 - val_loss: 0.9646 - val_accuracy: 0.6648\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9524 - accuracy: 0.6699 - val_loss: 0.9475 - val_accuracy: 0.6714\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9376 - accuracy: 0.6774 - val_loss: 0.9332 - val_accuracy: 0.6821\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9237 - accuracy: 0.6823 - val_loss: 0.9202 - val_accuracy: 0.6818\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9119 - accuracy: 0.6891 - val_loss: 0.9117 - val_accuracy: 0.6901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:03<00:00,  1.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 6 added. Resulting score: 0.7144\n",
            "Train model 7\n",
            "Weight init method: Glorot Uniform \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.1557 - accuracy: 0.2471 - val_loss: 2.1867 - val_accuracy: 0.3487\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8822 - accuracy: 0.4099 - val_loss: 1.7901 - val_accuracy: 0.4467\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6593 - accuracy: 0.4705 - val_loss: 1.5631 - val_accuracy: 0.5091\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.4958 - accuracy: 0.5174 - val_loss: 1.4264 - val_accuracy: 0.5545\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3793 - accuracy: 0.5612 - val_loss: 1.3258 - val_accuracy: 0.5750\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2909 - accuracy: 0.5936 - val_loss: 1.2487 - val_accuracy: 0.6040\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2206 - accuracy: 0.6149 - val_loss: 1.1879 - val_accuracy: 0.6230\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1647 - accuracy: 0.6316 - val_loss: 1.1381 - val_accuracy: 0.6324\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1179 - accuracy: 0.6436 - val_loss: 1.0980 - val_accuracy: 0.6407\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0787 - accuracy: 0.6536 - val_loss: 1.0615 - val_accuracy: 0.6545\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0455 - accuracy: 0.6613 - val_loss: 1.0315 - val_accuracy: 0.6578\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0163 - accuracy: 0.6702 - val_loss: 1.0073 - val_accuracy: 0.6666\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9913 - accuracy: 0.6777 - val_loss: 0.9839 - val_accuracy: 0.6759\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9670 - accuracy: 0.6854 - val_loss: 0.9618 - val_accuracy: 0.6819\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9475 - accuracy: 0.6900 - val_loss: 0.9446 - val_accuracy: 0.6863\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9286 - accuracy: 0.6968 - val_loss: 0.9304 - val_accuracy: 0.6892\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9118 - accuracy: 0.7022 - val_loss: 0.9085 - val_accuracy: 0.7019\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8959 - accuracy: 0.7066 - val_loss: 0.8947 - val_accuracy: 0.7056\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8805 - accuracy: 0.7120 - val_loss: 0.8794 - val_accuracy: 0.7090\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.8647 - accuracy: 0.7175 - val_loss: 0.8672 - val_accuracy: 0.7171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 7 added. Resulting score: 0.7195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fGT6jV-hcLbJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CurcmjMCcrJI"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yvZLQyb5cg7R",
        "outputId": "ebc67e11-eb0e-47b0-863b-f7d0de95911b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "accuracy_df.insert(1, \"Round\", accuracy_df.index + 1)\n",
        "\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy.csv\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Round</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6840</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6987</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7170</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7118</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7145</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7177</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7144</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7195</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Round\n",
              "0    0.0000      1\n",
              "1    0.6840      2\n",
              "2    0.6987      3\n",
              "3    0.7170      4\n",
              "4    0.7118      5\n",
              "5    0.7145      6\n",
              "6    0.7177      7\n",
              "7    0.7144      8\n",
              "8    0.7195      9"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXq8Uj3lenzH",
        "outputId": "974f5d99-e44c-41cf-a358-38c9052bcb45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy_df.plot(x=\"Round\", y=\"Accuracy\", xticks=accuracy_df[\"Round\"])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMfc-h8xAYQu"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0N9wSXF1iSp3",
        "outputId": "736e062a-4077-4f32-acb3-58793dc1f1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = []\n",
        "\n",
        "for m in tqdm(models):\n",
        "    predictions.append(np.argmax(m.predict(x_test), axis=1))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAky42lMV102",
        "outputId": "81fb6bff-4fd3-4d81-c9cd-d8ee4e432116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(predictions):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(predictions):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "display(pd.DataFrame(correlation_matrix))\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.871305</td>\n",
              "      <td>0.875581</td>\n",
              "      <td>0.870748</td>\n",
              "      <td>0.888393</td>\n",
              "      <td>0.874177</td>\n",
              "      <td>0.871880</td>\n",
              "      <td>0.867839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.871305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.899659</td>\n",
              "      <td>0.863129</td>\n",
              "      <td>0.891148</td>\n",
              "      <td>0.897952</td>\n",
              "      <td>0.877635</td>\n",
              "      <td>0.883685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.875581</td>\n",
              "      <td>0.899659</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.859124</td>\n",
              "      <td>0.885291</td>\n",
              "      <td>0.889631</td>\n",
              "      <td>0.870224</td>\n",
              "      <td>0.885219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.870748</td>\n",
              "      <td>0.863129</td>\n",
              "      <td>0.859124</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.879595</td>\n",
              "      <td>0.871862</td>\n",
              "      <td>0.894571</td>\n",
              "      <td>0.857108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.888393</td>\n",
              "      <td>0.891148</td>\n",
              "      <td>0.885291</td>\n",
              "      <td>0.879595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.893063</td>\n",
              "      <td>0.881699</td>\n",
              "      <td>0.881690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.874177</td>\n",
              "      <td>0.897952</td>\n",
              "      <td>0.889631</td>\n",
              "      <td>0.871862</td>\n",
              "      <td>0.893063</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.900322</td>\n",
              "      <td>0.891488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.871880</td>\n",
              "      <td>0.877635</td>\n",
              "      <td>0.870224</td>\n",
              "      <td>0.894571</td>\n",
              "      <td>0.881699</td>\n",
              "      <td>0.900322</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.864986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.867839</td>\n",
              "      <td>0.883685</td>\n",
              "      <td>0.885219</td>\n",
              "      <td>0.857108</td>\n",
              "      <td>0.881690</td>\n",
              "      <td>0.891488</td>\n",
              "      <td>0.864986</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...         5         6         7\n",
              "0       NaN  0.871305  0.875581  ...  0.874177  0.871880  0.867839\n",
              "1  0.871305       NaN  0.899659  ...  0.897952  0.877635  0.883685\n",
              "2  0.875581  0.899659       NaN  ...  0.889631  0.870224  0.885219\n",
              "3  0.870748  0.863129  0.859124  ...  0.871862  0.894571  0.857108\n",
              "4  0.888393  0.891148  0.885291  ...  0.893063  0.881699  0.881690\n",
              "5  0.874177  0.897952  0.889631  ...       NaN  0.900322  0.891488\n",
              "6  0.871880  0.877635  0.870224  ...  0.900322       NaN  0.864986\n",
              "7  0.867839  0.883685  0.885219  ...  0.891488  0.864986       NaN\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.8799643988209123\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}