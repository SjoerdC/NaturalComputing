{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weight_int_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "outputId": "f0f30dbc-bde7-45f0-93a7-1921da40051d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "NUM_CHANNELS = 1\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"MNIST_weight_init\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9M4_-IaBOsn"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n9nJGd_BQ-r",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8QvEt97vF52"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JtJIUBsFKeRO",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "140b67a1-7a0a-46ea-c8bc-befcb3c31535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4SYRuKZaIwb",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBci5ba9hiaQ",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIBGIrlkvOt0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EbiuqESLvTOY"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqdcrD_vQ-Q"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "d79cdba6-228a-46ff-dd7a-a660f0edacb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = []\n",
        "predictions = []\n",
        "initializer = [\"Zero\",\"Ones\",\"Random Normal\",\"Random Uniform\",\"Identity\",\"Orthogonal\",\"Glorot Normal\",\"Glorot Uniform\"]\n",
        "for i in range(len(initializer)):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "    print(f\"Weight init method: {initializer[i]} \")\n",
        "    model = FashionMNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
        "    \n",
        "    for layer in model.layers: \n",
        "        if hasattr(layer, 'kernel_initializer'):\n",
        "            if(initializer[i] == \"Zero\"):\n",
        "                layer.kernel_initializer = initializers.Zeros()\n",
        "            elif(initializer[i] == \"Ones\"):\n",
        "                layer.kernel_initializer = initializers.Ones()\n",
        "            elif(initializer[i] == \"Random Normal\"):\n",
        "                layer.kernel_initializer = initializers.RandomNormal()\n",
        "            elif(initializer[i] == \"Random Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.RandomUniform()\n",
        "            elif(initializer[i] == \"Identity\"):\n",
        "                layer.kernel_initializer = initializers.Identity()\n",
        "            elif(initializer[i] == \"Orthogonal\"):\n",
        "                layer.kernel_initializer = initializers.Orthogonal()\n",
        "            elif(initializer[i] == \"Glorot Normal\"):\n",
        "                layer.kernel_initializer = initializers.GlorotNormal()\n",
        "            elif(initializer[i] == \"Glorot Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.GlorotUnifrom()\n",
        "          \n",
        "    es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', min_delta=0.01, patience=3)\n",
        "    model.fit(x_train,y_train,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = EPOCHS,\n",
        "              validation_data = (x_val,y_val),\n",
        "              shuffle = True,\n",
        "              callbacks=[es])\n",
        "    models.append(model)\n",
        "    y_prob = model.predict(x_test) \n",
        "    predictions.append(y_prob.argmax(axis=-1))\n",
        "    acc = model.evaluate(x_test,y_testc)[1]\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 0\n",
            "Weight init method: Zero \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 93us/step - loss: 2.1487 - accuracy: 0.2455 - val_loss: 2.1680 - val_accuracy: 0.2932\n",
            "Epoch 2/10\n",
            " 3456/48000 [=>............................] - ETA: 2s - loss: 1.9920 - accuracy: 0.3571"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.9000 - accuracy: 0.3768 - val_loss: 1.8021 - val_accuracy: 0.4241\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.7052 - accuracy: 0.4329 - val_loss: 1.6046 - val_accuracy: 0.4569\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.5538 - accuracy: 0.4793 - val_loss: 1.4684 - val_accuracy: 0.5028\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.4303 - accuracy: 0.5273 - val_loss: 1.3604 - val_accuracy: 0.5491\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.3392 - accuracy: 0.5650 - val_loss: 1.2798 - val_accuracy: 0.5813\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.2675 - accuracy: 0.5877 - val_loss: 1.2177 - val_accuracy: 0.5991\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.2105 - accuracy: 0.6040 - val_loss: 1.1671 - val_accuracy: 0.6131\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1630 - accuracy: 0.6166 - val_loss: 1.1236 - val_accuracy: 0.6214\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 1.1241 - accuracy: 0.6256 - val_loss: 1.0852 - val_accuracy: 0.6342\n",
            "10000/10000 [==============================] - 1s 89us/step\n",
            "Model: 0 added. Resulting score: 0.6317999958992004\n",
            "Train model 1\n",
            "Weight init method: Ones \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 64us/step - loss: 2.1930 - accuracy: 0.2764 - val_loss: 2.1917 - val_accuracy: 0.2992\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 1.9076 - accuracy: 0.3816 - val_loss: 1.7854 - val_accuracy: 0.4142\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.6702 - accuracy: 0.4515 - val_loss: 1.5533 - val_accuracy: 0.5042\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.5053 - accuracy: 0.5191 - val_loss: 1.4211 - val_accuracy: 0.5531\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.3921 - accuracy: 0.5580 - val_loss: 1.3261 - val_accuracy: 0.5864\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.3070 - accuracy: 0.5796 - val_loss: 1.2517 - val_accuracy: 0.5950\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.2409 - accuracy: 0.5958 - val_loss: 1.1933 - val_accuracy: 0.6009\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1878 - accuracy: 0.6061 - val_loss: 1.1453 - val_accuracy: 0.6218\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1428 - accuracy: 0.6175 - val_loss: 1.1041 - val_accuracy: 0.6316\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1046 - accuracy: 0.6292 - val_loss: 1.0687 - val_accuracy: 0.6363\n",
            "10000/10000 [==============================] - 1s 84us/step\n",
            "Model: 1 added. Resulting score: 0.6315000057220459\n",
            "Train model 2\n",
            "Weight init method: Random Normal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 61us/step - loss: 2.2549 - accuracy: 0.2009 - val_loss: 2.2325 - val_accuracy: 0.3391\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.9715 - accuracy: 0.3616 - val_loss: 1.8440 - val_accuracy: 0.4212\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.7259 - accuracy: 0.4403 - val_loss: 1.5999 - val_accuracy: 0.4870\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.5375 - accuracy: 0.5053 - val_loss: 1.4411 - val_accuracy: 0.5469\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.4008 - accuracy: 0.5479 - val_loss: 1.3262 - val_accuracy: 0.5707\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.3034 - accuracy: 0.5784 - val_loss: 1.2437 - val_accuracy: 0.5932\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.2302 - accuracy: 0.5998 - val_loss: 1.1791 - val_accuracy: 0.6132\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 1.1709 - accuracy: 0.6178 - val_loss: 1.1268 - val_accuracy: 0.6234\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.1250 - accuracy: 0.6293 - val_loss: 1.0835 - val_accuracy: 0.6383\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.0863 - accuracy: 0.6417 - val_loss: 1.0486 - val_accuracy: 0.6482\n",
            "10000/10000 [==============================] - 1s 82us/step\n",
            "Model: 2 added. Resulting score: 0.64410001039505\n",
            "Train model 3\n",
            "Weight init method: Random Uniform \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 61us/step - loss: 2.2184 - accuracy: 0.1978 - val_loss: 2.1859 - val_accuracy: 0.3118\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.9657 - accuracy: 0.3868 - val_loss: 1.8779 - val_accuracy: 0.3965\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 54us/step - loss: 1.7564 - accuracy: 0.4289 - val_loss: 1.6414 - val_accuracy: 0.4601\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.5819 - accuracy: 0.4770 - val_loss: 1.4980 - val_accuracy: 0.4972\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.4550 - accuracy: 0.5176 - val_loss: 1.3899 - val_accuracy: 0.5461\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.3619 - accuracy: 0.5529 - val_loss: 1.3046 - val_accuracy: 0.5753\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.2899 - accuracy: 0.5757 - val_loss: 1.2443 - val_accuracy: 0.5855\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.2315 - accuracy: 0.5869 - val_loss: 1.1912 - val_accuracy: 0.6045\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1841 - accuracy: 0.6019 - val_loss: 1.1436 - val_accuracy: 0.6112\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1426 - accuracy: 0.6134 - val_loss: 1.1052 - val_accuracy: 0.6179\n",
            "10000/10000 [==============================] - 1s 82us/step\n",
            "Model: 3 added. Resulting score: 0.6165000200271606\n",
            "Train model 4\n",
            "Weight init method: Identity \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 62us/step - loss: 2.1713 - accuracy: 0.1981 - val_loss: 2.1876 - val_accuracy: 0.3061\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.8716 - accuracy: 0.4382 - val_loss: 1.7312 - val_accuracy: 0.4703\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.6188 - accuracy: 0.4942 - val_loss: 1.5068 - val_accuracy: 0.5230\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.4609 - accuracy: 0.5377 - val_loss: 1.3834 - val_accuracy: 0.5541\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.3521 - accuracy: 0.5683 - val_loss: 1.2899 - val_accuracy: 0.5850\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.2706 - accuracy: 0.5913 - val_loss: 1.2166 - val_accuracy: 0.6102\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 54us/step - loss: 1.2045 - accuracy: 0.6115 - val_loss: 1.1584 - val_accuracy: 0.6252\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.1494 - accuracy: 0.6271 - val_loss: 1.1087 - val_accuracy: 0.6424\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.1032 - accuracy: 0.6423 - val_loss: 1.0636 - val_accuracy: 0.6517\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.0628 - accuracy: 0.6536 - val_loss: 1.0273 - val_accuracy: 0.6602\n",
            "10000/10000 [==============================] - 1s 82us/step\n",
            "Model: 4 added. Resulting score: 0.6557000279426575\n",
            "Train model 5\n",
            "Weight init method: Orthogonal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 61us/step - loss: 2.2057 - accuracy: 0.2380 - val_loss: 2.2152 - val_accuracy: 0.3123\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.9555 - accuracy: 0.3909 - val_loss: 1.8563 - val_accuracy: 0.4238\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.7203 - accuracy: 0.4539 - val_loss: 1.6023 - val_accuracy: 0.4741\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.5324 - accuracy: 0.4957 - val_loss: 1.4475 - val_accuracy: 0.5139\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.4057 - accuracy: 0.5339 - val_loss: 1.3402 - val_accuracy: 0.5613\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.3146 - accuracy: 0.5681 - val_loss: 1.2629 - val_accuracy: 0.5886\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 54us/step - loss: 1.2453 - accuracy: 0.5954 - val_loss: 1.2016 - val_accuracy: 0.6082\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 54us/step - loss: 1.1924 - accuracy: 0.6110 - val_loss: 1.1535 - val_accuracy: 0.6246\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1486 - accuracy: 0.6263 - val_loss: 1.1151 - val_accuracy: 0.6366\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.1127 - accuracy: 0.6361 - val_loss: 1.0821 - val_accuracy: 0.6430\n",
            "10000/10000 [==============================] - 1s 84us/step\n",
            "Model: 5 added. Resulting score: 0.6385999917984009\n",
            "Train model 6\n",
            "Weight init method: Glorot Normal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 62us/step - loss: 2.1489 - accuracy: 0.2374 - val_loss: 2.1709 - val_accuracy: 0.3153\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.8900 - accuracy: 0.4099 - val_loss: 1.7790 - val_accuracy: 0.4368\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.6595 - accuracy: 0.4798 - val_loss: 1.5443 - val_accuracy: 0.4992\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.4870 - accuracy: 0.5284 - val_loss: 1.4018 - val_accuracy: 0.5569\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.3677 - accuracy: 0.5663 - val_loss: 1.3039 - val_accuracy: 0.5802\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.2829 - accuracy: 0.5865 - val_loss: 1.2312 - val_accuracy: 0.5968\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 57us/step - loss: 1.2181 - accuracy: 0.6028 - val_loss: 1.1741 - val_accuracy: 0.6097\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1657 - accuracy: 0.6132 - val_loss: 1.1270 - val_accuracy: 0.6228\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1262 - accuracy: 0.6215 - val_loss: 1.0928 - val_accuracy: 0.6268\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.0926 - accuracy: 0.6308 - val_loss: 1.0591 - val_accuracy: 0.6364\n",
            "10000/10000 [==============================] - 1s 89us/step\n",
            "Model: 6 added. Resulting score: 0.6308000087738037\n",
            "Train model 7\n",
            "Weight init method: Glorot Uniform \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 3s 62us/step - loss: 2.2052 - accuracy: 0.2313 - val_loss: 2.1944 - val_accuracy: 0.2510\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.9934 - accuracy: 0.4254 - val_loss: 1.8982 - val_accuracy: 0.4678\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.7892 - accuracy: 0.4717 - val_loss: 1.6711 - val_accuracy: 0.5182\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.5965 - accuracy: 0.5199 - val_loss: 1.4888 - val_accuracy: 0.5487\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.4438 - accuracy: 0.5571 - val_loss: 1.3681 - val_accuracy: 0.5730\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.3371 - accuracy: 0.5780 - val_loss: 1.2790 - val_accuracy: 0.5913\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.2580 - accuracy: 0.5939 - val_loss: 1.2062 - val_accuracy: 0.6055\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 56us/step - loss: 1.1957 - accuracy: 0.6085 - val_loss: 1.1530 - val_accuracy: 0.6163\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1441 - accuracy: 0.6205 - val_loss: 1.1035 - val_accuracy: 0.6293\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 3s 55us/step - loss: 1.1026 - accuracy: 0.6303 - val_loss: 1.0669 - val_accuracy: 0.6367\n",
            "10000/10000 [==============================] - 1s 84us/step\n",
            "Model: 7 added. Resulting score: 0.6313999891281128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fGT6jV-hcLbJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CurcmjMCcrJI"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yvZLQyb5cg7R",
        "outputId": "4a7987be-45bb-4e5c-e38c-9f3f9d952bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "accuracy_df[\"weight_init_method\"] = initializer\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy.csv\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>weight_init_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6318</td>\n",
              "      <td>Zero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6315</td>\n",
              "      <td>Ones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6441</td>\n",
              "      <td>Random Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6165</td>\n",
              "      <td>Random Uniform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6557</td>\n",
              "      <td>Identity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.6386</td>\n",
              "      <td>Orthogonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.6308</td>\n",
              "      <td>Glorot Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.6314</td>\n",
              "      <td>Glorot Uniform</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy weight_init_method\n",
              "0    0.6318               Zero\n",
              "1    0.6315               Ones\n",
              "2    0.6441      Random Normal\n",
              "3    0.6165     Random Uniform\n",
              "4    0.6557           Identity\n",
              "5    0.6386         Orthogonal\n",
              "6    0.6308      Glorot Normal\n",
              "7    0.6314     Glorot Uniform"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXq8Uj3lenzH",
        "outputId": "4525b4a5-233d-40c8-e1ce-69067ac4c06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# remove first row\n",
        "accuracy_df = accuracy_df.iloc[1:]\n",
        "\n",
        "accuracy_df.plot(x=\"weight_init_method\", y=\"Accuracy\",rot = 90)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37chbRgZDXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "267cbe97-4038-4dcc-ed08-11234408bacf"
      },
      "source": [
        "classified = []\n",
        "\n",
        "for prediction in tqdm(predictions):\n",
        "    classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 257.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMfc-h8xAYQu"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAky42lMV102",
        "outputId": "93401eae-e6cd-40ee-8ecd-13026362efce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(classified):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(classified):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "correlation_matrix_df = pd.DataFrame(correlation_matrix)\n",
        "correlation_matrix_df.columns = initializer\n",
        "correlation_matrix_df.index = initializer\n",
        "display(correlation_matrix_df)\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zero</th>\n",
              "      <th>Ones</th>\n",
              "      <th>Random Normal</th>\n",
              "      <th>Random Uniform</th>\n",
              "      <th>Identity</th>\n",
              "      <th>Orthogonal</th>\n",
              "      <th>Glorot Normal</th>\n",
              "      <th>Glorot Uniform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Zero</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.700217</td>\n",
              "      <td>0.685318</td>\n",
              "      <td>0.675400</td>\n",
              "      <td>0.699178</td>\n",
              "      <td>0.693255</td>\n",
              "      <td>0.740508</td>\n",
              "      <td>0.689705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ones</th>\n",
              "      <td>0.700217</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.673483</td>\n",
              "      <td>0.687585</td>\n",
              "      <td>0.682902</td>\n",
              "      <td>0.747903</td>\n",
              "      <td>0.720576</td>\n",
              "      <td>0.729075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Normal</th>\n",
              "      <td>0.685318</td>\n",
              "      <td>0.673483</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.721691</td>\n",
              "      <td>0.690860</td>\n",
              "      <td>0.672914</td>\n",
              "      <td>0.689018</td>\n",
              "      <td>0.702297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Uniform</th>\n",
              "      <td>0.675400</td>\n",
              "      <td>0.687585</td>\n",
              "      <td>0.721691</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.654721</td>\n",
              "      <td>0.677691</td>\n",
              "      <td>0.695972</td>\n",
              "      <td>0.747492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Identity</th>\n",
              "      <td>0.699178</td>\n",
              "      <td>0.682902</td>\n",
              "      <td>0.690860</td>\n",
              "      <td>0.654721</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.673224</td>\n",
              "      <td>0.689868</td>\n",
              "      <td>0.654792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orthogonal</th>\n",
              "      <td>0.693255</td>\n",
              "      <td>0.747903</td>\n",
              "      <td>0.672914</td>\n",
              "      <td>0.677691</td>\n",
              "      <td>0.673224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.737458</td>\n",
              "      <td>0.687297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Normal</th>\n",
              "      <td>0.740508</td>\n",
              "      <td>0.720576</td>\n",
              "      <td>0.689018</td>\n",
              "      <td>0.695972</td>\n",
              "      <td>0.689868</td>\n",
              "      <td>0.737458</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.698471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Uniform</th>\n",
              "      <td>0.689705</td>\n",
              "      <td>0.729075</td>\n",
              "      <td>0.702297</td>\n",
              "      <td>0.747492</td>\n",
              "      <td>0.654792</td>\n",
              "      <td>0.687297</td>\n",
              "      <td>0.698471</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Zero      Ones  ...  Glorot Normal  Glorot Uniform\n",
              "Zero                 NaN  0.700217  ...       0.740508        0.689705\n",
              "Ones            0.700217       NaN  ...       0.720576        0.729075\n",
              "Random Normal   0.685318  0.673483  ...       0.689018        0.702297\n",
              "Random Uniform  0.675400  0.687585  ...       0.695972        0.747492\n",
              "Identity        0.699178  0.682902  ...       0.689868        0.654792\n",
              "Orthogonal      0.693255  0.747903  ...       0.737458        0.687297\n",
              "Glorot Normal   0.740508  0.720576  ...            NaN        0.698471\n",
              "Glorot Uniform  0.689705  0.729075  ...       0.698471             NaN\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.6971025480855594\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}