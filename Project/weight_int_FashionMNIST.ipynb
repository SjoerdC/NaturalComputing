{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weight_int_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed2ac9fc-d82d-4744-eee2-bb875d6b9ebd"
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "NUM_CHANNELS = 1\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"MNIST_weight_init\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9M4_-IaBOsn"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n9nJGd_BQ-r",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8QvEt97vF52"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JtJIUBsFKeRO",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "9a3e94fb-983d-4950-daf3-54beb99cda80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4SYRuKZaIwb",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBci5ba9hiaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIBGIrlkvOt0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EbiuqESLvTOY"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXFkx19XmqKe",
        "colab": {}
      },
      "source": [
        "def predict(models):\n",
        "    predictions = []\n",
        "\n",
        "    for m in tqdm(models):\n",
        "        predictions.append(np.argmax(m.predict(x_test), axis=1))\n",
        "\n",
        "    prediction = np.transpose(predictions)\n",
        "    prediction = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=prediction)\n",
        "\n",
        "    return accuracy_score(prediction, np.argmax(y_test, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqdcrD_vQ-Q"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "40c25dc0-0580-4f46-de08-95c37aa0e147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = [0]\n",
        "initializer = [\"Zero\",\"Ones\",\"Random Normal\",\"Random Uniform\",\"Identity\",\"Orthogonal\",\"Glorot Normal\",\"Glorot Uniform\"]\n",
        "for i in range(len(initializer)):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "    print(f\"Weight init method: {initializer[i]} \")\n",
        "    model = FashionMNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
        "    \n",
        "    for layer in model.layers: \n",
        "        if hasattr(layer, 'kernel_initializer'):\n",
        "            if(initializer[i] == \"Zero\"):\n",
        "                layer.kernel_initializer = initializers.Zeros()\n",
        "            elif(initializer[i] == \"Ones\"):\n",
        "                layer.kernel_initializer = initializers.Ones()\n",
        "            elif(initializer[i] == \"Random Normal\"):\n",
        "                layer.kernel_initializer = initializers.RandomNormal()\n",
        "            elif(initializer[i] == \"Random Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.RandomUniform()\n",
        "            elif(initializer[i] == \"Identity\"):\n",
        "                layer.kernel_initializer = initializers.Identity()\n",
        "            elif(initializer[i] == \"Orthogonal\"):\n",
        "                layer.kernel_initializer = initializers.Orthogonal()\n",
        "            elif(initializer[i] == \"Glorot Normal\"):\n",
        "                layer.kernel_initializer = initializers.GlorotNormal()\n",
        "            elif(initializer[i] == \"Glorot Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.GlorotUnifrom()\n",
        "          \n",
        "    es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', min_delta=0.01, patience=3)\n",
        "    model.fit(x_train,y_train,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = EPOCHS,\n",
        "              validation_data = (x_test,y_test),\n",
        "              shuffle = True,\n",
        "              callbacks=[es])\n",
        "    models.append(model)\n",
        "\n",
        "    acc = predict(models)\n",
        "\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 0\n",
            "Weight init method: Zero \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 10s 203us/step - loss: 2.1487 - accuracy: 0.2455 - val_loss: 2.1708 - val_accuracy: 0.2841\n",
            "Epoch 2/20\n",
            " 2432/48000 [>.............................] - ETA: 3s - loss: 1.9953 - accuracy: 0.3573"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8997 - accuracy: 0.3768 - val_loss: 1.8102 - val_accuracy: 0.4124\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.7049 - accuracy: 0.4332 - val_loss: 1.6138 - val_accuracy: 0.4573\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.5538 - accuracy: 0.4789 - val_loss: 1.4793 - val_accuracy: 0.5064\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4304 - accuracy: 0.5273 - val_loss: 1.3724 - val_accuracy: 0.5483\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.3392 - accuracy: 0.5654 - val_loss: 1.2922 - val_accuracy: 0.5834\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2675 - accuracy: 0.5879 - val_loss: 1.2317 - val_accuracy: 0.6032\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2105 - accuracy: 0.6040 - val_loss: 1.1830 - val_accuracy: 0.6148\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1630 - accuracy: 0.6165 - val_loss: 1.1413 - val_accuracy: 0.6202\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1241 - accuracy: 0.6252 - val_loss: 1.1038 - val_accuracy: 0.6317\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0904 - accuracy: 0.6346 - val_loss: 1.0768 - val_accuracy: 0.6371\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0611 - accuracy: 0.6418 - val_loss: 1.0487 - val_accuracy: 0.6465\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0359 - accuracy: 0.6499 - val_loss: 1.0249 - val_accuracy: 0.6502\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0117 - accuracy: 0.6579 - val_loss: 1.0065 - val_accuracy: 0.6508\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9920 - accuracy: 0.6622 - val_loss: 0.9843 - val_accuracy: 0.6633\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 0.9738 - accuracy: 0.6682 - val_loss: 0.9687 - val_accuracy: 0.6701\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 0.9564 - accuracy: 0.6771 - val_loss: 0.9584 - val_accuracy: 0.6718\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 0.9403 - accuracy: 0.6811 - val_loss: 0.9372 - val_accuracy: 0.6780\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9259 - accuracy: 0.6844 - val_loss: 0.9258 - val_accuracy: 0.6814\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9133 - accuracy: 0.6892 - val_loss: 0.9126 - val_accuracy: 0.6840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 0 added. Resulting score: 0.684\n",
            "Train model 1\n",
            "Weight init method: Ones \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.2546 - accuracy: 0.2019 - val_loss: 2.2334 - val_accuracy: 0.3373\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.9715 - accuracy: 0.3614 - val_loss: 1.8556 - val_accuracy: 0.4184\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7264 - accuracy: 0.4407 - val_loss: 1.6146 - val_accuracy: 0.4839\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.5381 - accuracy: 0.5052 - val_loss: 1.4571 - val_accuracy: 0.5396\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 1.4011 - accuracy: 0.5479 - val_loss: 1.3431 - val_accuracy: 0.5672\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3037 - accuracy: 0.5785 - val_loss: 1.2626 - val_accuracy: 0.5902\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2304 - accuracy: 0.6001 - val_loss: 1.1995 - val_accuracy: 0.6138\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1712 - accuracy: 0.6180 - val_loss: 1.1491 - val_accuracy: 0.6232\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1252 - accuracy: 0.6299 - val_loss: 1.1071 - val_accuracy: 0.6350\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0864 - accuracy: 0.6416 - val_loss: 1.0739 - val_accuracy: 0.6432\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0520 - accuracy: 0.6525 - val_loss: 1.0424 - val_accuracy: 0.6559\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0238 - accuracy: 0.6601 - val_loss: 1.0182 - val_accuracy: 0.6546\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9992 - accuracy: 0.6671 - val_loss: 0.9938 - val_accuracy: 0.6674\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9770 - accuracy: 0.6743 - val_loss: 0.9748 - val_accuracy: 0.6747\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9562 - accuracy: 0.6805 - val_loss: 0.9539 - val_accuracy: 0.6827\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9385 - accuracy: 0.6856 - val_loss: 0.9373 - val_accuracy: 0.6890\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9207 - accuracy: 0.6933 - val_loss: 0.9216 - val_accuracy: 0.6955\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9059 - accuracy: 0.6977 - val_loss: 0.9092 - val_accuracy: 0.6969\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.8906 - accuracy: 0.7054 - val_loss: 0.8940 - val_accuracy: 0.7073\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8775 - accuracy: 0.7107 - val_loss: 0.8812 - val_accuracy: 0.7117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:01<00:00,  1.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 1 added. Resulting score: 0.6987\n",
            "Train model 2\n",
            "Weight init method: Random Normal \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.1713 - accuracy: 0.1981 - val_loss: 2.1893 - val_accuracy: 0.3017\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.8716 - accuracy: 0.4382 - val_loss: 1.7423 - val_accuracy: 0.4626\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6188 - accuracy: 0.4941 - val_loss: 1.5204 - val_accuracy: 0.5150\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4609 - accuracy: 0.5376 - val_loss: 1.3975 - val_accuracy: 0.5486\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3521 - accuracy: 0.5684 - val_loss: 1.3043 - val_accuracy: 0.5802\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2705 - accuracy: 0.5914 - val_loss: 1.2318 - val_accuracy: 0.6032\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2044 - accuracy: 0.6115 - val_loss: 1.1754 - val_accuracy: 0.6183\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1494 - accuracy: 0.6270 - val_loss: 1.1264 - val_accuracy: 0.6344\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1032 - accuracy: 0.6425 - val_loss: 1.0826 - val_accuracy: 0.6453\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0627 - accuracy: 0.6535 - val_loss: 1.0476 - val_accuracy: 0.6555\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0284 - accuracy: 0.6647 - val_loss: 1.0169 - val_accuracy: 0.6686\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9984 - accuracy: 0.6732 - val_loss: 0.9883 - val_accuracy: 0.6771\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9710 - accuracy: 0.6831 - val_loss: 0.9649 - val_accuracy: 0.6826\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9476 - accuracy: 0.6910 - val_loss: 0.9434 - val_accuracy: 0.6897\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9250 - accuracy: 0.6983 - val_loss: 0.9226 - val_accuracy: 0.6960\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9042 - accuracy: 0.7048 - val_loss: 0.9027 - val_accuracy: 0.6997\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.8872 - accuracy: 0.7102 - val_loss: 0.8871 - val_accuracy: 0.7054\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.8701 - accuracy: 0.7151 - val_loss: 0.8717 - val_accuracy: 0.7126\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.8561 - accuracy: 0.7189 - val_loss: 0.8578 - val_accuracy: 0.7181\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8416 - accuracy: 0.7233 - val_loss: 0.8501 - val_accuracy: 0.7177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 2 added. Resulting score: 0.717\n",
            "Train model 3\n",
            "Weight init method: Random Unifrom \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 2.1491 - accuracy: 0.2372 - val_loss: 2.1718 - val_accuracy: 0.3124\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.8905 - accuracy: 0.4095 - val_loss: 1.7846 - val_accuracy: 0.4421\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.6600 - accuracy: 0.4795 - val_loss: 1.5538 - val_accuracy: 0.5004\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.4873 - accuracy: 0.5284 - val_loss: 1.4132 - val_accuracy: 0.5571\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.3679 - accuracy: 0.5661 - val_loss: 1.3173 - val_accuracy: 0.5773\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2830 - accuracy: 0.5864 - val_loss: 1.2463 - val_accuracy: 0.5929\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2182 - accuracy: 0.6026 - val_loss: 1.1917 - val_accuracy: 0.6024\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.1658 - accuracy: 0.6132 - val_loss: 1.1456 - val_accuracy: 0.6135\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1263 - accuracy: 0.6215 - val_loss: 1.1116 - val_accuracy: 0.6221\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.0927 - accuracy: 0.6308 - val_loss: 1.0790 - val_accuracy: 0.6306\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.0661 - accuracy: 0.6374 - val_loss: 1.0553 - val_accuracy: 0.6362\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0432 - accuracy: 0.6443 - val_loss: 1.0336 - val_accuracy: 0.6424\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0225 - accuracy: 0.6484 - val_loss: 1.0169 - val_accuracy: 0.6457\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0056 - accuracy: 0.6538 - val_loss: 0.9995 - val_accuracy: 0.6528\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9901 - accuracy: 0.6587 - val_loss: 0.9847 - val_accuracy: 0.6567\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9762 - accuracy: 0.6635 - val_loss: 0.9708 - val_accuracy: 0.6627\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9626 - accuracy: 0.6669 - val_loss: 0.9592 - val_accuracy: 0.6656\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9507 - accuracy: 0.6717 - val_loss: 0.9469 - val_accuracy: 0.6658\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9395 - accuracy: 0.6760 - val_loss: 0.9370 - val_accuracy: 0.6776\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9297 - accuracy: 0.6802 - val_loss: 0.9262 - val_accuracy: 0.6803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:02<00:00,  1.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 3 added. Resulting score: 0.7118\n",
            "Train model 4\n",
            "Weight init method: Identity \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 84us/step - loss: 2.1553 - accuracy: 0.2131 - val_loss: 2.1742 - val_accuracy: 0.2281\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8659 - accuracy: 0.3871 - val_loss: 1.7598 - val_accuracy: 0.4280\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.6311 - accuracy: 0.4780 - val_loss: 1.5296 - val_accuracy: 0.5047\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.4639 - accuracy: 0.5305 - val_loss: 1.3891 - val_accuracy: 0.5523\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.3457 - accuracy: 0.5679 - val_loss: 1.2935 - val_accuracy: 0.5817\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2604 - accuracy: 0.5893 - val_loss: 1.2186 - val_accuracy: 0.5971\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1964 - accuracy: 0.6036 - val_loss: 1.1640 - val_accuracy: 0.6115\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.1464 - accuracy: 0.6159 - val_loss: 1.1220 - val_accuracy: 0.6229\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.1068 - accuracy: 0.6270 - val_loss: 1.0864 - val_accuracy: 0.6304\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0726 - accuracy: 0.6345 - val_loss: 1.0569 - val_accuracy: 0.6379\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0446 - accuracy: 0.6433 - val_loss: 1.0326 - val_accuracy: 0.6449\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0199 - accuracy: 0.6509 - val_loss: 1.0082 - val_accuracy: 0.6496\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9970 - accuracy: 0.6573 - val_loss: 0.9891 - val_accuracy: 0.6546\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9761 - accuracy: 0.6638 - val_loss: 0.9715 - val_accuracy: 0.6665\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9571 - accuracy: 0.6716 - val_loss: 0.9495 - val_accuracy: 0.6736\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9395 - accuracy: 0.6778 - val_loss: 0.9324 - val_accuracy: 0.6782\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9224 - accuracy: 0.6843 - val_loss: 0.9182 - val_accuracy: 0.6818\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 0.9060 - accuracy: 0.6908 - val_loss: 0.9031 - val_accuracy: 0.6882\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 0.8918 - accuracy: 0.6960 - val_loss: 0.8861 - val_accuracy: 0.6971\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 0.8760 - accuracy: 0.7014 - val_loss: 0.8737 - val_accuracy: 0.7015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:02<00:00,  1.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 4 added. Resulting score: 0.7145\n",
            "Train model 5\n",
            "Weight init method: Orthogonal \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.2271 - accuracy: 0.2100 - val_loss: 2.2119 - val_accuracy: 0.1924\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.9787 - accuracy: 0.4407 - val_loss: 1.8755 - val_accuracy: 0.4601\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7214 - accuracy: 0.4897 - val_loss: 1.5990 - val_accuracy: 0.5052\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.5135 - accuracy: 0.5258 - val_loss: 1.4285 - val_accuracy: 0.5496\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 1.3808 - accuracy: 0.5615 - val_loss: 1.3201 - val_accuracy: 0.5882\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2868 - accuracy: 0.5920 - val_loss: 1.2424 - val_accuracy: 0.6065\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2153 - accuracy: 0.6141 - val_loss: 1.1808 - val_accuracy: 0.6295\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1579 - accuracy: 0.6308 - val_loss: 1.1293 - val_accuracy: 0.6369\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1111 - accuracy: 0.6437 - val_loss: 1.0882 - val_accuracy: 0.6481\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0725 - accuracy: 0.6539 - val_loss: 1.0532 - val_accuracy: 0.6556\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0388 - accuracy: 0.6645 - val_loss: 1.0247 - val_accuracy: 0.6650\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0113 - accuracy: 0.6713 - val_loss: 0.9988 - val_accuracy: 0.6719\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9868 - accuracy: 0.6782 - val_loss: 0.9791 - val_accuracy: 0.6743\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9646 - accuracy: 0.6861 - val_loss: 0.9575 - val_accuracy: 0.6857\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9462 - accuracy: 0.6910 - val_loss: 0.9374 - val_accuracy: 0.6942\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9278 - accuracy: 0.6953 - val_loss: 0.9209 - val_accuracy: 0.6969\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9107 - accuracy: 0.7017 - val_loss: 0.9057 - val_accuracy: 0.7016\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8952 - accuracy: 0.7047 - val_loss: 0.8934 - val_accuracy: 0.7049\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 0.8813 - accuracy: 0.7107 - val_loss: 0.8800 - val_accuracy: 0.7083\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.8686 - accuracy: 0.7139 - val_loss: 0.8678 - val_accuracy: 0.7147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 5 added. Resulting score: 0.7177\n",
            "Train model 6\n",
            "Weight init method: Glorot Normal \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 83us/step - loss: 2.1850 - accuracy: 0.2416 - val_loss: 2.1911 - val_accuracy: 0.3165\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.9054 - accuracy: 0.3821 - val_loss: 1.7935 - val_accuracy: 0.4465\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6647 - accuracy: 0.4481 - val_loss: 1.5595 - val_accuracy: 0.4838\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.4961 - accuracy: 0.5094 - val_loss: 1.4239 - val_accuracy: 0.5352\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3773 - accuracy: 0.5587 - val_loss: 1.3249 - val_accuracy: 0.5745\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2919 - accuracy: 0.5818 - val_loss: 1.2521 - val_accuracy: 0.5949\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.2269 - accuracy: 0.5975 - val_loss: 1.1950 - val_accuracy: 0.6027\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1758 - accuracy: 0.6084 - val_loss: 1.1513 - val_accuracy: 0.6115\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1332 - accuracy: 0.6190 - val_loss: 1.1139 - val_accuracy: 0.6183\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0995 - accuracy: 0.6253 - val_loss: 1.0833 - val_accuracy: 0.6272\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0696 - accuracy: 0.6324 - val_loss: 1.0561 - val_accuracy: 0.6338\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0445 - accuracy: 0.6387 - val_loss: 1.0348 - val_accuracy: 0.6409\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0221 - accuracy: 0.6460 - val_loss: 1.0129 - val_accuracy: 0.6486\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0020 - accuracy: 0.6525 - val_loss: 0.9949 - val_accuracy: 0.6546\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9841 - accuracy: 0.6593 - val_loss: 0.9777 - val_accuracy: 0.6604\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9676 - accuracy: 0.6646 - val_loss: 0.9646 - val_accuracy: 0.6648\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9524 - accuracy: 0.6699 - val_loss: 0.9475 - val_accuracy: 0.6714\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9376 - accuracy: 0.6774 - val_loss: 0.9332 - val_accuracy: 0.6821\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9237 - accuracy: 0.6823 - val_loss: 0.9202 - val_accuracy: 0.6818\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9119 - accuracy: 0.6891 - val_loss: 0.9117 - val_accuracy: 0.6901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:03<00:00,  1.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 6 added. Resulting score: 0.7144\n",
            "Train model 7\n",
            "Weight init method: Glorot Uniform \n",
            "Train on 48000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.1557 - accuracy: 0.2471 - val_loss: 2.1867 - val_accuracy: 0.3487\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8822 - accuracy: 0.4099 - val_loss: 1.7901 - val_accuracy: 0.4467\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6593 - accuracy: 0.4705 - val_loss: 1.5631 - val_accuracy: 0.5091\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.4958 - accuracy: 0.5174 - val_loss: 1.4264 - val_accuracy: 0.5545\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3793 - accuracy: 0.5612 - val_loss: 1.3258 - val_accuracy: 0.5750\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2909 - accuracy: 0.5936 - val_loss: 1.2487 - val_accuracy: 0.6040\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.2206 - accuracy: 0.6149 - val_loss: 1.1879 - val_accuracy: 0.6230\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1647 - accuracy: 0.6316 - val_loss: 1.1381 - val_accuracy: 0.6324\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1179 - accuracy: 0.6436 - val_loss: 1.0980 - val_accuracy: 0.6407\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0787 - accuracy: 0.6536 - val_loss: 1.0615 - val_accuracy: 0.6545\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.0455 - accuracy: 0.6613 - val_loss: 1.0315 - val_accuracy: 0.6578\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.0163 - accuracy: 0.6702 - val_loss: 1.0073 - val_accuracy: 0.6666\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9913 - accuracy: 0.6777 - val_loss: 0.9839 - val_accuracy: 0.6759\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9670 - accuracy: 0.6854 - val_loss: 0.9618 - val_accuracy: 0.6819\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 0.9475 - accuracy: 0.6900 - val_loss: 0.9446 - val_accuracy: 0.6863\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.9286 - accuracy: 0.6968 - val_loss: 0.9304 - val_accuracy: 0.6892\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.9118 - accuracy: 0.7022 - val_loss: 0.9085 - val_accuracy: 0.7019\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8959 - accuracy: 0.7066 - val_loss: 0.8947 - val_accuracy: 0.7056\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 0.8805 - accuracy: 0.7120 - val_loss: 0.8794 - val_accuracy: 0.7090\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 0.8647 - accuracy: 0.7175 - val_loss: 0.8672 - val_accuracy: 0.7171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 7 added. Resulting score: 0.7195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fGT6jV-hcLbJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CurcmjMCcrJI"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yvZLQyb5cg7R",
        "outputId": "50e316cf-d67d-4061-8870-ad9f3be9d092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "initializer.insert(0, \"None\")\n",
        "accuracy_df[\"weight_init_method\"] = initializer\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy.csv\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>weight_init_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6840</td>\n",
              "      <td>Zero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6987</td>\n",
              "      <td>Ones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.7170</td>\n",
              "      <td>Random Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.7118</td>\n",
              "      <td>Random Unifrom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.7145</td>\n",
              "      <td>Identity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7177</td>\n",
              "      <td>Orthogonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.7144</td>\n",
              "      <td>Glorot Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.7195</td>\n",
              "      <td>Glorot Uniform</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy weight_init_method\n",
              "0    0.0000               None\n",
              "1    0.6840               Zero\n",
              "2    0.6987               Ones\n",
              "3    0.7170      Random Normal\n",
              "4    0.7118     Random Unifrom\n",
              "5    0.7145           Identity\n",
              "6    0.7177         Orthogonal\n",
              "7    0.7144      Glorot Normal\n",
              "8    0.7195     Glorot Uniform"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXq8Uj3lenzH",
        "outputId": "5a846b72-40a3-46ab-b2d7-faa68792bbac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy_df.plot(x=\"weight_init_method\", y=\"Accuracy\",rot = 90)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFRCAYAAABkAlbWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZxcdZnv8c+3t3S2zkaTQBYSMQECSUQDKKDiwogzsokKyDK4gBvI1dERxxEB73UERxkX5l4YB8SFRUAhKMrIoqKAJAHsJgEkBmKqIRCyVGfr9PbcP86pTnWlO12drqrfqarn/Xr1q+ucOl31pFP91K+e3yYzwznnXPmrCR2Ac865wvCE7pxzFcITunPOVQhP6M45VyE8oTvnXIWoC/XE++yzj82ePTvU0zvnXFlavnz5q2bWPNB9wRL67NmzWbZsWaind865siRpzWD3ecnFOecqhCd055yrEJ7QnXOuQnhCd865CuEJ3TnnKoQndOecqxCe0J1zrkIEG4funHOVorfX6OjuYUdnDx3dvXR0Rbd3dvewozM+7uqhoyu6/8jZkzlo2viCx+EJ3RWdmbFxWyd/27idv23cztqN21m7cQfr2juor61hdEMto+traKyvZXR9LaPi733nGmpprK/tu390fS2N8X1999fVUFdbmR84zYyuHqO7t5euHqOrpzf66jY6M7fjr87urPuzr+3ppbPH6OrOOe7ppau7l+7e+LG6d/1sv8fOea7urPu7e4zaGlFfW0NDXQ31tYq/R18NtdG5+toa6uv6Hzf0Hcdfdep/HD9W37nM42dd01CnrNu7nrOuVnR29+5KpF09dHRlJ9fc++Lk293/+ihJ70rWO7OSc+ZcZ3fvsP5Pv3ryoZ7QXXJ1dPWQ2rSDtXHS7p+8t7Ots6ff9c3jRzGtqZGunl52dvf/o9k5zD+OjPpa9SX9xpzEHyX97DeHmv7XxW8KoxtqGVVXS0+cPDNJtLvf7SgBZpJZV2/0vbunl67e+P4e67udeZzuOIF2D3S+7/7dr+3pLd4mNJnEtyv5Kk6aWcfx7aaGeuprtFtira0RvWZ9byad3Zk3jOj7jq4e2jt2nc+80XR292a9SRT33zkcmddR7uuksb6WCaPrGd00KjqOX0+jcl9LWY2N7HOZa0bV19DUWF+U2PNK6JJOAL4N1ALfN7Ov59x/NfC2+HAMsK+ZTSxkoC6s3l5j/dadAybsv23czsvtO/td31hfw6zJY5g1eQxvOnAKsyaPYeakMcyaMoYZk0YzpmHwl15vr0VJPtMKyvn4mn1+Z9/9vVlvCNH37FbYpm2d0XWZVlr8BtLVM7IkUiOoq62hvkbR91pRV7MrSdb1Ox/dbqyvoW5U3RDXxt/73d49yUYt3qzj7NZwTuu1r7Vct+v5JI3o319IPb27f7ro9+Yw5CeSzJtE5s22l4a6mr7km/2mnZ1oR2W/0Zf5J70hE7qkWuAa4HggBSyVtMTMVmauMbPPZF1/EXB4EWJ1RbZtZzdrN23nbxu2szantb124/Z+LWcJpjU1MnPyGN48t7kvec+cPIaZk0fTPG7UXieLmhpFZZiG2kL90wbV1dPb76N45nZUQoiSaF3cKq2rFfVxAs7crqlJTkIsd7U1orYmSqxu7+TTQj8SWGVmqwEk3QKcDKwc5Pozga8UJjxXSD29xrr2jihhZxL1pl0J+9Wtnf2uHzeqjlmTx/Da5nG87aDmvoQ9a/IYpk8azai68v/Dy7RcxzeGjsS5kcsnoU8H1mYdp4CjBrpQ0gHAHOCBkYfmhiPT8biuvYOX2ztYl94Z3U538GJ6B6lNO0ht2t6vxFBbI/af2MisyWM4fv7UqHU9aUxfa3vimPpEfSR3zu1ZoTtFzwBuN7Oege6UdAFwAcCsWbMK/NSVq7O7l5czibq9g3Xp+Cvr3MvtO3fraZegedwopk1oZP7+TZxw2LRdpZFJY9hvYiP1ZVwvdM71l09CbwNmZh3PiM8N5AzgU4M9kJldB1wHsHjx4mR0aQdkZrTv6I6SdNyaXpeTtF9u72DDts7dfraxvoZpTY1MbWrkDbMmMXVCI9Oaoq/M7ebxozxhO1dF8knoS4G5kuYQJfIzgA/mXiTpYGAS8EhBIyxT3T29rN+6s19rOjtpv9we3beja/cPM1PGNjC1qZFpExpZNHNilKgnjGLahNF9SbtpdJ2XQ5xz/QyZ0M2sW9KFwL1EwxavN7MVkq4AlpnZkvjSM4BbzKwqW97Pv7qNK3/1DC+md7Au3cGrW3eSO6y2obaGfZui8dfz92/i7Qfvy34TGvuS97SmRvZtGlURnY3OudLLq4ZuZvcA9+ScuzTn+LLChVV+fvZ4iv9ZuY5j5zZz8LTx/UofU5sa2W9CI5PGNPgwN+dc0fhM0QJpbUszb+p4fvjhI0OH4pyrUt5jVgBmRmsqzcIZE0KH4pyrYp7QC+DFdDQSZcEMX+3AOReOJ/QCaE1tBmDBdG+hO+fC8YReAC2pNHU14uAiLIfpnHP58oReAK1taQ6aNt4XFXLOBeUJfYTMjNY27xB1zoXnCX2EUpt2sHl7Fwume4eocy4sT+gj1JJKA3gL3TkXnCf0EWpp20xDbQ3zpnqHqHMuLE/oI9SaSnPwfuNpqPNfpXMuLM9CI5DpEPXx5865JPCEPgJrNmxnS0e318+dc4ngCX0EWtqiDlEf4eKcSwJP6CPQmtpMQ10Nc6eOCx2Kc855Qh+JllSa+fs1+TZvzrlE8Ey0l3p7jRUvtnv93DmXGJ7Q99LzG7axdWe3j3BxziWGJ/S91No3Q9Q7RJ1zyZBXQpd0gqRnJa2SdMkg13xA0kpJKyTdVNgwk6cllWZ0fS0HNo8NHYpzzgF57CkqqRa4BjgeSAFLJS0xs5VZ18wFvggcY2abJO1brICTorVtM/P3b6LOO0SdcwmRTzY6ElhlZqvNrBO4BTg555rzgWvMbBOAmb1S2DCTpafXeKqt3evnzrlEySehTwfWZh2n4nPZ5gHzJP1R0qOSThjogSRdIGmZpGXr16/fu4gT4K/rt7Kjq8dHuDjnEqVQ9YI6YC5wHHAm8F+SdustNLPrzGyxmS1ubm4u0FOXXqsvmeucS6B8EnobMDPreEZ8LlsKWGJmXWb2PPAXogRfkVrb0oxtqGXOPj5D1DmXHPkk9KXAXElzJDUAZwBLcq65k6h1jqR9iEowqwsYZ6K0pDZz6PQJ1NYodCjOOddnyIRuZt3AhcC9wNPAT81shaQrJJ0UX3YvsEHSSuBB4PNmtqFYQYfU3dPLihe9Q9Q5lzxDDlsEMLN7gHtyzl2adduAz8ZfFe25V7ays7vX6+fOucTxQdTDlOkQ9Ra6cy5pPKEPU2tbmvGj6pg9xWeIOueSxRP6MLW0pTls+gRqvEPUOZcwntCHobO7l6df8iVznXPJ5Al9GP7y8hY6u3s5zOvnzrkE8oQ+DK1tPkPUOZdcntCHoSWVpqmxjlmTx4QOxTnnduMJfRieakuzcMZEJO8Qdc4ljyf0PO3s7uGZde0s8HKLcy6hPKHn6dl1W+jqMRZ6h6hzLqE8oeepJZ4h6iNcnHNJ5Qk9T62pNJPG1DNj0ujQoTjn3IA8oeeppS3NAu8Qdc4lmCf0PHR09fDcy1u8fu6cSzRP6Hl4+qV2unvNR7g45xLNE3oefIaoc64ceELPQ0sqzT7jGpjW1Bg6FOecG5Qn9Dy0ptIsmD7BO0Sdc4mWV0KXdIKkZyWtknTJAPefJ2m9pCfjr48WPtQwtnd289wrW1gwY2LoUJxzbo+G3FNUUi1wDXA8kAKWSlpiZitzLr3VzC4sQoxBPf1SO72Gj3BxziVePi30I4FVZrbazDqBW4CTixtWcmRmiPoIF+dc0uWT0KcDa7OOU/G5XKdJapF0u6SZBYkuAVpTaaY2jWKqd4g65xKuUJ2idwOzzWwh8BvgxoEuknSBpGWSlq1fv75AT11cLW1Rh6hzziVdPgm9Dchucc+Iz/Uxsw1mtjM+/D7whoEeyMyuM7PFZra4ubl5b+Itqa07u/nr+q0smO4dos655MsnoS8F5kqaI6kBOANYkn2BpP2yDk8Cni5ciOGsaEtj5hOKnHPlYchRLmbWLelC4F6gFrjezFZIugJYZmZLgE9LOgnoBjYC5xUx5pLJzBD1JXOdc+VgyIQOYGb3APfknLs06/YXgS8WNrTwWtvS7D+hkebxo0KH4pxzQ/KZonvQmkp769w5VzY8oQ+ivaOL1a9u8/q5c65seEIfxFNtmQlFPsLFOVcePKEPoi+he8nFOVcmPKEPoiWVZsak0Uwe2xA6FOecy4sn9EG0tqW9fu6cKyue0AeQ3t7Fmg3bfYSLc66seEIfQN+Wcz7l3zlXRjyhD6ClbTPgHaLOufLiCX0AT7WlOWDKGCaMqQ8dinPO5c0T+gBaUr5krnOu/HhCz7FxWyepTTt8hItzrux4Qs/hKyw658qVJ/QcramoQ9QTunOu3HhCz9GSSvOafcbS1Ogdos658uIJPcdTbWkWeP3cOVeGPKFnWb9lJy+mO3yEi3OuLHlCz5JZYXGhL5nrnCtDntCztKTSSHDo/k2hQ3HOuWHLK6FLOkHSs5JWSbpkD9edJskkLS5ciKXT2raZA5vHMXZUXlutOudcogyZ0CXVAtcA7wbmA2dKmj/AdeOBi4E/FTrIUmlJpVno9XPnXJnKp4V+JLDKzFabWSdwC3DyANd9FbgS6ChgfCXzcnsHr2zZ6SNcnHNlK5+EPh1Ym3Wcis/1kfR6YKaZ/XJPDyTpAknLJC1bv379sIMtptZUpkPUE7pzrjyNuFNUUg3wLeCfhrrWzK4zs8Vmtri5uXmkT11QLW1pagTz9/OE7pwrT/kk9DZgZtbxjPhcxnjgMOC3kl4A3ggsKbeO0dbUZubuO57RDbWhQ3HOub2ST0JfCsyVNEdSA3AGsCRzp5mlzWwfM5ttZrOBR4GTzGxZUSIuAjOj1WeIOufK3JAJ3cy6gQuBe4GngZ+a2QpJV0g6qdgBlsJL6Q5e3drp9XPnXFnLa8C1md0D3JNz7tJBrj1u5GGVVmbJXJ/y75wrZz5TlGiES12NOGQ/nyHqnCtfntCJRrjMmzqexnrvEHXOla+qT+hmRmtqs5dbnHNlr+oTemrTDjZt7/IRLs65slf1Cb21zWeIOucqgyf0tjT1teKgaeNDh+KccyPiCT2V5uBpTYyq8w5R51x5q+qEbma0pDZ7/dw5VxGqOqH/beN22ju6fYSLc64iVHVCb0n5DFHnXOWo6oTe2pamoa6GeVO9Q9Q5V/6qO6Gn0hyyXxMNdVX9a3DOVYiqzWS9vcZTbb6HqHOuclRtQn9hwza27PQOUedc5ajahN63ZK4PWXTOVYiqTegtqTSj6mqYu++40KE451xBVG1Cb02lOXT/Jupqq/ZX4JyrMFWZzXp6jRUvplk4Y2LoUJxzrmDySuiSTpD0rKRVki4Z4P6PS2qV9KSkP0iaX/hQC+f5V7eyrbPHO0SdcxVlyIQuqRa4Bng3MB84c4CEfZOZLTCz1wFXAd8qeKQF1DdD1DtEnXMVJJ8W+pHAKjNbbWadwC3AydkXmFl71uFYwAoXYuG1pNKMrq/lwGbvEHXOVY66PK6ZDqzNOk4BR+VeJOlTwGeBBuDtBYmuSFrb0hw2vYnaGoUOxTnnCqZgnaJmdo2ZHQh8AfjXga6RdIGkZZKWrV+/vlBPPSzdPb2sfLGdBdO9Q9Q5V1nySehtwMys4xnxucHcApwy0B1mdp2ZLTazxc3NzflHWUB/Xb+NHV09vuWcc67i5JPQlwJzJc2R1ACcASzJvkDS3KzDfwCeK1yIhdWS2gx4h6hzrvIMWUM3s25JFwL3ArXA9Wa2QtIVwDIzWwJcKOmdQBewCfjHYgY9Eq1tacaNqmPOlLGhQ3HOuYLKp1MUM7sHuCfn3KVZty8ucFxF0xLPEK3xDlHnXIWpqpmiXT29rHyp3evnzrmKVFUJ/bmXt9LZ3csCn/LvnKtAVZXQW9uiDlHf1MI5V4mqKqG3pNKMb6zjgCljQofinHMFV1UJvbUtzYLpE5C8Q9Q5V3mqJqHv7O7h6Zfaffy5c65iVU1C/8u6rXT1GAt9yr9zrkJVTULP7CHqQxadc5WqihL6ZiaOqWfGpNGhQ3HOuaKomoTekvIOUedcZauKhN7R1cOz67b4lnPOuYpWFQn9mXVb6O41r5875ypaVST01r4lc32Ei3OuclVHQm9LM2VsA/tPaAwdinPOFU1VJPSWVJoFM7xD1DlX2So+oe/o7OG5V7b6glzOuYpX8Ql95Uvt9PQah3lCd85VuIpP6JkO0YXeIeqcq3AVn9Bb2tI0jx/F1KZRoUNxzrmiyiuhSzpB0rOSVkm6ZID7PytppaQWSfdLOqDwoe6dp9rSLPQZos65KjBkQpdUC1wDvBuYD5wpaX7OZU8Ai81sIXA7cFWhA90b23Z2s+qVrb5krnOuKuTTQj8SWGVmq82sE7gFODn7AjN70My2x4ePAjMKG+beWflSO73mKyw656pDPgl9OrA26zgVnxvMR4BfDXSHpAskLZO0bP369flHuZdaUtGSuT7CxTlXDQraKSrpbGAx8I2B7jez68xssZktbm5uLuRTD6g1tZlpTY3sO95niDrnKl9dHte0ATOzjmfE5/qR9E7gS8BbzWxnYcIbmZa2tNfPnXNVI58W+lJgrqQ5khqAM4Al2RdIOhy4FjjJzF4pfJjDt6Wji+df3eYzRJ1zVWPIhG5m3cCFwL3A08BPzWyFpCsknRRf9g1gHHCbpCclLRnk4UpmxYvtmOEtdOdc1cin5IKZ3QPck3Pu0qzb7yxwXCPWGneI+qYWzrlqUbEzRVva0kyfOJop43yGqHOuOlRsQm9NbfbWuXOuqlRkQk/v6OKFDdu9fu6cqyoVmdBXtEX1c58h6pyrJhWZ0FvavEPUOVd9KjKht6bSzJw8moljGkKH4pxzJVORCb2lbTMLp/uGFs656lJxCX3Ttk7WbtzhHaLOuapTcQm9NdMh6vVz51yVqdiEfqgndOdclam8hJ5KM2efsUwYXR86FOecK6nKS+htad/QwjlXlSoqob+6dSdtm3d4/dw5V5UqKqFn6uc+wsU5V40qKqE/lUojwaH7N4UOxTnnSq6iEnpLW5rX7DOW8Y3eIeqcqz4VldBbU2kWzvAZos656lQxCf2V9g7WtXf4CBfnXNXKK6FLOkHSs5JWSbpkgPvfIulxSd2S3lf4MIfW6kvmOueq3JAJXVItcA3wbmA+cKak+TmX/Q04D7ip0AHmqyWVpkYwfz/vEHXOVad8Nok+ElhlZqsBJN0CnAyszFxgZi/E9/UWIca8PNWW5rX7jmPsqLz2vXbOuYqTT8llOrA26zgVn0sMM6OlLc0CXzLXOVfFStopKukCScskLVu/fn3BHvfl9p2s37LT6+fOuaqWT0JvA2ZmHc+Izw2bmV1nZovNbHFzc/PePMSAWlKbAXyEi3OuquWT0JcCcyXNkdQAnAEsKW5Yw9Palqa2Rt4h6pyrakMmdDPrBi4E7gWeBn5qZiskXSHpJABJR0hKAe8HrpW0ophB52pJpZm77zhGN9SW8mmdcy5R8hoSYmb3APfknLs06/ZSolJMyZkZT7Wlecch+4Z4euecS4yynyn6YrqDDds6WeBT/p1zVa7sE3pr3CHqa6A756pd2Sf0llSauhpx0LTxoUNxzrmgyj6ht7alOWjaeBrrvUPUOVfdyjqhmxktqbRPKHLOOco8oac27SC9o8un/DvnHGWe0FtSvmSuc85llHdCb9tMQ20N86Z6h6hzzpV1Qm9NpTl4v/E01JX1P8M55wqibBcP7+01WtvSnLRo/9ChOOdydHV1kUql6OjoCB1K2WpsbGTGjBnU1+e/6X3ZJvQ1G7ezpaPb6+fOJVAqlWL8+PHMnj0bSaHDKTtmxoYNG0ilUsyZMyfvnyvbWkVmD1Ef4eJc8nR0dDBlyhRP5ntJElOmTBn2J5zyTeipzYyqq2Hu1HGhQ3HODcCT+cjsze+vbBN6SyrN/P2bqK8t23+Cc84VVFlmw97eaMncBb4gl3NuD+68804k8cwzz4QOpSTKMqGvfnUb2zp7PKE75/bo5ptv5thjj+Xmm28u2nP09PQU7bGHqyxHubS2xUvm+hroziXe5XevYOWL7QV9zPn7N/GVEw/d4zVbt27lD3/4Aw8++CAnnngil19+OT09PXzhC1/g17/+NTU1NZx//vlcdNFFLF26lIsvvpht27YxatQo7r//fu644w6WLVvG9773PQDe85738LnPfY7jjjuOcePG8bGPfYz77ruPa665hgceeIC7776bHTt2cPTRR3PttdciiVWrVvHxj3+c9evXU1tby2233cbll1/Oe9/7Xk455RQAzjrrLD7wgQ9w8sknj/j3Up4JPdXO6PpaDmweGzoU51xC3XXXXZxwwgnMmzePKVOmsHz5ch577DFeeOEFnnzySerq6ti4cSOdnZ2cfvrp3HrrrRxxxBG0t7czevToPT72tm3bOOqoo/jmN78JwPz587n00mgTt3POOYdf/OIXnHjiiZx11llccsklnHrqqXR0dNDb28tHPvIRrr76ak455RTS6TQPP/wwN954Y0H+zeWZ0Ns2c+j+TdR5h6hziTdUS7pYbr75Zi6++GIAzjjjDG6++Waef/55Pv7xj1NXF6W+yZMn09rayn777ccRRxwBQFPT0JvN19bWctppp/UdP/jgg1x11VVs376djRs3cuihh3LcccfR1tbGqaeeCkQThQDe+ta38slPfpL169dzxx13cNppp/XFM1J5PYqkE4BvA7XA983s6zn3jwJ+CLwB2ACcbmYvFCTCHD29xlNt7Zx+xMxiPLxzrgJs3LiRBx54gNbWViTR09ODpL6knY+6ujp6e3v7jrPHhDc2NlJbW9t3/pOf/CTLli1j5syZXHbZZUOOHz/33HP58Y9/zC233MINN9wwzH/d4IZs4kqqBa4B3g3MB86UND/nso8Am8zstcDVwJUFizDHX9dvZUdXj88Qdc4N6vbbb+ecc85hzZo1vPDCC6xdu5Y5c+awaNEirr32Wrq7u4Eo8R900EG89NJLLF26FIAtW7bQ3d3N7NmzefLJJ+nt7WXt2rU89thjAz5XJnnvs88+bN26ldtvvx2A8ePHM2PGDO68804Adu7cyfbt2wE477zz+I//+A8gKtcUSj41iyOBVWa22sw6gVuA3Or9yUCmCHQ78A4VaVaBL5nrnBvKzTff3FfqyDjttNN46aWXmDVrFgsXLmTRokXcdNNNNDQ0cOutt3LRRRexaNEijj/+eDo6OjjmmGOYM2cO8+fP59Of/jSvf/3rB3yuiRMncv7553PYYYfxrne9q9+ngB/96Ed85zvfYeHChRx99NGsW7cOgKlTp3LIIYfwoQ99qKD/bpnZni+Q3gecYGYfjY/PAY4yswuzrnkqviYVH/81vubVnMe6ALgAYNasWW9Ys2bNsAO+84k2fvDwC9zxiaOprfGZaM4l0dNPP80hhxwSOozE2r59OwsWLODxxx9nwoTBG6cD/R4lLTezxQNdX9JeRTO7zswWm9ni5ubmvXqMUw6fzp2fOsaTuXOuLN13330ccsghXHTRRXtM5nsjn07RNiC7B3JGfG6ga1KS6oAJRJ2jzjnnsrzzne9kb6oT+cinhb4UmCtpjqQG4AxgSc41S4B/jG+/D3jAhqrlOOcqmqeAkdmb39+QCd3MuoELgXuBp4GfmtkKSVdIOim+7L+BKZJWAZ8FLhl2JM65itHY2MiGDRs8qe+lzHrombHr+RqyU7RYFi9ebMuWLQvy3M654vIdi0ZusB2L9tQpWpYzRZ1zyVZfXz+snXZcYfjceeecqxCe0J1zrkJ4QnfOuQoRrFNU0npgbwdj7gO8OuRVpedxDY/HNXxJjc3jGp6RxHWAmQ04MzNYQh8JScsG6+UNyeMaHo9r+JIam8c1PMWKy0suzjlXITyhO+dchSjXhH5d6AAG4XENj8c1fEmNzeManqLEVZY1dOecc7sr1xa6c865HJ7QnXOuQnhCd865CuGLc7mik/TZPd1vZt8qVSyDkTSJaJOWvr8JM3s8XERuOCTdDQzaIWhmJw12XylImgicC8ym/2vs04V8nrJK6JKOBeaa2Q2SmoFxZvZ8AuKaCmR2hn3MzF4JGQ+ApKuA/w3sAH4NLAQ+Y2Y/DhDO+ADPmTdJXwXOA/7KrqRgwNtDxZRN0nLgeuAmM9sUOp6E+vfQAQzhHuBRoBXoLdaTlM0oF0lfARYDB5nZPEn7A7eZ2TGB4/oA8A3gt4CANwOfN7PbA8f1pJm9TtKpwHuINh75vZktChlXEkl6FlhgZp2hYxmIpNcCHwJOB5YBNwD/E2JXMElbGLglLMDMrKnEIZUFSY+b2euL/Tzl1EI/FTgceBzAzF6UlISW35eAIzKt8viTw31A0ITOrv/bfyB640tLYTfWltQIfAQ4FOjbisXMPhwsqMhTwEQg+CergZjZKuBLkr5M9OZ8PdAj6Qbg22a2sYSxJOFvblCS5gL/Bsyn/2vsNcGCivxI0vnAL4CdmZOF/r8rp4TeaWYmyQAkjQ0dUKwmp8SygWR0Nv9C0jNEJZdPxG80obeP+RHwDPAu4ArgLKJtDUP7N+AJSU/R/48taN01m6SFRK30vwfuAH4CHAs8ALwuYFz70j9x/i1ULLEbgK8AVwNvI/qdJeHvsZPok/yX6F/WK+gbTTmVXD4HzAWOJ/oD/DBRTfG7geP6BlF9+ub41OlAi5l9IVxUEUmTgbSZ9cRvgOPNbF3AeJ4ws8MltZjZQkn1wENm9sZQMcVxrQCuJae+aWa/CxZUlriGvplo7947zGxn1n0/M7P3BojpJOCbwP5En2wOAJ42s0NLHUtOXMvN7A2SWs1sQfa5wHGtBo40s6Ku/Fg2LXQz+3dJxwPtwEHApWb2m5AxKaphfIeoQ/TY+PR1ZvbzcFFFJI0BPgnMAi4g+sM7iOgjXyhd8ffNkg4D1gH7BownY7uZfSd0EHvwfjNbnX1C0hwzez5EMo99FXgjcF/8Jv024OxAsWTbKakGeE7ShUAbMC5wTMKJ3XUAABXgSURBVACrgO3FfpKyaaEnVXZLIEkk3QosB841s8PiBP+wmYX8eP5RonLBQqKPxuOI3pj/X6iY4ri+RVRqWUL/kksihi0O1KEWutWZWf5V0p+Bw82sV9KfQ3e6SzqCqIw3kehNZwJwlZk9GjiunxP1HT1I/9dYdQ5blPRe4EqiFp1ITq/645KOMLOlgePIdaCZnS7pTAAz267AvaJm9v345u8ocO1whA6Pv2eXfoIPW5R0MFESmBC//jOayKpbB7JZ0jjg98BPJL0CbAscE1l/h1uJ6udJcWf8VVRlk9CBq4ATzSwJnWjZjgLOlvQC0Qs680azMGhU0ClpNHEHjKQDyWoZhFCqyRXDZWZvC/n8e3AQ0aiWicCJWee3AOcHiWiXk4k62T9D1Lk9gaijOyhJi4k6Hg+g/2ss2N+jpFrgvFK8zsopob+cwGQO0YiNJPoK0YSimZJ+AhxDNHkmpJJMrhguSROIfl9viU/9DrjCzNLhogIzuwu4S9KbzOyRkLHkMrPs1viNwQLZ3U+Az5Og11g8KKFX0oRiv6bKpoYu6dvANKKPLdk1qJ8FCyqW4BmsU4jKCAIeLXYPex7xlGRyxXBJuoNoLHomMZ0DLArY4QiApH82s6skfZcBJvOE/GST1BKopD+Y2bFDX1laku4iKu39hqzSVKH/D8spod8wwGkLPSklqTNYASRNZ/ePnr8PGM9niGqbRZ1cMVyZWbVDnSs1SSea2d2S/nGg+80sWMtY0ioSWAKV9A7gTOB+EtTwK9X/YdmUXMwsSR0c2RI5g1XSlURj4lew66OnEXVihVKSyRV7YYekY83sDwCSjiGakBWUmd0d39xuZrdl3yfp/QFCypbUEuiHgIOBevq/7oMmdDO7UVIDMC8+9ayZde3pZ/ZGObXQZwDfJaoFAzwEXGxmqXBRgaTHzOzITDkhnsDzSOhO0Xh9koXZk1BCK9XkiuGStAj4IVHHHsAm4B/NrCVcVLsMMmwxaPkqqSVQSc+a2UEhYxiIpOOISnovEJWnZhK9xgrawCqbFjrRuOWbgEzL5Oz43PHBIor8VNK1wMR4rYYPA/8VOCaA1UStlMQkdEo0uWI44hEI55jZIklNAGbWHjgsACS9m2iq/3RJ2ROfmoDuMFH1i2E78HdZ54K3hIGHJc03s5WB48j1TeDvzOxZAEnziGaXF3QuQTkl9GYzy66j/0DS/woVjKR3mdm9A81gJRpmFtp24ElJubXEkEMEtxHFVNTJFcMRj0A4Nr6diESe5UWi1RVPIpoklrGFaLhgMAkugb6R6DX2PNFrLCnDiOszyRzAzP4SL31RUOVUcrmfqEWeWTPlTOBDZvaOQPH0ENWjzzaztpz7go/mkPQJojdsI2rN7YDgHWmJ69wDkPR/genAbfQfgRC6tQmApPpi1FtHIokl0Hji3JuBNbn3mdlu50pJ0vVENf3MfgRnAbWFHtRRTgn9AKIX0JuIktTDwKct0Opukp4A/pOoRf4Zy1r/PLMIVaC46oCvEZV+1hC1UGYRvRn+S6jEEJc27kviJJ6kjqDKiDtpL2PXiKVMqzNYZ7Kk3xCVQH8UnzobOMvMgpZAE7wUxyjgU+xa8+kh4D8L3sdlZv61F1/A4/H3ecBSooQ5Jvu+QHFdDXyfaGXFzLkm4DrgPwL/zu4HJoT+v8uK58r4+/tDxzJEnM8A7yYa8z0l8xU4pifzORcgrhuJ9icI/v8Wx3N//P3KUjxf4mvoki7dw91mZl8tWTADB/AXSW8i2u7tCUnnhoyHaKr4PItfRRDVhuMSzDNAsH4HojHorXHrrmiTK4bh7yVdAnyRqNySVGkz+1XoIHJskHQ2/UugGwLGk3EUcJakNSRjKY79JB0NnCTpljiePlbgBeASn9AZeMGfsUQ730whWlEthL7/GDPrBi6R9GuiF3hzoJjicGy3OppFnX+h62s/I/woiGy/JhqiOE5SdodoImY9ZnlQ0br7PyM5q0F+mKgEejW7SqBJ6ChN2lIclwJfBmYAuZuhF3wBuLKpoQPEE3YuJkrmPwW+aYE2ZJZ0ipnttnqaot3jP2ZmXw8QFpLuBH5mZj/MOX828AELv/t50SdXDJeku8zs5NBxDCYeFZTLzCwRm1gnTTyv4M3x4UNm9ueQ8QBI+nIpqgllkdAV7bzzWaKe4RuJ9lH03c8HEE/3/xnRqJbMULfFwGjgVMsZkVPi2I6jBJMrXPHljIvPSAPLLFpULAhJFxOtRJn5JHgq0aYzQXY2k3SwmT0jacBRb4X+lJX4hB5/1HwvUafeNWa2NXBIZUHS24nW0gZYaWb3h4wH+rZS+6DlTK6wQBs1ZBZy0q6d7JX9PSklF0lTiUYu7W9m75Y0H3iTmf13wJiuI5pin+l7OA14nqgMutrMgvTVSGoh+t1si4+DztyWdJ2ZXVCqT1nlkNB7ieqG3fRfcS5Rf3RuaIr3Eh3qnOtP0q+IRlF9yaIZrXXAExZweJ6kR4FjzKwnPq4jGop3LNBqZvMDxdVKNMqlIz5uBJaG/F2VUuI7Rc0sCTt2u8JYJun79J9csSxgPH3icfJT6b8yZegd7DP2MbOfSvoiRJ3w8cS2kCYRbSGYWd97LDA57nwPudzEDcCfFG35BnAK0ebawcWjXWbT/zX2w0F/YC8kPqG7ivIJoskVmWGKDxFNzgpK0kVEG1y8TP8V+pLyyWGborXtM7tPvZFdiTSUq4im2P+W6NPyW4CvxSWO+0IFZWbfkvQ7ds1g/ZCZPREqngxJPwIOBJ4EMm/GRrQoXOGeJ+klF+eKLV7b+ygzS8I46t3EHWrfBQ4j2oijGXifBV4NUtJ+wJHx4VIzezFkPEkm6Wlg/kBDigvJW+iu6OIOocFeyGaB1uPJspbwLd5Bmdnjkt5KtPibSMhwT+AIdg0P7CVaTCyIrI5t2NW5DVGOazCz0LnuKaLlhl8q5pOE/ke66vC5Ac69EfhnIMg8ghyrgd9K+iX9J+7kTgQpKUXbvA1kniQs4OJhkr5OlNB/Ep/6tKK9T/8lRDxm1m9TGUnjiMp7HwN+PuAPldY+wEpJj9H/NVbQeSGe0F3RmVnf0q9xS/PLQCPw8YRMaf9b/NUQfyXFifH3fYGjgQfi47cRzcwMOev274HXmVkvgKQbgSeAIAk9Q9JEouUtziVaPOyIhJTSLivFk3hCdyUh6V3AvxK1Tv6PmQ00LjcIM7s8dAwDsXjNcUn/Q1R/fSk+3g/4QcDQMiYCmf1gJ+zpwmKTtA/wT0TbLl4PHG5miSmjmdnvSvE8ntBd0UlaStSR9w3gkfhc38y5UGuSSLqb/rV9A14FHjSzHw/8U0HMzCTz2MtESyKH9G9Ei9E9yK5RLpcEjGcNsJ5o2OJ24CPR8uiRUOWznNo+ZL3GgC8U+tODj3JxRRcPbcveFDp7xblga5LE5Z9ck4nW9n7OzEImqD6SvgfMZdfKhqcDq8zsonBR9X1SOCI+fMzM1gWM5TIG73hP1KeweL2n84Cjzaygm317QncuRzzJaLmZvS50LBlxB2lmRMnvzSx4R1+8blBm0w0AfF2e/BVjZzMvuTiXI57tGDqMfuIRLYlZeljSlUSfFFbQfzKWJ/Q8xPuJFjz/ekJ3VStexTPXJKIREitKHM5uBqi/9t1F+HWMTgEOskJvoVZhBhl6OonozfD2Ae4bEU/orpotp39NP9Nh9VuiZQqCyh1bnTCrgXqyxlQngaQ5Zvb8UOdK6MScYyPa2enbZvbLQj+Z19BdSUlayO4LFCWmlOD2TNJ3iZLSdGAR0T6x2RNlQm0nCAxcl5a0PNQSzaXmLXRXMpKuJ1rwKrfu6gm9fGRWx1wOLMm5L1jrUNLBROv/T8gpczQRTWKrCp7QXSm9MdQ62a4wzOxGiHYGMrNvZ98X7xYUykFEG6RPpH+ZYwvRDkZVwUsurmQk/TfRPrArQ8fiRmaQ0sYTZnZ4qJjiGN5kZo+EjGEgpartewvdldIPgUckrSOqu2ZGawRfd9xr+/mRdCbwQeA1krJLLuPZtQxASGvjzS0y66E/BFxsZqmAMQHcAeSOOb8dKGht3xO6K6X/Bs4BWtlVQw/Oa/vD8jDRErD7AN/MOr8FCLo+e+wGokW5MjMwz47PHR8imFLX9j2hu1Jab2a5HWlJ4LX9PJnZGkkpoKNUC04N075mdkPW8Q8kBdmwOlbS2r4ndFdKT0i6Cbib/kPdQreEH5E032v7+Yln0vZKmpCkFQ1jr0o6m13r3pxJNO47CDO7C7irVLV9T+iulEYTJfK/yzqXhNJGYmv7CbYVaJX0G2Bb5mTocejAh4m267ua6LX1MPChoBFFSlLb91EururFe4p+lpzavpmtCRZUwkn6BFGD0IBuYAfsGtYYKKZa4IdmdlaoGAYTv/HdBPwoPnU2cJaZFbS27wndlYykGUStp0SNQJD0iJm9KWQM5UJSHfA1opbwGqJPM7OIOh7/JfRep5L+ALzdzDpDxpFL0p/NbFHOuScLvaKnl1xcKSVqBEKWpNb2k+gbREMU55jZFgBJTcC/x/eF7ICEaI2ZP8ZDKrNLQUH3h6VEtX1vobuSGahFUoxWynBJumGA02ZmHy55MAkn6TlgnuUkjrjc8YyZzQ0TWV8cXxnofOgNLiQdQPTp9E3squ1/2sz+Vsjn8Ra6K6UNSRqBkJHZu9PlxXKTeXyyR1Lw1mEmcUsaFx9vDRtR35vd18zspGI/V02xn8C5LB8GPgCsI5qc8j4SMAJB0gxJP5f0Svx1R1zvd7tbKenc3JPxG/UzAeLJjeMwSU8QTRJbIWm5pENDxmRmPcABkhqK/VxecnFVr1QjECpBvO3cz4hGtSyPTy8mGpJ6qpm1hYoNQNLDwJfM7MH4+Dii1vHRgeP6IXAI0QqVRavte0J3RZe1hvaAQo9dTmptP8kkvZ1oSjvASjO7P2Q8GYOMJtntXKmVqrbvNXRXCpk1tI8B5gO3xsfvB5IwOzORtf0kM7MHgAdCxzGA1ZK+TP9PW6sDxgOUrrbvLXRXMpIeBY41s+74uB54yMzeGDiukoxAcMUnaRJwOXBsfOoh4DIz2xQuqqi2T/Qmk9nH9lXgXDMr6N61ntBdyUh6FniTmW2MjycBj5rZQWEjc664SlXb95KLK6WvE03ieZBohuFbgMtCBZP02r7Ln6S72fP/ZdGHDA5hbCaZA5jZbyWNLfSTeEJ3JWNmN0j6FXBUfOoLZrYuYEhJr+27/P176ACGUJLavpdcXEnFw94OoP/OQL8PF1Fya/uucpSqtu8tdFcykq4ETmf3nYGCJnRgEtEOMpkt1MbF51yZkHQyMMPMromP/wQ0x3f/s5ndHiw4IE7cRS/heUJ3pXQKcJCZ7RzyytJKVG3f7ZV/Bs7IOh4FHAGMJVoALkhCL3Vt3xO6K6XVQD1ZKxomQQJr+274GsxsbdbxH8xsA9Ecg4J3Pg5DSWv7XkN3JSPpDmARcD/9l6kNPpokibV9lz9Jq8zstYPc91czO7DUMYXgLXRXSkvir0RJcG3f5e9Pks43s//KPinpY8BjgWIqeW3fW+iu6sUTnhYmsLbv8iRpX+BOok9+j8en30BUSz/FzF4OFNcfgTMy5SBJTwLvIK7tm9k7Cvl83kJ3JSNpLvBvRGO+GzPnzew1wYKKJLK27/JnZq8AR+csGvbLeM2ZkEpa2/eE7krpBuArRDuyv41oLfQkrMm/HXhSUuJq+254ErhoWL/hr2Z2YdZhMwXmCd2V0mgzu1+SzGwNcJmk5cClgeNKZG3fVYSS1vY9obtS2impBnhO0oVAG9EknqDM7MbQMbiK9RngTkkfZIDafqGfzDtFXclIOgJ4GpgIfBWYAFxpZn8KHFdSa/uuQuTU9lcUq7bvCd0FE2+ee4aZ/SRwHH9gV23/ROLavpmFLgU5NyxJ6JByFU5Sk6QvSvqepL9T5EJgFdGm0aGNjrdQk5mtMbPLgH8IHJNzw+Y1dFcKPwI2AY8AHwX+hWjNlFPN7MmQgcUSWdt3bri85OKKTlKrmS2Ib9cCLwGzzKwjbGSRpNb2nRsub6G7UujK3DCzHkmppCRzADNbGt/cCnwoU9sHPKG7suItdFd0knqAbZlDYDTRZB4BZmZNgeJqAj4FTCcah/6b+PifgBYzOzlEXM7tLU/ormpJuotdtf13APsSvclcnJDavnPD4gndVa2k1/adGy4ftuiqWb/aPpCo2r5zw+UtdFe1klrbd25veUJ3zrkK4SUX55yrEJ7QnXOuQnhCd865CuEJ3TnnKoQndJcYkr4vaf4Q1/xA0vsGOD873kRgTz+7WNJ38ojj4Xwfc6QknZL9b5b0W0mLR/B4I/p5V948obvEMLOPmtnKvfzx2cAek6+ZLctnn1AzOzrfxyyAU4g21nBuxDyhu4KT9HlJn45vXy3pgfj22yX9JF4T/RFJj0u6TdK4+P6+1qWkj0j6i6THJP2XpO9lPcVbJD0saXVWa/3rwJslPSnpM4PEdZykX8S3L5N0ffycqzPxxvdtHcZjnifpTkm/kfSCpAslfVbSE5IelTQ5vu5ASb+WtFzSQ5IOlnQ0cBLwjfg5Dowf9v3xv/svkt4c/3yjpBsktcaP/bb4/GhJt0h6WtLPicbSuyrlCd0Vw0PAm+Pbi4Fxkurjcy3AvwLvNLPXA8uAz2b/sKT9gS8DbwSOAQ7Oefz9gGOB9xAlXYBLgIfM7HVmdnWecR4MvAs4EvhKHGO2fB/zMOC9wBHA/wG2m9nhRGvEnBtfcx1wkZm9Afgc8J9m9jDRomCfj5/jr/G1dWZ2JPC/iHZSgmjRMIuXKjgTuFFSI/CJ+PkOia99Q57/dleBfPlcVwzLgTfEqxnuJNocdzFRQl9CVGL4oySABqLEl+1I4HdmthFA0m3AvKz77zSzXmClpKkjiPOXZraTaIOLV4CpQGovHudBM9sCbJGUBu6Oz7cCC+NPIEcDt8X/Zog2CR7Mz+Lvy4nKPhC9gX0XwMyekbSG6HfyFuA78fkWSS17Eb+rEJ7QXcGZWZek54HzgIeJWuVvA14LPA/8xszOHMFT7My6rUGvGt7j9LD3fw/Zj9ObddwbP2YNsNnMXjfMxxtJTK4KecnFFctDRKWF38e3Pw48ATwKHCPptQCSxkqal/OzS4G3SpokqQ44LY/n2wKML1TwhXxMM2sHnpf0foB4T9VFw3yOh4Cz4p+fB8wCniX6/X4wPn8YsHCk8bry5QndFctDRLXuR8zsZaCDqB69nqjlfnNcHniEnBq5mbUBXwMeA/4IvACkh3i+FqBH0p8H68DcC4V8zLOAj0j6M7ACyGyecQvw+bij88BBfxr+E6iR1ArcCpwXl4v+L1EfxdPAFURlGlelfHEul0iSxpnZ1riF/nPgejP7eei4nEsyb6G7pLpM0pPAU0R19zsDx+Nc4nkL3VUcSe8Crsw5/byZnZqkx3Su0DyhO+dchfCSi3POVQhP6M45VyE8oTvnXIXwhO6ccxXi/wPK4MxQgVtLhAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMfc-h8xAYQu"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0N9wSXF1iSp3",
        "outputId": "e32a6d94-548a-44be-f09c-e9b6bfe0dc99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = []\n",
        "\n",
        "for m in tqdm(models):\n",
        "    predictions.append(np.argmax(m.predict(x_test), axis=1))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.93it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAky42lMV102",
        "outputId": "8c9a6f73-e681-4489-a9d9-752d9a06b18b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(predictions):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(predictions):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "display(pd.DataFrame(correlation_matrix))\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.871305</td>\n",
              "      <td>0.875581</td>\n",
              "      <td>0.870748</td>\n",
              "      <td>0.888393</td>\n",
              "      <td>0.874177</td>\n",
              "      <td>0.871880</td>\n",
              "      <td>0.867839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.871305</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.899659</td>\n",
              "      <td>0.863129</td>\n",
              "      <td>0.891148</td>\n",
              "      <td>0.897952</td>\n",
              "      <td>0.877635</td>\n",
              "      <td>0.883685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.875581</td>\n",
              "      <td>0.899659</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.859124</td>\n",
              "      <td>0.885291</td>\n",
              "      <td>0.889631</td>\n",
              "      <td>0.870224</td>\n",
              "      <td>0.885219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.870748</td>\n",
              "      <td>0.863129</td>\n",
              "      <td>0.859124</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.879595</td>\n",
              "      <td>0.871862</td>\n",
              "      <td>0.894571</td>\n",
              "      <td>0.857108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.888393</td>\n",
              "      <td>0.891148</td>\n",
              "      <td>0.885291</td>\n",
              "      <td>0.879595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.893063</td>\n",
              "      <td>0.881699</td>\n",
              "      <td>0.881690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.874177</td>\n",
              "      <td>0.897952</td>\n",
              "      <td>0.889631</td>\n",
              "      <td>0.871862</td>\n",
              "      <td>0.893063</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.900322</td>\n",
              "      <td>0.891488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.871880</td>\n",
              "      <td>0.877635</td>\n",
              "      <td>0.870224</td>\n",
              "      <td>0.894571</td>\n",
              "      <td>0.881699</td>\n",
              "      <td>0.900322</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.864986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.867839</td>\n",
              "      <td>0.883685</td>\n",
              "      <td>0.885219</td>\n",
              "      <td>0.857108</td>\n",
              "      <td>0.881690</td>\n",
              "      <td>0.891488</td>\n",
              "      <td>0.864986</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...         5         6         7\n",
              "0       NaN  0.871305  0.875581  ...  0.874177  0.871880  0.867839\n",
              "1  0.871305       NaN  0.899659  ...  0.897952  0.877635  0.883685\n",
              "2  0.875581  0.899659       NaN  ...  0.889631  0.870224  0.885219\n",
              "3  0.870748  0.863129  0.859124  ...  0.871862  0.894571  0.857108\n",
              "4  0.888393  0.891148  0.885291  ...  0.893063  0.881699  0.881690\n",
              "5  0.874177  0.897952  0.889631  ...       NaN  0.900322  0.891488\n",
              "6  0.871880  0.877635  0.870224  ...  0.900322       NaN  0.864986\n",
              "7  0.867839  0.883685  0.885219  ...  0.891488  0.864986       NaN\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.8799643988209123\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}