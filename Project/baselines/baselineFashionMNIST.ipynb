{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baseline_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "outputId": "bcebe0af-9237-4810-a687-a9dbc2abb57c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy\n",
        "import tensorflow as tf\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping, CSVLogger\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 9999\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "NUM_CHANNELS = 1\n",
        "MODEL_NAME = \"FashionMNIST_basleine\"\n",
        "PATH = \"\"\n",
        "NR_OF_RUNS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8QvEt97vF52"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JtJIUBsFKeRO",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "cd4f77d7-561c-4171-cab3-643e8284906b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_trainc = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4SYRuKZaIwb",
        "colab": {}
      },
      "source": [
        "x_train_full = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train_full /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIBGIrlkvOt0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqdcrD_vQ-Q"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "c34da81d-6296-4818-9690-3ae7035f6412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for run in range(1, NR_OF_RUNS+1):\n",
        "    \n",
        "    # Split the data\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_trainc, test_size=0.20, shuffle= True)\n",
        "    \n",
        "    models = []\n",
        "    accuracies = []\n",
        "    predictions = []\n",
        "    print(f\"\\n ===== Train model: Baseline: Run: {run}  =====\")\n",
        "        \n",
        "    # Set the seeds\n",
        "    np.random.seed(run*17)\n",
        "    tf.random.set_seed(run*17)\n",
        "\n",
        "    # Create directories\n",
        "    os.makedirs(PATH + MODEL_NAME + f\"/{run}/history\", exist_ok=True)\n",
        "    os.makedirs(PATH + MODEL_NAME + f\"/{run}/weights\", exist_ok=True)\n",
        "        \n",
        "    # weight init method\n",
        "    model = FashionMNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
        "            \n",
        "    #save weights \n",
        "    weights_path = PATH + MODEL_NAME + f\"/{run}/weights/weights-baseline.h5\"\n",
        "            \n",
        "    if os.path.exists(weights_path):\n",
        "        print(f\"Skipping training of model: weights exists\")\n",
        "        model.load_weights(weights_path)\n",
        "    else:\n",
        "        # initiate early stopping\n",
        "        es = EarlyStopping(min_delta=0.01, patience=3)\n",
        "        csv_logger = CSVLogger(PATH + MODEL_NAME + f\"/{run}/history/history.csv\", separator=';')\n",
        "        # train\n",
        "        model.fit(x_train,y_train,\n",
        "                batch_size = BATCH_SIZE,\n",
        "                epochs = EPOCHS,\n",
        "                validation_data = (x_val,y_val),\n",
        "                shuffle = True,\n",
        "                callbacks=[es, csv_logger])\n",
        "        model.save_weights(weights_path)\n",
        "            \n",
        "    acc = model.evaluate(x_test,y_testc)[1]\n",
        "    print(f\"Run: {run} added. Resulting score: {acc}\")\n",
        "\n",
        "    print(\"\\n ===== Saving results =====\")  \n",
        "    # Save the results\n",
        "    file = PATH + MODEL_NAME + f\"/results_.csv\"\n",
        "    df = pd.DataFrame([[run,acc]])\n",
        "    if not os.path.isfile(file):\n",
        "        df.to_csv(file, header=[\"run\",\"accuracy\"], index=False)\n",
        "    else: # else it exists so append without writing the header\n",
        "        df.to_csv(file, mode='a', header=False, index=False)\n",
        "    clear_output(wait=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ===== Train model: Baseline: Run: 10  =====\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/9999\n",
            "48000/48000 [==============================] - 3s 54us/step - loss: 2.1949 - accuracy: 0.2062 - val_loss: 2.1966 - val_accuracy: 0.2674\n",
            "Epoch 2/9999\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 1.8949 - accuracy: 0.4039 - val_loss: 1.7785 - val_accuracy: 0.4655\n",
            "Epoch 3/9999\n",
            "48000/48000 [==============================] - 3s 53us/step - loss: 1.6435 - accuracy: 0.5035 - val_loss: 1.5341 - val_accuracy: 0.5398\n",
            "Epoch 4/9999\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 1.4610 - accuracy: 0.5590 - val_loss: 1.3856 - val_accuracy: 0.5786\n",
            "Epoch 5/9999\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 1.3382 - accuracy: 0.5927 - val_loss: 1.2831 - val_accuracy: 0.6087\n",
            "Epoch 6/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 1.2490 - accuracy: 0.6139 - val_loss: 1.2074 - val_accuracy: 0.6270\n",
            "Epoch 7/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 1.1822 - accuracy: 0.6260 - val_loss: 1.1490 - val_accuracy: 0.6388\n",
            "Epoch 8/9999\n",
            "48000/48000 [==============================] - 2s 50us/step - loss: 1.1282 - accuracy: 0.6371 - val_loss: 1.1021 - val_accuracy: 0.6504\n",
            "Epoch 9/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 1.0854 - accuracy: 0.6472 - val_loss: 1.0645 - val_accuracy: 0.6581\n",
            "Epoch 10/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 1.0499 - accuracy: 0.6535 - val_loss: 1.0352 - val_accuracy: 0.6601\n",
            "Epoch 11/9999\n",
            "48000/48000 [==============================] - 2s 48us/step - loss: 1.0204 - accuracy: 0.6619 - val_loss: 1.0049 - val_accuracy: 0.6700\n",
            "Epoch 12/9999\n",
            "48000/48000 [==============================] - 2s 48us/step - loss: 0.9954 - accuracy: 0.6686 - val_loss: 0.9816 - val_accuracy: 0.6798\n",
            "Epoch 13/9999\n",
            "48000/48000 [==============================] - 2s 50us/step - loss: 0.9730 - accuracy: 0.6743 - val_loss: 0.9606 - val_accuracy: 0.6812\n",
            "Epoch 14/9999\n",
            "48000/48000 [==============================] - 2s 50us/step - loss: 0.9525 - accuracy: 0.6820 - val_loss: 0.9418 - val_accuracy: 0.6860\n",
            "Epoch 15/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 0.9343 - accuracy: 0.6863 - val_loss: 0.9244 - val_accuracy: 0.6957\n",
            "Epoch 16/9999\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 0.9178 - accuracy: 0.6919 - val_loss: 0.9110 - val_accuracy: 0.6963\n",
            "Epoch 17/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 0.9029 - accuracy: 0.6975 - val_loss: 0.8940 - val_accuracy: 0.7039\n",
            "Epoch 18/9999\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.8890 - accuracy: 0.7017 - val_loss: 0.8860 - val_accuracy: 0.7023\n",
            "Epoch 19/9999\n",
            "48000/48000 [==============================] - 2s 48us/step - loss: 0.8765 - accuracy: 0.7047 - val_loss: 0.8692 - val_accuracy: 0.7076\n",
            "Epoch 20/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.8638 - accuracy: 0.7090 - val_loss: 0.8573 - val_accuracy: 0.7137\n",
            "Epoch 21/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.8520 - accuracy: 0.7133 - val_loss: 0.8478 - val_accuracy: 0.7145\n",
            "Epoch 22/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.8423 - accuracy: 0.7166 - val_loss: 0.8377 - val_accuracy: 0.7195\n",
            "Epoch 23/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.8326 - accuracy: 0.7207 - val_loss: 0.8274 - val_accuracy: 0.7182\n",
            "Epoch 24/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.8236 - accuracy: 0.7226 - val_loss: 0.8180 - val_accuracy: 0.7242\n",
            "Epoch 25/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.8131 - accuracy: 0.7275 - val_loss: 0.8096 - val_accuracy: 0.7238\n",
            "Epoch 26/9999\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.8054 - accuracy: 0.7295 - val_loss: 0.7999 - val_accuracy: 0.7293\n",
            "Epoch 27/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7965 - accuracy: 0.7331 - val_loss: 0.7914 - val_accuracy: 0.7313\n",
            "Epoch 28/9999\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.7902 - accuracy: 0.7350 - val_loss: 0.7843 - val_accuracy: 0.7368\n",
            "Epoch 29/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7812 - accuracy: 0.7376 - val_loss: 0.7778 - val_accuracy: 0.7361\n",
            "Epoch 30/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7741 - accuracy: 0.7401 - val_loss: 0.7707 - val_accuracy: 0.7398\n",
            "Epoch 31/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7666 - accuracy: 0.7439 - val_loss: 0.7620 - val_accuracy: 0.7415\n",
            "Epoch 32/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7601 - accuracy: 0.7457 - val_loss: 0.7557 - val_accuracy: 0.7463\n",
            "Epoch 33/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.7530 - accuracy: 0.7474 - val_loss: 0.7503 - val_accuracy: 0.7452\n",
            "Epoch 34/9999\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.7454 - accuracy: 0.7499 - val_loss: 0.7441 - val_accuracy: 0.7486\n",
            "Epoch 35/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 0.7410 - accuracy: 0.7509 - val_loss: 0.7377 - val_accuracy: 0.7489\n",
            "Epoch 36/9999\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.7341 - accuracy: 0.7536 - val_loss: 0.7347 - val_accuracy: 0.7500\n",
            "Epoch 37/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 0.7289 - accuracy: 0.7553 - val_loss: 0.7250 - val_accuracy: 0.7561\n",
            "Epoch 38/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 0.7237 - accuracy: 0.7577 - val_loss: 0.7217 - val_accuracy: 0.7568\n",
            "Epoch 39/9999\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 0.7169 - accuracy: 0.7585 - val_loss: 0.7152 - val_accuracy: 0.7596\n",
            "Epoch 40/9999\n",
            "48000/48000 [==============================] - 2s 49us/step - loss: 0.7119 - accuracy: 0.7594 - val_loss: 0.7097 - val_accuracy: 0.7601\n",
            "Epoch 41/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.7080 - accuracy: 0.7617 - val_loss: 0.7044 - val_accuracy: 0.7617\n",
            "Epoch 42/9999\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 0.7029 - accuracy: 0.7638 - val_loss: 0.7012 - val_accuracy: 0.7622\n",
            "Epoch 43/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.6992 - accuracy: 0.7648 - val_loss: 0.6971 - val_accuracy: 0.7620\n",
            "Epoch 44/9999\n",
            "48000/48000 [==============================] - 2s 45us/step - loss: 0.6938 - accuracy: 0.7648 - val_loss: 0.6940 - val_accuracy: 0.7623\n",
            "Epoch 45/9999\n",
            "48000/48000 [==============================] - 2s 47us/step - loss: 0.6899 - accuracy: 0.7664 - val_loss: 0.6883 - val_accuracy: 0.7658\n",
            "Epoch 46/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.6858 - accuracy: 0.7673 - val_loss: 0.6848 - val_accuracy: 0.7660\n",
            "Epoch 47/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.6826 - accuracy: 0.7681 - val_loss: 0.6809 - val_accuracy: 0.7681\n",
            "Epoch 48/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.6780 - accuracy: 0.7709 - val_loss: 0.6766 - val_accuracy: 0.7678\n",
            "Epoch 49/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 0.6748 - accuracy: 0.7724 - val_loss: 0.6733 - val_accuracy: 0.7719\n",
            "Epoch 50/9999\n",
            "48000/48000 [==============================] - 2s 48us/step - loss: 0.6710 - accuracy: 0.7721 - val_loss: 0.6701 - val_accuracy: 0.7707\n",
            "Epoch 51/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 0.6679 - accuracy: 0.7730 - val_loss: 0.6675 - val_accuracy: 0.7721\n",
            "Epoch 52/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.6646 - accuracy: 0.7744 - val_loss: 0.6631 - val_accuracy: 0.7737\n",
            "Epoch 53/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.6609 - accuracy: 0.7766 - val_loss: 0.6616 - val_accuracy: 0.7729\n",
            "Epoch 54/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.6579 - accuracy: 0.7762 - val_loss: 0.6565 - val_accuracy: 0.7763\n",
            "Epoch 55/9999\n",
            "48000/48000 [==============================] - 2s 51us/step - loss: 0.6544 - accuracy: 0.7773 - val_loss: 0.6533 - val_accuracy: 0.7779\n",
            "10000/10000 [==============================] - 1s 61us/step\n",
            "Run: 10 added. Resulting score: 0.772599995136261\n",
            "\n",
            " ===== Saving results =====\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MV--sBbgbTrz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "5e4f9142-2546-41f0-aa5f-cd4a408b6488"
      },
      "source": [
        "!zip -r /content/FashionMNIST_basleine.zip /content/FashionMNIST_basleine"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/FashionMNIST_basleine/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/9/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/9/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/9/weights/weights-baseline.h5 (deflated 71%)\n",
            "  adding: content/FashionMNIST_basleine/9/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/9/history/history.csv (deflated 53%)\n",
            "  adding: content/FashionMNIST_basleine/7/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/7/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/7/weights/weights-baseline.h5 (deflated 70%)\n",
            "  adding: content/FashionMNIST_basleine/7/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/7/history/history.csv (deflated 52%)\n",
            "  adding: content/FashionMNIST_basleine/8/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/8/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/8/weights/weights-baseline.h5 (deflated 70%)\n",
            "  adding: content/FashionMNIST_basleine/8/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/8/history/history.csv (deflated 53%)\n",
            "  adding: content/FashionMNIST_basleine/2/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/2/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/2/weights/weights-baseline.h5 (deflated 70%)\n",
            "  adding: content/FashionMNIST_basleine/2/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/2/history/history.csv (deflated 53%)\n",
            "  adding: content/FashionMNIST_basleine/10/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/10/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/10/weights/weights-baseline.h5 (deflated 71%)\n",
            "  adding: content/FashionMNIST_basleine/10/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/10/history/history.csv (deflated 52%)\n",
            "  adding: content/FashionMNIST_basleine/5/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/5/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/5/weights/weights-baseline.h5 (deflated 71%)\n",
            "  adding: content/FashionMNIST_basleine/5/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/5/history/history.csv (deflated 52%)\n",
            "  adding: content/FashionMNIST_basleine/6/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/6/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/6/weights/weights-baseline.h5 (deflated 70%)\n",
            "  adding: content/FashionMNIST_basleine/6/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/6/history/history.csv (deflated 52%)\n",
            "  adding: content/FashionMNIST_basleine/results_.csv (deflated 42%)\n",
            "  adding: content/FashionMNIST_basleine/4/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/4/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/4/weights/weights-baseline.h5 (deflated 71%)\n",
            "  adding: content/FashionMNIST_basleine/4/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/4/history/history.csv (deflated 52%)\n",
            "  adding: content/FashionMNIST_basleine/1/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/1/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/1/weights/weights-baseline.h5 (deflated 71%)\n",
            "  adding: content/FashionMNIST_basleine/1/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/1/history/history.csv (deflated 52%)\n",
            "  adding: content/FashionMNIST_basleine/3/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/3/weights/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/3/weights/weights-baseline.h5 (deflated 70%)\n",
            "  adding: content/FashionMNIST_basleine/3/history/ (stored 0%)\n",
            "  adding: content/FashionMNIST_basleine/3/history/history.csv (deflated 52%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GP6kYsnHbTr0",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}