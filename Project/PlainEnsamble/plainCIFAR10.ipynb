{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "plainCIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import count\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, CSVLogger\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 9999\n",
        "IMAGE_SIZE = 32\n",
        "NUM_CLASSES = 10\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "NR_OF_RUNS = 10\n",
        "MODEL_NAME = \"CIFAR_10_bagging\"\n",
        "PATH = \"\"\n",
        "VOTING = \"SOFT\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8QvEt97vF52",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "colab": {}
      },
      "source": [
        "(x_train_val, y_train_val), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('x_train shape:', x_train_val.shape)\n",
        "print(x_train_val.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train_val = keras.utils.to_categorical(y_train_val, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SYRuKZaIwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_val = x_train_val.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train_val /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIBGIrlkvOt0",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def CIFARmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(inputs)\n",
        "    x = Conv2D(filters=64, kernel_size=(3,3), strides=2)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
        "    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', strides=2, padding='same')(x)\n",
        "    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(filters=128, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters=10, kernel_size=(1,1),strides=(1,1), padding='valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbiuqESLvTOY",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFkx19XmqKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hard_voting(models, X):\n",
        "    predictions = []\n",
        "\n",
        "    for m in models:\n",
        "        predictions.append(np.argmax(m.predict(X), axis=1))\n",
        "\n",
        "    prediction = np.transpose(predictions)\n",
        "    prediction = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=prediction)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "def soft_voting(models, X):\n",
        "    predictions = np.empty((len(X),0,NUM_CLASSES))\n",
        "\n",
        "    for m in models:\n",
        "        pred = np.expand_dims(m.predict(X), axis=1)\n",
        "        predictions = np.append(predictions, pred, axis=1)\n",
        "\n",
        "    predictions = np.apply_along_axis(np.transpose, axis=1, arr=predictions)\n",
        "    predictions = np.mean(predictions, axis=1)\n",
        "    prediction = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "def predict(models, X, Y):\n",
        "    \n",
        "    if VOTING == \"SOFT\":\n",
        "      prediction = soft_voting(models, X)\n",
        "    elif VOTING == \"HARD\":\n",
        "      prediction = hard_voting(models, X)\n",
        "    else:\n",
        "      raise ValueError(f\"Voting mechanism: {VOTING} not supported\")\n",
        "\n",
        "    return accuracy_score(prediction, np.argmax(Y, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVqdcrD_vQ-Q",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLQOYIh0OW84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for run in range(1, NR_OF_RUNS+1):\n",
        "\n",
        "    # Split the data\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.20, shuffle= True)\n",
        "\n",
        "    models = []\n",
        "    accuracies = [0]\n",
        "    patience = 0\n",
        "\n",
        "    for i in count(1):\n",
        "\n",
        "        print(f\"\\n ===== Train model {i} =====\")\n",
        "\n",
        "        # Set the seeds\n",
        "        np.random.seed(run*i)\n",
        "        tf.random.set_seed(run*i)\n",
        "\n",
        "        # Create directories\n",
        "        os.makedirs(PATH + MODEL_NAME + f\"/{run}/history\", exist_ok=True)\n",
        "        os.makedirs(PATH + MODEL_NAME + f\"/{run}/weights\", exist_ok=True)\n",
        "\n",
        "        # Create the model\n",
        "        model = CIFARmodel(IMAGE_SIZE, NUM_CLASSES, 3)\n",
        "        \n",
        "        # Load the weighs if the model is already trained\n",
        "        weights_path = PATH + MODEL_NAME + f\"/{run}/weights/weights-{i}.h5\"\n",
        "\n",
        "        if os.path.exists(weights_path):\n",
        "            print(f\"Skipping training of model {i}: weights exists\")\n",
        "            model.load_weights(weights_path)\n",
        "        else:\n",
        "            es = EarlyStopping(min_delta=0.01, patience=3)\n",
        "            csv_logger = CSVLogger(PATH + MODEL_NAME + f\"/{run}/history/history-{i}.csv\", separator=';')\n",
        "\n",
        "            model.fit(x_train,y_train,\n",
        "                      batch_size = BATCH_SIZE,\n",
        "                      epochs = EPOCHS,\n",
        "                      validation_data = (x_val, y_val),\n",
        "                      shuffle = True,\n",
        "                      callbacks=[es, csv_logger])\n",
        "            \n",
        "            model.save_weights(weights_path)\n",
        "        \n",
        "        models.append(model)\n",
        "\n",
        "        acc = predict(models, x_val, y_val)\n",
        "        delta = acc - accuracies[-1]\n",
        "\n",
        "        accuracies.append(acc)\n",
        "\n",
        "        if delta >= MODEL_ADDITION_DELTA:\n",
        "          patience = 0\n",
        "        else:\n",
        "          patience += 1\n",
        "\n",
        "        print(f\"Model: {i} added. Resulting score: {acc}, Delta: {delta}, Patience: {patience}\")\n",
        "\n",
        "        if patience >= MODEL_ADDITION_PATIENCE:\n",
        "          break\n",
        "\n",
        "    # Results\n",
        "\n",
        "    ## Accuracy vs nr of models\n",
        "    ## Visualizing the accuracy vs the number of models in the ensamble\n",
        "\n",
        "    print(\"\\n ===== Accuracy vs nr of models =====\")\n",
        "\n",
        "    accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "    accuracy_df.insert(1, \"Nr of models\", accuracy_df.index)\n",
        "    accuracy_df.to_csv(PATH + MODEL_NAME + f\"/{run}/accuracy_{VOTING}.csv\")\n",
        "    display(accuracy_df)\n",
        "\n",
        "    ## Accuracy\n",
        "    ## The final accuracy of the ensamble on the test set\n",
        "    print(\"\\n ===== Accuracy ======\")\n",
        "\n",
        "    accuracy = predict(models, x_test, y_testc)\n",
        "    print(\"Accuracy: \" + str(accuracy))\n",
        "\n",
        "    ## Correlation between models\n",
        "    print(\"\\n ===== Correlation =====\")\n",
        "    predictions = []\n",
        "\n",
        "    for m in models:\n",
        "        predictions.append(np.argmax(m.predict(x_test), axis=1))\n",
        "    classified = []\n",
        "\n",
        "    for prediction in predictions:\n",
        "        classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])\n",
        "    correlation_matrix = []\n",
        "\n",
        "    for ix, x in enumerate(classified):\n",
        "      row = []\n",
        "      \n",
        "      for iy, y in enumerate(classified):\n",
        "        if (ix == iy):\n",
        "          row.append(np.nan)\n",
        "        else:\n",
        "          row.append(pearsonr(x,y)[0])\n",
        "\n",
        "      correlation_matrix.append(row)\n",
        "\n",
        "    correlation_matrix = np.array(correlation_matrix)\n",
        "    correlation_matrix_df = pd.DataFrame(correlation_matrix)\n",
        "    correlation_matrix_df.to_csv(PATH + MODEL_NAME + f\"/{run}/correlation_matrix_{VOTING}.csv\")\n",
        "    \n",
        "    display(correlation_matrix_df)\n",
        "    correlation = np.nanmean(correlation_matrix.flatten())\n",
        "    print(\"Average correlation: \" + str(correlation))\n",
        "\n",
        "    # Save the results\n",
        "    file = PATH + MODEL_NAME + f\"/results_{VOTING}.csv\"\n",
        "    df = pd.DataFrame([[run, accuracy, correlation]])\n",
        "\n",
        "    if not os.path.isfile(file):\n",
        "      df.to_csv(file, header=[\"run\", \"accuracy\", \"correlation\"], index=False)\n",
        "    else: # else it exists so append without writing the header\n",
        "      df.to_csv(file, mode='a', header=False, index=False)\n",
        "\n",
        "    clear_output(wait=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}