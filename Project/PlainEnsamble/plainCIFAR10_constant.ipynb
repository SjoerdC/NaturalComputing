{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"plainCIFAR10-constant.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"fde69AMuOpox","colab":{}},"source":["import keras\n","import cv2\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from itertools import count\n","from IPython.display import clear_output\n","from sklearn.metrics import accuracy_score\n","from keras.datasets import cifar10\n","from keras.applications.vgg16 import VGG16\n","from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n","from sklearn.model_selection import train_test_split\n","from keras.models import Model\n","from keras.callbacks import EarlyStopping, CSVLogger\n","from scipy.stats import pearsonr\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qYrab7qpOppj","colab":{}},"source":["BATCH_SIZE = 128\n","EPOCHS = 9999\n","IMAGE_SIZE = 32\n","NUM_CLASSES = 10\n","MODEL_ADDITION_DELTA = 0.01\n","MODEL_ADDITION_PATIENCE = 3\n","NR_OF_RUNS = 10\n","MODEL_NAME = \"CIFAR_10_bagging_constant\"\n","PATH = \"\"\n","VOTING = \"SOFT\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8QvEt97vF52","colab_type":"text"},"source":["# Preprocess"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XypdmBJROpp9","colab":{}},"source":["(x_train_val, y_train_val), (x_test, y_test) = cifar10.load_data()\n","\n","print('x_train shape:', x_train_val.shape)\n","print(x_train_val.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mo8yHyg-Opqo","colab":{}},"source":["# Convert class vectors to binary class matrices.\n","y_train_val = keras.utils.to_categorical(y_train_val, NUM_CLASSES)\n","y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a4SYRuKZaIwb","colab_type":"code","colab":{}},"source":["x_train_val = x_train_val.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train_val /= 255\n","x_test /= 255"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gIBGIrlkvOt0","colab_type":"text"},"source":["# Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zLWph6_aOpr2","colab":{}},"source":["def CIFARmodel(imsize, num_classes, num_channels):\n","    inputs = Input((imsize,imsize,num_channels))\n","    x = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(inputs)\n","    x = Conv2D(filters=64, kernel_size=(3,3), strides=2)(x)\n","    x = Activation('relu')(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n","    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', strides=2, padding='same')(x)\n","    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(filters=128, kernel_size=(1,1), activation='relu', padding='valid')(x)\n","    x = Conv2D(filters=10, kernel_size=(1,1),strides=(1,1), padding='valid')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    outputs = Activation('softmax')(x)\n","    \n","    model = Model(inputs=inputs, outputs=outputs)\n","\n","    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n","\n","    model.compile(loss='categorical_crossentropy',\n","                      optimizer=optimizer,\n","                      metrics=['accuracy'])\n","    \n","    weights_path = PATH + MODEL_NAME + f\"/start_weights.h5\"\n","\n","    if os.path.exists(weights_path):\n","        model.load_weights(weights_path)\n","    else:\n","        os.makedirs(PATH + MODEL_NAME, exist_ok=True)\n","        model.save_weights(weights_path)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbiuqESLvTOY","colab_type":"text"},"source":["# Predict"]},{"cell_type":"code","metadata":{"id":"JXFkx19XmqKe","colab_type":"code","colab":{}},"source":["def hard_voting(models, X):\n","    predictions = []\n","\n","    for m in models:\n","        predictions.append(np.argmax(m.predict(X), axis=1))\n","\n","    prediction = np.transpose(predictions)\n","    prediction = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=prediction)\n","\n","    return prediction\n","\n","def soft_voting(models, X):\n","    predictions = np.empty((len(X),0,NUM_CLASSES))\n","\n","    for m in models:\n","        pred = np.expand_dims(m.predict(X), axis=1)\n","        predictions = np.append(predictions, pred, axis=1)\n","\n","    predictions = np.apply_along_axis(np.transpose, axis=1, arr=predictions)\n","    predictions = np.mean(predictions, axis=1)\n","    prediction = np.argmax(predictions, axis=1)\n","\n","    return prediction\n","\n","def predict(models, X, Y):\n","    \n","    if VOTING == \"SOFT\":\n","      prediction = soft_voting(models, X)\n","    elif VOTING == \"HARD\":\n","      prediction = hard_voting(models, X)\n","    else:\n","      raise ValueError(f\"Voting mechanism: {VOTING} not supported\")\n","\n","    return accuracy_score(prediction, np.argmax(Y, axis=1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TVqdcrD_vQ-Q","colab_type":"text"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"yLQOYIh0OW84","colab_type":"code","colab":{}},"source":["for run in range(1, NR_OF_RUNS+1):\n","\n","    # Split the data\n","    x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.20, shuffle= True)\n","\n","    models = []\n","    accuracies = [0]\n","    patience = 0\n","\n","    for i in count(1):\n","\n","        print(f\"\\n ===== Train model {i} =====\")\n","\n","        # Set the seeds\n","        np.random.seed(run*i)\n","        tf.random.set_seed(run*i)\n","\n","        # Create directories\n","        os.makedirs(PATH + MODEL_NAME + f\"/{run}/history\", exist_ok=True)\n","        os.makedirs(PATH + MODEL_NAME + f\"/{run}/weights\", exist_ok=True)\n","\n","        # Create the model\n","        model = CIFARmodel(IMAGE_SIZE, NUM_CLASSES, 3)\n","        \n","        # Load the weighs if the model is already trained\n","        weights_path = PATH + MODEL_NAME + f\"/{run}/weights/weights-{i}.h5\"\n","\n","        if os.path.exists(weights_path):\n","            print(f\"Skipping training of model {i}: weights exists\")\n","            model.load_weights(weights_path)\n","        else:\n","            es = EarlyStopping(min_delta=0.01, patience=3)\n","            csv_logger = CSVLogger(PATH + MODEL_NAME + f\"/{run}/history/history-{i}.csv\", separator=';')\n","\n","            model.fit(x_train,y_train,\n","                      batch_size = BATCH_SIZE,\n","                      epochs = EPOCHS,\n","                      validation_data = (x_val, y_val),\n","                      shuffle = True,\n","                      callbacks=[es, csv_logger])\n","            \n","            model.save_weights(weights_path)\n","        \n","        models.append(model)\n","\n","        acc = predict(models, x_val, y_val)\n","        delta = acc - accuracies[-1]\n","\n","        accuracies.append(acc)\n","\n","        if delta >= MODEL_ADDITION_DELTA:\n","          patience = 0\n","        else:\n","          patience += 1\n","\n","        print(f\"Model: {i} added. Resulting score: {acc}, Delta: {delta}, Patience: {patience}\")\n","\n","        if patience >= MODEL_ADDITION_PATIENCE:\n","          break\n","\n","    # Results\n","\n","    ## Accuracy vs nr of models\n","    ## Visualizing the accuracy vs the number of models in the ensamble\n","\n","    print(\"\\n ===== Accuracy vs nr of models =====\")\n","\n","    accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n","    accuracy_df.insert(1, \"Nr of models\", accuracy_df.index)\n","    accuracy_df.to_csv(PATH + MODEL_NAME + f\"/{run}/accuracy_{VOTING}.csv\")\n","    display(accuracy_df)\n","\n","    ## Accuracy\n","    ## The final accuracy of the ensamble on the test set\n","    print(\"\\n ===== Accuracy ======\")\n","\n","    accuracy = predict(models, x_test, y_testc)\n","    print(\"Accuracy: \" + str(accuracy))\n","\n","    ## Correlation between models\n","    print(\"\\n ===== Correlation =====\")\n","    predictions = []\n","\n","    for m in models:\n","        predictions.append(np.argmax(m.predict(x_test), axis=1))\n","    classified = []\n","\n","    for prediction in predictions:\n","        classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])\n","    correlation_matrix = []\n","\n","    for ix, x in enumerate(classified):\n","      row = []\n","      \n","      for iy, y in enumerate(classified):\n","        if (ix == iy):\n","          row.append(np.nan)\n","        else:\n","          row.append(pearsonr(x,y)[0])\n","\n","      correlation_matrix.append(row)\n","\n","    correlation_matrix = np.array(correlation_matrix)\n","    correlation_matrix_df = pd.DataFrame(correlation_matrix)\n","    correlation_matrix_df.to_csv(PATH + MODEL_NAME + f\"/{run}/correlation_matrix_{VOTING}.csv\")\n","    \n","    display(correlation_matrix_df)\n","    correlation = np.nanmean(correlation_matrix.flatten())\n","    print(\"Average correlation: \" + str(correlation))\n","\n","    # Save the results\n","    file = PATH + MODEL_NAME + f\"/results_{VOTING}.csv\"\n","    df = pd.DataFrame([[run, accuracy, correlation]])\n","\n","    if not os.path.isfile(file):\n","      df.to_csv(file, header=[\"run\", \"accuracy\", \"correlation\"], index=False)\n","    else: # else it exists so append without writing the header\n","      df.to_csv(file, mode='a', header=False, index=False)\n","\n","    clear_output(wait=True)"],"execution_count":null,"outputs":[]}]}