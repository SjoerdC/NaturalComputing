{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baggingMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import count\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import mnist\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, CSVLogger\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 9999\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "NR_OF_RUNS = 10\n",
        "MODEL_NAME = \"MNIST_bagging\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8QvEt97vF52",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtJIUBsFKeRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "colab": {}
      },
      "source": [
        "(x_train_val, y_train_val), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train_val = preprocess(x_train_val)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train_val.shape)\n",
        "print(x_train_val.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train_val = keras.utils.to_categorical(y_train_val, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SYRuKZaIwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_val = x_train_val.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train_val /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIBGIrlkvOt0",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def MNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbiuqESLvTOY",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFkx19XmqKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(models, X, Y):\n",
        "    predictions = np.empty((len(X),0,NUM_CLASSES))\n",
        "\n",
        "    for m in tqdm(models):\n",
        "        pred = np.expand_dims(m.predict(X), axis=1)\n",
        "        predictions = np.append(predictions, pred, axis=1)\n",
        "\n",
        "    predictions = np.apply_along_axis(np.transpose, axis=1, arr=predictions)\n",
        "    predictions = np.mean(predictions, axis=1)\n",
        "    prediction = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return accuracy_score(prediction, np.argmax(Y, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVqdcrD_vQ-Q",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLQOYIh0OW84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for run in range(0, NR_OF_RUNS):\n",
        "\n",
        "    # Set the seeds\n",
        "    np.random.seed(run)\n",
        "    tf.random.set_seed(run)\n",
        "\n",
        "    # Split the data\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.20, shuffle= True)\n",
        "\n",
        "    models = []\n",
        "    accuracies = [0]\n",
        "    patience = 0\n",
        "\n",
        "    for i in count(1):\n",
        "\n",
        "        print(f\"Train model {i}\")\n",
        "\n",
        "        # Create directories\n",
        "        os.makedirs(PATH + MODEL_NAME + f\"/{run}/history\", exist_ok=True)\n",
        "        os.makedirs(PATH + MODEL_NAME + f\"/{run}/weights\", exist_ok=True)\n",
        "\n",
        "        # Bootstrapping\n",
        "        idx = np.random.choice(len(x_train), size=len(x_train), replace=True)\n",
        "\n",
        "        x_train_model = x_train[idx]\n",
        "        y_train_model = y_train[idx]\n",
        "\n",
        "        # Create the model\n",
        "        model = MNISTmodel(IMAGE_SIZE, NUM_CLASSES, 1)\n",
        "        \n",
        "        es = EarlyStopping(min_delta=0.01, patience=3)\n",
        "        csv_logger = CSVLogger(PATH + MODEL_NAME + f\"/{run}/history/history-{i}.csv\", separator=';')\n",
        "\n",
        "        model.fit(x_train_model,y_train_model,\n",
        "                  batch_size = BATCH_SIZE,\n",
        "                  epochs = EPOCHS,\n",
        "                  validation_data = (x_val, y_val),\n",
        "                  shuffle = True,\n",
        "                  callbacks=[es, csv_logger])\n",
        "        \n",
        "        model.save_weights(PATH + MODEL_NAME + f\"/{run}/weights/weights-{i}.h5\" )\n",
        "        models.append(model)\n",
        "\n",
        "        acc = predict(models, x_val, y_val)\n",
        "        delta = acc - accuracies[-1]\n",
        "\n",
        "        accuracies.append(acc)\n",
        "\n",
        "        if delta >= MODEL_ADDITION_DELTA:\n",
        "          patience = 0\n",
        "        else:\n",
        "          patience += 1\n",
        "\n",
        "        print(f\"Model: {i} added. Resulting score: {acc}, Delta: {delta}, Patience: {patience}\")\n",
        "\n",
        "        if patience >= MODEL_ADDITION_PATIENCE:\n",
        "          break\n",
        "\n",
        "    # Results\n",
        "\n",
        "    ## Accuracy vs nr of models\n",
        "    ## Visualizing the accuracy vs the number of models in the ensamble\n",
        "\n",
        "    print(\"Accuracy vs nr of models\")\n",
        "\n",
        "    accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "    accuracy_df.insert(1, \"Nr of models\", accuracy_df.index)\n",
        "\n",
        "    display(accuracy_df)\n",
        "    accuracy_df.to_csv(PATH + MODEL_NAME + f\"/{run}/accuracy.csv\")\n",
        "\n",
        "\n",
        "    accuracy_df = accuracy_df.iloc[1:]\n",
        "    accuracy_df.plot(x=\"Nr of models\", y=\"Accuracy\", xticks=accuracy_df[\"Nr of models\"])\n",
        "    plt.show()\n",
        "\n",
        "    ## Accuracy\n",
        "    ## The final accuracy of the ensamble on the test set\n",
        "    print(\"Accuracy\")\n",
        "\n",
        "    accuracy = predict(models, x_test, y_testc)\n",
        "    print(\"Accuracy: \" + str(accuracy))\n",
        "\n",
        "    ## Correlation between models\n",
        "    print(\"Correlation\")\n",
        "    predictions = []\n",
        "\n",
        "    for m in tqdm(models):\n",
        "        predictions.append(np.argmax(m.predict(x_test), axis=1))\n",
        "    classified = []\n",
        "\n",
        "    for prediction in tqdm(predictions):\n",
        "        classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])\n",
        "    correlation_matrix = []\n",
        "\n",
        "    for ix, x in enumerate(classified):\n",
        "      row = []\n",
        "      \n",
        "      for iy, y in enumerate(classified):\n",
        "        if (ix == iy):\n",
        "          row.append(np.nan)\n",
        "        else:\n",
        "          row.append(pearsonr(x,y)[0])\n",
        "\n",
        "      correlation_matrix.append(row)\n",
        "\n",
        "    correlation_matrix = np.array(correlation_matrix)\n",
        "    correlation_matrix_df = pd.DataFrame(correlation_matrix)\n",
        "    correlation_matrix_df.to_csv(PATH + MODEL_NAME + f\"/{run}/correlation_matrix.csv\")\n",
        "    \n",
        "    display(correlation_matrix_df)\n",
        "    correlation = np.nanmean(correlation_matrix.flatten())\n",
        "    print(\"Average correlation: \" + str(correlation))\n",
        "\n",
        "    # Save the results\n",
        "    file = PATH + MODEL_NAME + \"/results.csv\"\n",
        "    df = pd.DataFrame([[run, accuracy, correlation]])\n",
        "\n",
        "    if not os.path.isfile(file):\n",
        "      df.to_csv(file, header=[\"run\", \"accuracy\", \"correlation\"], index=False)\n",
        "    else: # else it exists so append without writing the header\n",
        "      df.to_csv(file, mode='a', header=False, index=False)\n",
        "\n",
        "    clear_output(wait=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}