{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baggingMNISTFashion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 9999\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"MNIST_Fashion_bagging\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9M4_-IaBOsn",
        "colab_type": "text"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n9nJGd_BQ-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8QvEt97vF52",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtJIUBsFKeRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "5667c565-f147-46ac-f406-4d2cdfa51a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SYRuKZaIwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLQOYIh0OW84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIBGIrlkvOt0",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbiuqESLvTOY",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFkx19XmqKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(models, X, Y):\n",
        "    predictions = []\n",
        "\n",
        "    for m in tqdm(models):\n",
        "        predictions.append(np.argmax(m.predict(X), axis=1))\n",
        "\n",
        "    prediction = np.transpose(predictions)\n",
        "    prediction = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=prediction)\n",
        "\n",
        "    return accuracy_score(prediction, np.argmax(Y, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVqdcrD_vQ-Q",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "2a16f072-540a-47ec-b45f-36785ca0e379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = [0]\n",
        "patience = 0\n",
        "\n",
        "for i in count(1):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "    idx = np.random.choice(len(x_train), size=len(x_train), replace=True)\n",
        "\n",
        "    x_train_model = x_train[idx]\n",
        "    y_train_model = y_train[idx]\n",
        "\n",
        "    model = FashionMNISTmodel(IMAGE_SIZE, NUM_CLASSES, 1)\n",
        "    \n",
        "    es = EarlyStopping(min_delta=0.01, patience=3)\n",
        "    model.fit(x_train_model,y_train_model,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = EPOCHS,\n",
        "              validation_data = (x_val,y_val),\n",
        "              shuffle = True,\n",
        "              callbacks=[es])\n",
        "    \n",
        "    model.save_weights(PATH + MODEL_NAME + f\"_weights-{i}.h5\" )\n",
        "    models.append(model)\n",
        "\n",
        "    acc = predict(models, x_val, y_val)\n",
        "    delta = acc - accuracies[-1]\n",
        "\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    if delta >= MODEL_ADDITION_DELTA:\n",
        "      patience = 0\n",
        "    else:\n",
        "      patience += 1\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}, Delta: {delta}, Patience: {patience}\")\n",
        "\n",
        "    if patience >= MODEL_ADDITION_PATIENCE:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 1\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 2.2231 - accuracy: 0.2218 - val_loss: 2.2163 - val_accuracy: 0.2464\n",
            "Epoch 2/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.9920 - accuracy: 0.3408 - val_loss: 1.9026 - val_accuracy: 0.3859\n",
            "Epoch 3/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.7712 - accuracy: 0.3977 - val_loss: 1.6812 - val_accuracy: 0.4026\n",
            "Epoch 4/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 1.5902 - accuracy: 0.4460 - val_loss: 1.5200 - val_accuracy: 0.4755\n",
            "Epoch 5/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.4567 - accuracy: 0.5061 - val_loss: 1.4009 - val_accuracy: 0.5352\n",
            "Epoch 6/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.3559 - accuracy: 0.5501 - val_loss: 1.3171 - val_accuracy: 0.5653\n",
            "Epoch 7/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.2747 - accuracy: 0.5817 - val_loss: 1.2419 - val_accuracy: 0.5928\n",
            "Epoch 8/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.2089 - accuracy: 0.6031 - val_loss: 1.1819 - val_accuracy: 0.6074\n",
            "Epoch 9/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 1.1538 - accuracy: 0.6188 - val_loss: 1.1331 - val_accuracy: 0.6229\n",
            "Epoch 10/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 1.1078 - accuracy: 0.6312 - val_loss: 1.0931 - val_accuracy: 0.6357\n",
            "Epoch 11/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.0693 - accuracy: 0.6416 - val_loss: 1.0608 - val_accuracy: 0.6403\n",
            "Epoch 12/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.0373 - accuracy: 0.6501 - val_loss: 1.0288 - val_accuracy: 0.6540\n",
            "Epoch 13/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.0095 - accuracy: 0.6572 - val_loss: 1.0022 - val_accuracy: 0.6623\n",
            "Epoch 14/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9834 - accuracy: 0.6666 - val_loss: 0.9793 - val_accuracy: 0.6719\n",
            "Epoch 15/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9601 - accuracy: 0.6739 - val_loss: 0.9598 - val_accuracy: 0.6758\n",
            "Epoch 16/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9400 - accuracy: 0.6813 - val_loss: 0.9416 - val_accuracy: 0.6797\n",
            "Epoch 17/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.9220 - accuracy: 0.6862 - val_loss: 0.9260 - val_accuracy: 0.6833\n",
            "Epoch 18/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.9048 - accuracy: 0.6922 - val_loss: 0.9089 - val_accuracy: 0.6948\n",
            "Epoch 19/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8885 - accuracy: 0.6984 - val_loss: 0.8950 - val_accuracy: 0.6977\n",
            "Epoch 20/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8744 - accuracy: 0.7039 - val_loss: 0.8817 - val_accuracy: 0.7013\n",
            "Epoch 21/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8604 - accuracy: 0.7085 - val_loss: 0.8675 - val_accuracy: 0.7106\n",
            "Epoch 22/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8476 - accuracy: 0.7125 - val_loss: 0.8582 - val_accuracy: 0.7122\n",
            "Epoch 23/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8369 - accuracy: 0.7154 - val_loss: 0.8470 - val_accuracy: 0.7138\n",
            "Epoch 24/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.8246 - accuracy: 0.7216 - val_loss: 0.8373 - val_accuracy: 0.7177\n",
            "Epoch 25/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8151 - accuracy: 0.7238 - val_loss: 0.8262 - val_accuracy: 0.7223\n",
            "Epoch 26/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8056 - accuracy: 0.7266 - val_loss: 0.8176 - val_accuracy: 0.7235\n",
            "Epoch 27/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7982 - accuracy: 0.7296 - val_loss: 0.8100 - val_accuracy: 0.7283\n",
            "Epoch 28/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7874 - accuracy: 0.7334 - val_loss: 0.8003 - val_accuracy: 0.7306\n",
            "Epoch 29/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7802 - accuracy: 0.7353 - val_loss: 0.7957 - val_accuracy: 0.7309\n",
            "Epoch 30/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7714 - accuracy: 0.7379 - val_loss: 0.7864 - val_accuracy: 0.7331\n",
            "Epoch 31/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.7641 - accuracy: 0.7400 - val_loss: 0.7797 - val_accuracy: 0.7387\n",
            "Epoch 32/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7582 - accuracy: 0.7421 - val_loss: 0.7728 - val_accuracy: 0.7398\n",
            "Epoch 33/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7520 - accuracy: 0.7449 - val_loss: 0.7674 - val_accuracy: 0.7409\n",
            "Epoch 34/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.7448 - accuracy: 0.7469 - val_loss: 0.7604 - val_accuracy: 0.7448\n",
            "Epoch 35/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7390 - accuracy: 0.7486 - val_loss: 0.7553 - val_accuracy: 0.7467\n",
            "Epoch 36/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7333 - accuracy: 0.7515 - val_loss: 0.7505 - val_accuracy: 0.7468\n",
            "Epoch 37/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7275 - accuracy: 0.7534 - val_loss: 0.7460 - val_accuracy: 0.7459\n",
            "Epoch 38/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7230 - accuracy: 0.7543 - val_loss: 0.7406 - val_accuracy: 0.7473\n",
            "Epoch 39/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7183 - accuracy: 0.7565 - val_loss: 0.7366 - val_accuracy: 0.7527\n",
            "Epoch 40/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7139 - accuracy: 0.7570 - val_loss: 0.7311 - val_accuracy: 0.7540\n",
            "Epoch 41/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7084 - accuracy: 0.7601 - val_loss: 0.7256 - val_accuracy: 0.7533\n",
            "Epoch 42/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7048 - accuracy: 0.7595 - val_loss: 0.7235 - val_accuracy: 0.7511\n",
            "Epoch 43/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7008 - accuracy: 0.7605 - val_loss: 0.7185 - val_accuracy: 0.7575\n",
            "Epoch 44/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6966 - accuracy: 0.7632 - val_loss: 0.7139 - val_accuracy: 0.7583\n",
            "Epoch 45/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.6932 - accuracy: 0.7638 - val_loss: 0.7102 - val_accuracy: 0.7599\n",
            "Epoch 46/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.6898 - accuracy: 0.7646 - val_loss: 0.7067 - val_accuracy: 0.7588\n",
            "Epoch 47/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6858 - accuracy: 0.7676 - val_loss: 0.7036 - val_accuracy: 0.7617\n",
            "Epoch 48/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6819 - accuracy: 0.7666 - val_loss: 0.6993 - val_accuracy: 0.7617\n",
            "Epoch 49/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.6787 - accuracy: 0.7683 - val_loss: 0.6962 - val_accuracy: 0.7646\n",
            "Epoch 50/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6759 - accuracy: 0.7687 - val_loss: 0.6935 - val_accuracy: 0.7645\n",
            "Epoch 51/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6728 - accuracy: 0.7703 - val_loss: 0.6931 - val_accuracy: 0.7621\n",
            "Epoch 52/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6700 - accuracy: 0.7714 - val_loss: 0.6885 - val_accuracy: 0.7662\n",
            "Epoch 53/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.6681 - accuracy: 0.7717 - val_loss: 0.6861 - val_accuracy: 0.7664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 1 added. Resulting score: 0.7664166666666666, Delta: 0.7664166666666666, Patience: 0\n",
            "Train model 2\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 2.1596 - accuracy: 0.2209 - val_loss: 2.1894 - val_accuracy: 0.2954\n",
            "Epoch 2/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.9184 - accuracy: 0.3455 - val_loss: 1.8189 - val_accuracy: 0.4348\n",
            "Epoch 3/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 1.6758 - accuracy: 0.4769 - val_loss: 1.5672 - val_accuracy: 0.5063\n",
            "Epoch 4/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.4812 - accuracy: 0.5471 - val_loss: 1.4010 - val_accuracy: 0.5558\n",
            "Epoch 5/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.3437 - accuracy: 0.5831 - val_loss: 1.2902 - val_accuracy: 0.5922\n",
            "Epoch 6/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.2500 - accuracy: 0.6024 - val_loss: 1.2071 - val_accuracy: 0.6198\n",
            "Epoch 7/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.1803 - accuracy: 0.6190 - val_loss: 1.1484 - val_accuracy: 0.6285\n",
            "Epoch 8/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.1277 - accuracy: 0.6277 - val_loss: 1.1039 - val_accuracy: 0.6401\n",
            "Epoch 9/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.0861 - accuracy: 0.6384 - val_loss: 1.0681 - val_accuracy: 0.6466\n",
            "Epoch 10/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.0539 - accuracy: 0.6447 - val_loss: 1.0383 - val_accuracy: 0.6584\n",
            "Epoch 11/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.0253 - accuracy: 0.6526 - val_loss: 1.0128 - val_accuracy: 0.6605\n",
            "Epoch 12/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 1.0016 - accuracy: 0.6595 - val_loss: 0.9931 - val_accuracy: 0.6646\n",
            "Epoch 13/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.9800 - accuracy: 0.6654 - val_loss: 0.9694 - val_accuracy: 0.6790\n",
            "Epoch 14/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.9599 - accuracy: 0.6722 - val_loss: 0.9516 - val_accuracy: 0.6827\n",
            "Epoch 15/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9422 - accuracy: 0.6789 - val_loss: 0.9382 - val_accuracy: 0.6859\n",
            "Epoch 16/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9261 - accuracy: 0.6846 - val_loss: 0.9233 - val_accuracy: 0.6892\n",
            "Epoch 17/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9128 - accuracy: 0.6888 - val_loss: 0.9065 - val_accuracy: 0.7010\n",
            "Epoch 18/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8988 - accuracy: 0.6942 - val_loss: 0.8934 - val_accuracy: 0.7026\n",
            "Epoch 19/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8858 - accuracy: 0.6986 - val_loss: 0.8817 - val_accuracy: 0.7070\n",
            "Epoch 20/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8739 - accuracy: 0.7033 - val_loss: 0.8688 - val_accuracy: 0.7126\n",
            "Epoch 21/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.8612 - accuracy: 0.7082 - val_loss: 0.8588 - val_accuracy: 0.7122\n",
            "Epoch 22/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8496 - accuracy: 0.7125 - val_loss: 0.8476 - val_accuracy: 0.7184\n",
            "Epoch 23/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8391 - accuracy: 0.7163 - val_loss: 0.8381 - val_accuracy: 0.7220\n",
            "Epoch 24/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8293 - accuracy: 0.7200 - val_loss: 0.8282 - val_accuracy: 0.7246\n",
            "Epoch 25/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8192 - accuracy: 0.7251 - val_loss: 0.8176 - val_accuracy: 0.7324\n",
            "Epoch 26/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.8089 - accuracy: 0.7268 - val_loss: 0.8090 - val_accuracy: 0.7335\n",
            "Epoch 27/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.7997 - accuracy: 0.7311 - val_loss: 0.8008 - val_accuracy: 0.7358\n",
            "Epoch 28/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7914 - accuracy: 0.7339 - val_loss: 0.7908 - val_accuracy: 0.7403\n",
            "Epoch 29/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7843 - accuracy: 0.7361 - val_loss: 0.7894 - val_accuracy: 0.7360\n",
            "Epoch 30/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7749 - accuracy: 0.7400 - val_loss: 0.7758 - val_accuracy: 0.7451\n",
            "Epoch 31/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.7677 - accuracy: 0.7424 - val_loss: 0.7693 - val_accuracy: 0.7471\n",
            "Epoch 32/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.7616 - accuracy: 0.7434 - val_loss: 0.7640 - val_accuracy: 0.7467\n",
            "Epoch 33/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7537 - accuracy: 0.7461 - val_loss: 0.7564 - val_accuracy: 0.7511\n",
            "Epoch 34/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7492 - accuracy: 0.7485 - val_loss: 0.7525 - val_accuracy: 0.7518\n",
            "Epoch 35/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7429 - accuracy: 0.7499 - val_loss: 0.7460 - val_accuracy: 0.7542\n",
            "Epoch 36/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7379 - accuracy: 0.7517 - val_loss: 0.7399 - val_accuracy: 0.7548\n",
            "Epoch 37/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7308 - accuracy: 0.7540 - val_loss: 0.7364 - val_accuracy: 0.7581\n",
            "Epoch 38/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7268 - accuracy: 0.7546 - val_loss: 0.7312 - val_accuracy: 0.7601\n",
            "Epoch 39/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7220 - accuracy: 0.7561 - val_loss: 0.7256 - val_accuracy: 0.7596\n",
            "Epoch 40/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7163 - accuracy: 0.7585 - val_loss: 0.7203 - val_accuracy: 0.7633\n",
            "Epoch 41/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.7133 - accuracy: 0.7593 - val_loss: 0.7179 - val_accuracy: 0.7636\n",
            "Epoch 42/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.7086 - accuracy: 0.7610 - val_loss: 0.7124 - val_accuracy: 0.7640\n",
            "Epoch 43/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7042 - accuracy: 0.7620 - val_loss: 0.7089 - val_accuracy: 0.7637\n",
            "Epoch 44/9999\n",
            "48000/48000 [==============================] - 2s 43us/step - loss: 0.7006 - accuracy: 0.7624 - val_loss: 0.7059 - val_accuracy: 0.7665\n",
            "Epoch 45/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6967 - accuracy: 0.7649 - val_loss: 0.7015 - val_accuracy: 0.7680\n",
            "Epoch 46/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6930 - accuracy: 0.7648 - val_loss: 0.6971 - val_accuracy: 0.7679\n",
            "Epoch 47/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6899 - accuracy: 0.7661 - val_loss: 0.6966 - val_accuracy: 0.7657\n",
            "Epoch 48/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.6858 - accuracy: 0.7665 - val_loss: 0.6902 - val_accuracy: 0.7702\n",
            "Epoch 49/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6816 - accuracy: 0.7683 - val_loss: 0.6896 - val_accuracy: 0.7692\n",
            "Epoch 50/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6781 - accuracy: 0.7704 - val_loss: 0.6834 - val_accuracy: 0.7714\n",
            "Epoch 51/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6756 - accuracy: 0.7708 - val_loss: 0.6795 - val_accuracy: 0.7726\n",
            "Epoch 52/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.6722 - accuracy: 0.7711 - val_loss: 0.6767 - val_accuracy: 0.7735\n",
            "Epoch 53/9999\n",
            "48000/48000 [==============================] - 2s 44us/step - loss: 0.6694 - accuracy: 0.7724 - val_loss: 0.6740 - val_accuracy: 0.7746\n",
            "Epoch 54/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.6667 - accuracy: 0.7733 - val_loss: 0.6735 - val_accuracy: 0.7734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  2.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 2 added. Resulting score: 0.76775, Delta: 0.0013333333333334085, Patience: 1\n",
            "Train model 3\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 2.1666 - accuracy: 0.2370 - val_loss: 2.1927 - val_accuracy: 0.2992\n",
            "Epoch 2/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.9106 - accuracy: 0.3816 - val_loss: 1.8120 - val_accuracy: 0.4329\n",
            "Epoch 3/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.6930 - accuracy: 0.4589 - val_loss: 1.5983 - val_accuracy: 0.4793\n",
            "Epoch 4/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.5278 - accuracy: 0.5086 - val_loss: 1.4563 - val_accuracy: 0.5416\n",
            "Epoch 5/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.4053 - accuracy: 0.5560 - val_loss: 1.3518 - val_accuracy: 0.5782\n",
            "Epoch 6/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 1.3127 - accuracy: 0.5896 - val_loss: 1.2709 - val_accuracy: 0.6090\n",
            "Epoch 7/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.2402 - accuracy: 0.6118 - val_loss: 1.2074 - val_accuracy: 0.6242\n",
            "Epoch 8/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.1803 - accuracy: 0.6295 - val_loss: 1.1527 - val_accuracy: 0.6398\n",
            "Epoch 9/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.1307 - accuracy: 0.6435 - val_loss: 1.1084 - val_accuracy: 0.6511\n",
            "Epoch 10/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.0890 - accuracy: 0.6536 - val_loss: 1.0713 - val_accuracy: 0.6632\n",
            "Epoch 11/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.0540 - accuracy: 0.6624 - val_loss: 1.0398 - val_accuracy: 0.6671\n",
            "Epoch 12/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.0247 - accuracy: 0.6701 - val_loss: 1.0119 - val_accuracy: 0.6736\n",
            "Epoch 13/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9980 - accuracy: 0.6755 - val_loss: 0.9888 - val_accuracy: 0.6848\n",
            "Epoch 14/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9742 - accuracy: 0.6821 - val_loss: 0.9674 - val_accuracy: 0.6911\n",
            "Epoch 15/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.9530 - accuracy: 0.6900 - val_loss: 0.9465 - val_accuracy: 0.6949\n",
            "Epoch 16/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.9338 - accuracy: 0.6951 - val_loss: 0.9283 - val_accuracy: 0.7020\n",
            "Epoch 17/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.9160 - accuracy: 0.7003 - val_loss: 0.9127 - val_accuracy: 0.7027\n",
            "Epoch 18/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8993 - accuracy: 0.7049 - val_loss: 0.8974 - val_accuracy: 0.7070\n",
            "Epoch 19/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8846 - accuracy: 0.7094 - val_loss: 0.8830 - val_accuracy: 0.7137\n",
            "Epoch 20/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8704 - accuracy: 0.7143 - val_loss: 0.8690 - val_accuracy: 0.7159\n",
            "Epoch 21/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8575 - accuracy: 0.7161 - val_loss: 0.8576 - val_accuracy: 0.7225\n",
            "Epoch 22/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8450 - accuracy: 0.7224 - val_loss: 0.8457 - val_accuracy: 0.7243\n",
            "Epoch 23/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8347 - accuracy: 0.7240 - val_loss: 0.8366 - val_accuracy: 0.7270\n",
            "Epoch 24/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8232 - accuracy: 0.7281 - val_loss: 0.8251 - val_accuracy: 0.7306\n",
            "Epoch 25/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8135 - accuracy: 0.7301 - val_loss: 0.8158 - val_accuracy: 0.7326\n",
            "Epoch 26/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8038 - accuracy: 0.7330 - val_loss: 0.8069 - val_accuracy: 0.7352\n",
            "Epoch 27/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7953 - accuracy: 0.7355 - val_loss: 0.7979 - val_accuracy: 0.7383\n",
            "Epoch 28/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7870 - accuracy: 0.7387 - val_loss: 0.7911 - val_accuracy: 0.7406\n",
            "Epoch 29/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7800 - accuracy: 0.7410 - val_loss: 0.7854 - val_accuracy: 0.7386\n",
            "Epoch 30/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7714 - accuracy: 0.7427 - val_loss: 0.7762 - val_accuracy: 0.7423\n",
            "Epoch 31/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7648 - accuracy: 0.7457 - val_loss: 0.7703 - val_accuracy: 0.7452\n",
            "Epoch 32/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7574 - accuracy: 0.7474 - val_loss: 0.7643 - val_accuracy: 0.7483\n",
            "Epoch 33/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7516 - accuracy: 0.7498 - val_loss: 0.7575 - val_accuracy: 0.7477\n",
            "Epoch 34/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.7457 - accuracy: 0.7514 - val_loss: 0.7525 - val_accuracy: 0.7495\n",
            "Epoch 35/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7404 - accuracy: 0.7525 - val_loss: 0.7473 - val_accuracy: 0.7511\n",
            "Epoch 36/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7352 - accuracy: 0.7533 - val_loss: 0.7440 - val_accuracy: 0.7507\n",
            "Epoch 37/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7297 - accuracy: 0.7548 - val_loss: 0.7395 - val_accuracy: 0.7505\n",
            "Epoch 38/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7256 - accuracy: 0.7575 - val_loss: 0.7326 - val_accuracy: 0.7539\n",
            "Epoch 39/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7209 - accuracy: 0.7564 - val_loss: 0.7298 - val_accuracy: 0.7536\n",
            "Epoch 40/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7179 - accuracy: 0.7584 - val_loss: 0.7248 - val_accuracy: 0.7563\n",
            "Epoch 41/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7126 - accuracy: 0.7605 - val_loss: 0.7205 - val_accuracy: 0.7570\n",
            "Epoch 42/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7086 - accuracy: 0.7616 - val_loss: 0.7167 - val_accuracy: 0.7575\n",
            "Epoch 43/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7046 - accuracy: 0.7625 - val_loss: 0.7145 - val_accuracy: 0.7567\n",
            "Epoch 44/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7010 - accuracy: 0.7638 - val_loss: 0.7101 - val_accuracy: 0.7597\n",
            "Epoch 45/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.6985 - accuracy: 0.7649 - val_loss: 0.7071 - val_accuracy: 0.7592\n",
            "Epoch 46/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.6957 - accuracy: 0.7650 - val_loss: 0.7041 - val_accuracy: 0.7613\n",
            "Epoch 47/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6918 - accuracy: 0.7659 - val_loss: 0.7018 - val_accuracy: 0.7628\n",
            "Epoch 48/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.6883 - accuracy: 0.7675 - val_loss: 0.6970 - val_accuracy: 0.7632\n",
            "Epoch 49/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.6857 - accuracy: 0.7680 - val_loss: 0.6943 - val_accuracy: 0.7636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  2.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 3 added. Resulting score: 0.7751666666666667, Delta: 0.007416666666666627, Patience: 2\n",
            "Train model 4\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/9999\n",
            "48000/48000 [==============================] - 2s 46us/step - loss: 2.1957 - accuracy: 0.2355 - val_loss: 2.1877 - val_accuracy: 0.2937\n",
            "Epoch 2/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.9150 - accuracy: 0.3643 - val_loss: 1.8133 - val_accuracy: 0.4236\n",
            "Epoch 3/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 1.7006 - accuracy: 0.4357 - val_loss: 1.6097 - val_accuracy: 0.4710\n",
            "Epoch 4/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.5437 - accuracy: 0.4937 - val_loss: 1.4770 - val_accuracy: 0.5139\n",
            "Epoch 5/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.4284 - accuracy: 0.5379 - val_loss: 1.3779 - val_accuracy: 0.5538\n",
            "Epoch 6/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.3412 - accuracy: 0.5710 - val_loss: 1.3036 - val_accuracy: 0.5810\n",
            "Epoch 7/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.2718 - accuracy: 0.5902 - val_loss: 1.2401 - val_accuracy: 0.6043\n",
            "Epoch 8/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 1.2152 - accuracy: 0.6065 - val_loss: 1.1884 - val_accuracy: 0.6143\n",
            "Epoch 9/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 1.1666 - accuracy: 0.6202 - val_loss: 1.1453 - val_accuracy: 0.6269\n",
            "Epoch 10/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.1253 - accuracy: 0.6296 - val_loss: 1.1065 - val_accuracy: 0.6351\n",
            "Epoch 11/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.0892 - accuracy: 0.6383 - val_loss: 1.0735 - val_accuracy: 0.6435\n",
            "Epoch 12/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 1.0577 - accuracy: 0.6465 - val_loss: 1.0439 - val_accuracy: 0.6530\n",
            "Epoch 13/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 1.0286 - accuracy: 0.6556 - val_loss: 1.0227 - val_accuracy: 0.6567\n",
            "Epoch 14/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 1.0037 - accuracy: 0.6631 - val_loss: 0.9974 - val_accuracy: 0.6646\n",
            "Epoch 15/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.9819 - accuracy: 0.6671 - val_loss: 0.9752 - val_accuracy: 0.6733\n",
            "Epoch 16/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.9612 - accuracy: 0.6734 - val_loss: 0.9578 - val_accuracy: 0.6783\n",
            "Epoch 17/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.9441 - accuracy: 0.6808 - val_loss: 0.9409 - val_accuracy: 0.6817\n",
            "Epoch 18/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.9273 - accuracy: 0.6843 - val_loss: 0.9271 - val_accuracy: 0.6848\n",
            "Epoch 19/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.9121 - accuracy: 0.6904 - val_loss: 0.9123 - val_accuracy: 0.6923\n",
            "Epoch 20/9999\n",
            "48000/48000 [==============================] - 2s 42us/step - loss: 0.8979 - accuracy: 0.6942 - val_loss: 0.8992 - val_accuracy: 0.6975\n",
            "Epoch 21/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.8856 - accuracy: 0.6995 - val_loss: 0.8877 - val_accuracy: 0.6966\n",
            "Epoch 22/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.8730 - accuracy: 0.7041 - val_loss: 0.8763 - val_accuracy: 0.7029\n",
            "Epoch 23/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8619 - accuracy: 0.7073 - val_loss: 0.8653 - val_accuracy: 0.7042\n",
            "Epoch 24/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.8515 - accuracy: 0.7121 - val_loss: 0.8551 - val_accuracy: 0.7082\n",
            "Epoch 25/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.8415 - accuracy: 0.7150 - val_loss: 0.8463 - val_accuracy: 0.7101\n",
            "Epoch 26/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.8314 - accuracy: 0.7193 - val_loss: 0.8361 - val_accuracy: 0.7166\n",
            "Epoch 27/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.8228 - accuracy: 0.7215 - val_loss: 0.8275 - val_accuracy: 0.7186\n",
            "Epoch 28/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.8131 - accuracy: 0.7258 - val_loss: 0.8184 - val_accuracy: 0.7211\n",
            "Epoch 29/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.8041 - accuracy: 0.7280 - val_loss: 0.8115 - val_accuracy: 0.7249\n",
            "Epoch 30/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7977 - accuracy: 0.7314 - val_loss: 0.8036 - val_accuracy: 0.7260\n",
            "Epoch 31/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7890 - accuracy: 0.7345 - val_loss: 0.7951 - val_accuracy: 0.7282\n",
            "Epoch 32/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7828 - accuracy: 0.7359 - val_loss: 0.7888 - val_accuracy: 0.7305\n",
            "Epoch 33/9999\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.7747 - accuracy: 0.7390 - val_loss: 0.7831 - val_accuracy: 0.7382\n",
            "Epoch 34/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7683 - accuracy: 0.7429 - val_loss: 0.7751 - val_accuracy: 0.7354\n",
            "Epoch 35/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7610 - accuracy: 0.7449 - val_loss: 0.7704 - val_accuracy: 0.7368\n",
            "Epoch 36/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7551 - accuracy: 0.7460 - val_loss: 0.7661 - val_accuracy: 0.7429\n",
            "Epoch 37/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7490 - accuracy: 0.7493 - val_loss: 0.7574 - val_accuracy: 0.7428\n",
            "Epoch 38/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7426 - accuracy: 0.7511 - val_loss: 0.7523 - val_accuracy: 0.7486\n",
            "Epoch 39/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7368 - accuracy: 0.7535 - val_loss: 0.7467 - val_accuracy: 0.7488\n",
            "Epoch 40/9999\n",
            "48000/48000 [==============================] - 2s 41us/step - loss: 0.7319 - accuracy: 0.7560 - val_loss: 0.7416 - val_accuracy: 0.7486\n",
            "Epoch 41/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7276 - accuracy: 0.7566 - val_loss: 0.7374 - val_accuracy: 0.7509\n",
            "Epoch 42/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7222 - accuracy: 0.7579 - val_loss: 0.7321 - val_accuracy: 0.7538\n",
            "Epoch 43/9999\n",
            "48000/48000 [==============================] - 2s 40us/step - loss: 0.7171 - accuracy: 0.7606 - val_loss: 0.7294 - val_accuracy: 0.7548\n",
            "Epoch 44/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7125 - accuracy: 0.7601 - val_loss: 0.7216 - val_accuracy: 0.7592\n",
            "Epoch 45/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.7080 - accuracy: 0.7631 - val_loss: 0.7176 - val_accuracy: 0.7599\n",
            "Epoch 46/9999\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.7038 - accuracy: 0.7642 - val_loss: 0.7138 - val_accuracy: 0.7610\n",
            "Epoch 47/9999\n",
            "48000/48000 [==============================] - 2s 38us/step - loss: 0.7001 - accuracy: 0.7656 - val_loss: 0.7104 - val_accuracy: 0.7584\n",
            "Epoch 48/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.6943 - accuracy: 0.7676 - val_loss: 0.7067 - val_accuracy: 0.7622\n",
            "Epoch 49/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.6914 - accuracy: 0.7676 - val_loss: 0.7012 - val_accuracy: 0.7633\n",
            "Epoch 50/9999\n",
            "48000/48000 [==============================] - 2s 39us/step - loss: 0.6876 - accuracy: 0.7679 - val_loss: 0.7037 - val_accuracy: 0.7628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  2.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: 4 added. Resulting score: 0.7744166666666666, Delta: -0.0007500000000000284, Patience: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGT6jV-hcLbJ",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CurcmjMCcrJI",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy vs nr of models\n",
        "Visualizing the accuracy vs the number of models in the ensamble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvZLQyb5cg7R",
        "colab_type": "code",
        "outputId": "c5cd947b-e526-4a34-a5bb-9b0e4584cfda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "accuracy_df.insert(1, \"Nr of models\", accuracy_df.index)\n",
        "\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Nr of models</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.766417</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.767750</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.775167</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.774417</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy  Nr of models\n",
              "0  0.000000             0\n",
              "1  0.766417             1\n",
              "2  0.767750             2\n",
              "3  0.775167             3\n",
              "4  0.774417             4"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXq8Uj3lenzH",
        "colab_type": "code",
        "outputId": "8cef7ac3-0c97-4495-820a-4947411d4e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# remove first row\n",
        "accuracy_df = accuracy_df.iloc[1:]\n",
        "\n",
        "accuracy_df.plot(x=\"Nr of models\", y=\"Accuracy\", xticks=accuracy_df[\"Nr of models\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51rnX_l7Pfdr",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy\n",
        "The final accuracy of the ensamble on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwNmmvSFPlVx",
        "colab_type": "code",
        "outputId": "77dfd9e4-14fd-46ed-b070-af1b3d9b81c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Accuracy: \" + str(predict(models, x_test, y_testc)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  2.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMfc-h8xAYQu",
        "colab_type": "text"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N9wSXF1iSp3",
        "colab_type": "code",
        "outputId": "10fc1959-9073-497f-dcb0-402930c4b087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = []\n",
        "\n",
        "for m in tqdm(models):\n",
        "    predictions.append(np.argmax(m.predict(x_test), axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqxXArY8N4po",
        "colab_type": "code",
        "outputId": "65af30b0-aa96-4976-f5c6-ac5fdf97cdab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classified = []\n",
        "\n",
        "for prediction in tqdm(predictions):\n",
        "    classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 232.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAky42lMV102",
        "colab_type": "code",
        "outputId": "1bb37410-8a7f-4fb0-cfb2-22b51b569398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(classified):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(classified):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "correlation_matrix_df = pd.DataFrame(correlation_matrix)\n",
        "display(correlation_matrix_df)\n",
        "correlation_matrix_df.to_csv(PATH + MODEL_NAME + \"_correlation_matrix.csv\")\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.742703</td>\n",
              "      <td>0.768401</td>\n",
              "      <td>0.736869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.742703</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.753368</td>\n",
              "      <td>0.755554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.768401</td>\n",
              "      <td>0.753368</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.747011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.736869</td>\n",
              "      <td>0.755554</td>\n",
              "      <td>0.747011</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3\n",
              "0       NaN  0.742703  0.768401  0.736869\n",
              "1  0.742703       NaN  0.753368  0.755554\n",
              "2  0.768401  0.753368       NaN  0.747011\n",
              "3  0.736869  0.755554  0.747011       NaN"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.7506508849361845\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}