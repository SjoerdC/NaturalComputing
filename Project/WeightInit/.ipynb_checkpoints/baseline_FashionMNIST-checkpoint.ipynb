{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fde69AMuOpox",
    "outputId": "b9c59b4b-11cd-435f-c413-88fa8aaa7ba1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers\n",
    "from itertools import count\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, CSVLogger\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYrab7qpOppj"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 9999\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "NUM_CHANNELS = 1\n",
    "MODEL_NAME = \"FashionMNIST_basleine\"\n",
    "PATH = \"\"\n",
    "NR_OF_RUNS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8QvEt97vF52"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtJIUBsFKeRO"
   },
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    \n",
    "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "XypdmBJROpp9",
    "outputId": "1e2eaae6-9aaf-4291-f564-0c8721019b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mo8yHyg-Opqo"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_trainc = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4SYRuKZaIwb"
   },
   "outputs": [],
   "source": [
    "x_train_full = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train_full /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIBGIrlkvOt0"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLWph6_aOpr2"
   },
   "outputs": [],
   "source": [
    "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
    "    inputs = Input((imsize,imsize,num_channels))\n",
    "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
    "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVqdcrD_vQ-Q"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HjvZqLBJOpsw",
    "outputId": "1dcf98c2-b0c5-4eb9-d5f7-531da7eb0be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===== Train model: Weight init method: Zero  =====\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/9999\n",
      "48000/48000 [==============================] - 2s 47us/step - loss: 2.2436 - accuracy: 0.1964 - val_loss: 2.2212 - val_accuracy: 0.2649\n",
      "Epoch 2/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.9657 - accuracy: 0.3361 - val_loss: 1.8639 - val_accuracy: 0.4157\n",
      "Epoch 3/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.7334 - accuracy: 0.4454 - val_loss: 1.6455 - val_accuracy: 0.4727\n",
      "Epoch 4/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.5629 - accuracy: 0.5054 - val_loss: 1.4999 - val_accuracy: 0.5204\n",
      "Epoch 5/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.4399 - accuracy: 0.5437 - val_loss: 1.3977 - val_accuracy: 0.5506\n",
      "Epoch 6/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.3482 - accuracy: 0.5652 - val_loss: 1.3226 - val_accuracy: 0.5648\n",
      "Epoch 7/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.2763 - accuracy: 0.5846 - val_loss: 1.2582 - val_accuracy: 0.5907\n",
      "Epoch 8/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.2169 - accuracy: 0.6021 - val_loss: 1.2022 - val_accuracy: 0.5998\n",
      "Epoch 9/9999\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 1.1679 - accuracy: 0.6153 - val_loss: 1.1568 - val_accuracy: 0.6187\n",
      "Epoch 10/9999\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 1.1241 - accuracy: 0.6299 - val_loss: 1.1156 - val_accuracy: 0.6302\n",
      "Epoch 11/9999\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 1.0861 - accuracy: 0.6406 - val_loss: 1.0838 - val_accuracy: 0.6377\n",
      "Epoch 12/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.0544 - accuracy: 0.6516 - val_loss: 1.0531 - val_accuracy: 0.6496\n",
      "Epoch 13/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 1.0250 - accuracy: 0.6593 - val_loss: 1.0260 - val_accuracy: 0.6567\n",
      "Epoch 14/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.9990 - accuracy: 0.6684 - val_loss: 1.0041 - val_accuracy: 0.6625\n",
      "Epoch 15/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.9753 - accuracy: 0.6742 - val_loss: 0.9797 - val_accuracy: 0.6672\n",
      "Epoch 16/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.9566 - accuracy: 0.6805 - val_loss: 0.9615 - val_accuracy: 0.6734\n",
      "Epoch 17/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.9387 - accuracy: 0.6853 - val_loss: 0.9466 - val_accuracy: 0.6803\n",
      "Epoch 18/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.9219 - accuracy: 0.6901 - val_loss: 0.9288 - val_accuracy: 0.6825\n",
      "Epoch 19/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.9073 - accuracy: 0.6934 - val_loss: 0.9169 - val_accuracy: 0.6858\n",
      "Epoch 20/9999\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.8939 - accuracy: 0.6985 - val_loss: 0.9028 - val_accuracy: 0.6893\n",
      "Epoch 21/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.8818 - accuracy: 0.7012 - val_loss: 0.8907 - val_accuracy: 0.6950\n",
      "Epoch 22/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.8696 - accuracy: 0.7052 - val_loss: 0.8791 - val_accuracy: 0.6986\n",
      "Epoch 23/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.8597 - accuracy: 0.7077 - val_loss: 0.8692 - val_accuracy: 0.7046\n",
      "Epoch 24/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.8495 - accuracy: 0.7112 - val_loss: 0.8598 - val_accuracy: 0.7070\n",
      "Epoch 25/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.8390 - accuracy: 0.7150 - val_loss: 0.8494 - val_accuracy: 0.7098\n",
      "Epoch 26/9999\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.8299 - accuracy: 0.7180 - val_loss: 0.8432 - val_accuracy: 0.7118\n",
      "Epoch 27/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.8214 - accuracy: 0.7217 - val_loss: 0.8323 - val_accuracy: 0.7161\n",
      "Epoch 28/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.8137 - accuracy: 0.7240 - val_loss: 0.8248 - val_accuracy: 0.7198\n",
      "Epoch 29/9999\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.8050 - accuracy: 0.7260 - val_loss: 0.8197 - val_accuracy: 0.7249\n",
      "Epoch 30/9999\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.7960 - accuracy: 0.7290 - val_loss: 0.8142 - val_accuracy: 0.7170\n",
      "Epoch 31/9999\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.7901 - accuracy: 0.7319 - val_loss: 0.8027 - val_accuracy: 0.7254\n",
      "Epoch 32/9999\n",
      "48000/48000 [==============================] - 2s 44us/step - loss: 0.7834 - accuracy: 0.7325 - val_loss: 0.7957 - val_accuracy: 0.7301\n",
      "Epoch 33/9999\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.7763 - accuracy: 0.7358 - val_loss: 0.7888 - val_accuracy: 0.7317\n",
      "Epoch 34/9999\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.7681 - accuracy: 0.7381 - val_loss: 0.7837 - val_accuracy: 0.7312\n",
      "Epoch 35/9999\n",
      "23296/48000 [=============>................] - ETA: 0s - loss: 0.7692 - accuracy: 0.7391"
     ]
    }
   ],
   "source": [
    "for run in range(1, NR_OF_RUNS+1):\n",
    "    \n",
    "    # Split the data\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_trainc, test_size=0.20, shuffle= True)\n",
    "    \n",
    "    models = []\n",
    "    accuracies = []\n",
    "    predictions = []\n",
    "    print(f\"\\n ===== Train model: Baseline: Run: {run}  =====\")\n",
    "        \n",
    "    # Set the seeds\n",
    "    np.random.seed(run*2)\n",
    "    tf.random.set_seed(run*2)\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(PATH + MODEL_NAME + f\"/{run}/history\", exist_ok=True)\n",
    "    os.makedirs(PATH + MODEL_NAME + f\"/{run}/weights\", exist_ok=True)\n",
    "        \n",
    "    # weight init method\n",
    "    model = FashionMNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
    "            \n",
    "    #save weights \n",
    "    weights_path = PATH + MODEL_NAME + f\"/{run}/weights/weights-baseline.h5\"\n",
    "            \n",
    "    if os.path.exists(weights_path):\n",
    "        print(f\"Skipping training of model: weights exists\")\n",
    "        model.load_weights(weights_path)\n",
    "    else:\n",
    "        # initiate early stopping\n",
    "        es = EarlyStopping(min_delta=0.01, patience=3)\n",
    "        csv_logger = CSVLogger(PATH + MODEL_NAME + f\"/{run}/history/history.csv\", separator=';')\n",
    "        # train\n",
    "        model.fit(x_train,y_train,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                epochs = EPOCHS,\n",
    "                validation_data = (x_val,y_val),\n",
    "                shuffle = True,\n",
    "                callbacks=[es, csv_logger])\n",
    "        model.save_weights(weights_path)\n",
    "            \n",
    "    acc = model.evaluate(x_test,y_testc)[1]\n",
    "    print(f\"Run: {run} added. Resulting score: {acc}\")\n",
    "\n",
    "    print(\"\\n ===== Saving results =====\")  \n",
    "    # Save the results\n",
    "    file = PATH + MODEL_NAME + f\"/results_.csv\"\n",
    "    df = pd.DataFrame([[run,acc]])\n",
    "    if not os.path.isfile(file):\n",
    "        df.to_csv(file, header=[\"run\",\"accuracy\"], index=False)\n",
    "    else: # else it exists so append without writing the header\n",
    "        df.to_csv(file, mode='a', header=False, index=False)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MV--sBbgbTrz"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/FashionMNIST_basleine.zip /content/FashionMNIST_basleine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GP6kYsnHbTr0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "weight_int_FashionMNIST.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
