{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weight_int_FashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "outputId": "d122bff6-af31-4feb-c397-3cf5ce1ff9bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "NUM_CHANNELS = 1\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"FashionMNIST_weight_init\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9M4_-IaBOsn"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n9nJGd_BQ-r",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8QvEt97vF52"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JtJIUBsFKeRO",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "524eb663-f26a-4333-e88c-6afe88e722fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 8us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 4s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4SYRuKZaIwb",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBci5ba9hiaQ",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIBGIrlkvOt0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqdcrD_vQ-Q"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "0f129390-f247-4a46-902c-e4c271d5a9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = []\n",
        "predictions = []\n",
        "initializer = [\"Zero\",\"Ones\",\"Random Normal\",\"Random Uniform\",\"Identity\",\"Orthogonal\",\"Glorot Normal\",\"Glorot Uniform\"]\n",
        "for i in range(len(initializer)):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "    print(f\"Weight init method: {initializer[i]} \")\n",
        "    model = FashionMNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
        "    \n",
        "    for layer in model.layers: \n",
        "        if hasattr(layer, 'kernel_initializer'):\n",
        "            if(initializer[i] == \"Zero\"):\n",
        "                layer.kernel_initializer = initializers.Zeros()\n",
        "            elif(initializer[i] == \"Ones\"):\n",
        "                layer.kernel_initializer = initializers.Ones()\n",
        "            elif(initializer[i] == \"Random Normal\"):\n",
        "                layer.kernel_initializer = initializers.RandomNormal()\n",
        "            elif(initializer[i] == \"Random Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.RandomUniform()\n",
        "            elif(initializer[i] == \"Identity\"):\n",
        "                layer.kernel_initializer = initializers.Identity()\n",
        "            elif(initializer[i] == \"Orthogonal\"):\n",
        "                layer.kernel_initializer = initializers.Orthogonal()\n",
        "            elif(initializer[i] == \"Glorot Normal\"):\n",
        "                layer.kernel_initializer = initializers.GlorotNormal()\n",
        "            elif(initializer[i] == \"Glorot Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.GlorotUnifrom()\n",
        "          \n",
        "    es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', min_delta=0.01, patience=3)\n",
        "    model.fit(x_train,y_train,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = EPOCHS,\n",
        "              validation_data = (x_val,y_val),\n",
        "              shuffle = True,\n",
        "              callbacks=[es])\n",
        "    models.append(model)\n",
        "    y_prob = model.predict(x_test) \n",
        "    predictions.append(y_prob.argmax(axis=-1))\n",
        "    acc = model.evaluate(x_test,y_testc)[1]\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 0\n",
            "Weight init method: Zero \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 10s 200us/step - loss: 2.1487 - accuracy: 0.2455 - val_loss: 2.1678 - val_accuracy: 0.2932\n",
            "Epoch 2/10\n",
            " 2560/48000 [>.............................] - ETA: 3s - loss: 1.9955 - accuracy: 0.3562"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8997 - accuracy: 0.3767 - val_loss: 1.8018 - val_accuracy: 0.4243\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.7050 - accuracy: 0.4332 - val_loss: 1.6045 - val_accuracy: 0.4567\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.5538 - accuracy: 0.4789 - val_loss: 1.4686 - val_accuracy: 0.5033\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4304 - accuracy: 0.5273 - val_loss: 1.3604 - val_accuracy: 0.5487\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3393 - accuracy: 0.5654 - val_loss: 1.2798 - val_accuracy: 0.5813\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.2675 - accuracy: 0.5878 - val_loss: 1.2177 - val_accuracy: 0.5993\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2105 - accuracy: 0.6039 - val_loss: 1.1672 - val_accuracy: 0.6132\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.1631 - accuracy: 0.6165 - val_loss: 1.1236 - val_accuracy: 0.6208\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1241 - accuracy: 0.6253 - val_loss: 1.0853 - val_accuracy: 0.6338\n",
            "10000/10000 [==============================] - 1s 94us/step\n",
            "Model: 0 added. Resulting score: 0.6320000290870667\n",
            "Train model 1\n",
            "Weight init method: Ones \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 82us/step - loss: 2.1931 - accuracy: 0.2769 - val_loss: 2.1919 - val_accuracy: 0.2992\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.9080 - accuracy: 0.3816 - val_loss: 1.7858 - val_accuracy: 0.4139\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.6705 - accuracy: 0.4514 - val_loss: 1.5534 - val_accuracy: 0.5038\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.5054 - accuracy: 0.5193 - val_loss: 1.4212 - val_accuracy: 0.5527\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.3921 - accuracy: 0.5583 - val_loss: 1.3261 - val_accuracy: 0.5872\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.3069 - accuracy: 0.5796 - val_loss: 1.2516 - val_accuracy: 0.5951\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2409 - accuracy: 0.5958 - val_loss: 1.1933 - val_accuracy: 0.6010\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1877 - accuracy: 0.6061 - val_loss: 1.1451 - val_accuracy: 0.6220\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1426 - accuracy: 0.6175 - val_loss: 1.1040 - val_accuracy: 0.6315\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1044 - accuracy: 0.6291 - val_loss: 1.0685 - val_accuracy: 0.6367\n",
            "10000/10000 [==============================] - 1s 90us/step\n",
            "Model: 1 added. Resulting score: 0.6322000026702881\n",
            "Train model 2\n",
            "Weight init method: Random Normal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 2.2546 - accuracy: 0.2020 - val_loss: 2.2324 - val_accuracy: 0.3386\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.9716 - accuracy: 0.3613 - val_loss: 1.8445 - val_accuracy: 0.4210\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.7264 - accuracy: 0.4407 - val_loss: 1.6002 - val_accuracy: 0.4883\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.5381 - accuracy: 0.5053 - val_loss: 1.4414 - val_accuracy: 0.5471\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.4012 - accuracy: 0.5479 - val_loss: 1.3263 - val_accuracy: 0.5706\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3038 - accuracy: 0.5787 - val_loss: 1.2442 - val_accuracy: 0.5936\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2304 - accuracy: 0.6001 - val_loss: 1.1795 - val_accuracy: 0.6148\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1712 - accuracy: 0.6182 - val_loss: 1.1273 - val_accuracy: 0.6248\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1252 - accuracy: 0.6300 - val_loss: 1.0840 - val_accuracy: 0.6385\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0864 - accuracy: 0.6415 - val_loss: 1.0487 - val_accuracy: 0.6488\n",
            "10000/10000 [==============================] - 1s 93us/step\n",
            "Model: 2 added. Resulting score: 0.6434999704360962\n",
            "Train model 3\n",
            "Weight init method: Random Uniform \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 2.2184 - accuracy: 0.1978 - val_loss: 2.1861 - val_accuracy: 0.3121\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.9661 - accuracy: 0.3867 - val_loss: 1.8782 - val_accuracy: 0.3966\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.7567 - accuracy: 0.4290 - val_loss: 1.6417 - val_accuracy: 0.4612\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.5821 - accuracy: 0.4767 - val_loss: 1.4982 - val_accuracy: 0.4971\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.4553 - accuracy: 0.5176 - val_loss: 1.3901 - val_accuracy: 0.5454\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3622 - accuracy: 0.5530 - val_loss: 1.3048 - val_accuracy: 0.5759\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2901 - accuracy: 0.5758 - val_loss: 1.2445 - val_accuracy: 0.5852\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2316 - accuracy: 0.5869 - val_loss: 1.1913 - val_accuracy: 0.6037\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1842 - accuracy: 0.6020 - val_loss: 1.1437 - val_accuracy: 0.6115\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1427 - accuracy: 0.6136 - val_loss: 1.1052 - val_accuracy: 0.6182\n",
            "10000/10000 [==============================] - 1s 94us/step\n",
            "Model: 3 added. Resulting score: 0.6162999868392944\n",
            "Train model 4\n",
            "Weight init method: Identity \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 2.1713 - accuracy: 0.1981 - val_loss: 2.1876 - val_accuracy: 0.3062\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.8716 - accuracy: 0.4382 - val_loss: 1.7311 - val_accuracy: 0.4702\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.6188 - accuracy: 0.4941 - val_loss: 1.5069 - val_accuracy: 0.5230\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4609 - accuracy: 0.5376 - val_loss: 1.3834 - val_accuracy: 0.5540\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3521 - accuracy: 0.5683 - val_loss: 1.2899 - val_accuracy: 0.5849\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2706 - accuracy: 0.5914 - val_loss: 1.2165 - val_accuracy: 0.6104\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.2045 - accuracy: 0.6115 - val_loss: 1.1584 - val_accuracy: 0.6252\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1494 - accuracy: 0.6270 - val_loss: 1.1087 - val_accuracy: 0.6423\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1032 - accuracy: 0.6425 - val_loss: 1.0636 - val_accuracy: 0.6515\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.0627 - accuracy: 0.6535 - val_loss: 1.0273 - val_accuracy: 0.6603\n",
            "10000/10000 [==============================] - 1s 92us/step\n",
            "Model: 4 added. Resulting score: 0.6553000211715698\n",
            "Train model 5\n",
            "Weight init method: Orthogonal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 2.2058 - accuracy: 0.2379 - val_loss: 2.2153 - val_accuracy: 0.3117\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.9560 - accuracy: 0.3907 - val_loss: 1.8568 - val_accuracy: 0.4233\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.7219 - accuracy: 0.4534 - val_loss: 1.6050 - val_accuracy: 0.4737\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.5339 - accuracy: 0.4954 - val_loss: 1.4487 - val_accuracy: 0.5129\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4066 - accuracy: 0.5329 - val_loss: 1.3411 - val_accuracy: 0.5599\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3152 - accuracy: 0.5677 - val_loss: 1.2634 - val_accuracy: 0.5882\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.2457 - accuracy: 0.5948 - val_loss: 1.2020 - val_accuracy: 0.6079\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 3s 73us/step - loss: 1.1926 - accuracy: 0.6105 - val_loss: 1.1537 - val_accuracy: 0.6247\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.1487 - accuracy: 0.6260 - val_loss: 1.1152 - val_accuracy: 0.6366\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1128 - accuracy: 0.6360 - val_loss: 1.0821 - val_accuracy: 0.6431\n",
            "10000/10000 [==============================] - 1s 92us/step\n",
            "Model: 5 added. Resulting score: 0.6389999985694885\n",
            "Train model 6\n",
            "Weight init method: Glorot Normal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 2.1491 - accuracy: 0.2372 - val_loss: 2.1712 - val_accuracy: 0.3137\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.8905 - accuracy: 0.4096 - val_loss: 1.7796 - val_accuracy: 0.4369\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.6600 - accuracy: 0.4796 - val_loss: 1.5447 - val_accuracy: 0.4990\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.4873 - accuracy: 0.5282 - val_loss: 1.4020 - val_accuracy: 0.5571\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3679 - accuracy: 0.5661 - val_loss: 1.3041 - val_accuracy: 0.5798\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2830 - accuracy: 0.5864 - val_loss: 1.2312 - val_accuracy: 0.5973\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2182 - accuracy: 0.6027 - val_loss: 1.1742 - val_accuracy: 0.6097\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1658 - accuracy: 0.6130 - val_loss: 1.1271 - val_accuracy: 0.6228\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1263 - accuracy: 0.6214 - val_loss: 1.0928 - val_accuracy: 0.6270\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.0927 - accuracy: 0.6306 - val_loss: 1.0592 - val_accuracy: 0.6364\n",
            "10000/10000 [==============================] - 1s 95us/step\n",
            "Model: 6 added. Resulting score: 0.6305000185966492\n",
            "Train model 7\n",
            "Weight init method: Glorot Uniform \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 2.2052 - accuracy: 0.2313 - val_loss: 2.1944 - val_accuracy: 0.2509\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.9934 - accuracy: 0.4254 - val_loss: 1.8982 - val_accuracy: 0.4674\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.7892 - accuracy: 0.4717 - val_loss: 1.6711 - val_accuracy: 0.5185\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.5966 - accuracy: 0.5200 - val_loss: 1.4893 - val_accuracy: 0.5481\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.4440 - accuracy: 0.5573 - val_loss: 1.3683 - val_accuracy: 0.5728\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.3372 - accuracy: 0.5781 - val_loss: 1.2792 - val_accuracy: 0.5910\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.2581 - accuracy: 0.5937 - val_loss: 1.2063 - val_accuracy: 0.6063\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1957 - accuracy: 0.6086 - val_loss: 1.1531 - val_accuracy: 0.6163\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.1442 - accuracy: 0.6204 - val_loss: 1.1035 - val_accuracy: 0.6297\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.1027 - accuracy: 0.6304 - val_loss: 1.0669 - val_accuracy: 0.6364\n",
            "10000/10000 [==============================] - 1s 92us/step\n",
            "Model: 7 added. Resulting score: 0.631600022315979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fGT6jV-hcLbJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CurcmjMCcrJI"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yvZLQyb5cg7R",
        "outputId": "0b02924b-2835-4ac5-e8d5-1cd8ef73f9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "accuracy_df[\"weight_init_method\"] = initializer\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy.csv\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>weight_init_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6320</td>\n",
              "      <td>Zero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.6322</td>\n",
              "      <td>Ones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6435</td>\n",
              "      <td>Random Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6163</td>\n",
              "      <td>Random Uniform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6553</td>\n",
              "      <td>Identity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.6390</td>\n",
              "      <td>Orthogonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.6305</td>\n",
              "      <td>Glorot Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.6316</td>\n",
              "      <td>Glorot Uniform</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy weight_init_method\n",
              "0    0.6320               Zero\n",
              "1    0.6322               Ones\n",
              "2    0.6435      Random Normal\n",
              "3    0.6163     Random Uniform\n",
              "4    0.6553           Identity\n",
              "5    0.6390         Orthogonal\n",
              "6    0.6305      Glorot Normal\n",
              "7    0.6316     Glorot Uniform"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXq8Uj3lenzH",
        "outputId": "707e5bf9-0fe5-4933-f7be-7c594f694106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy_df.plot(x=\"weight_init_method\", y=\"Accuracy\",rot = 90)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFRCAYAAAB9pXo1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeXxU9bn48c+TjSSEsCUkQIKgrAmyCbi2LlWgva71VkWq1fpDW4ut1Vq199b22trb2lrbWtpbrXUHtLZVaq3gbutKyLAlyA5JWGNIQiCEbM/vj3MCQ0zIJExyzsw879crLzJnzpx5RifnOee7PaKqGGOMiT1xXgdgjDHGG5YAjDEmRlkCMMaYGGUJwBhjYpQlAGOMiVEJXgfQGRkZGTp8+HCvwzDGmIiyfPnyT1Q1s/X2iEoAw4cPp6CgwOswjDEmoojItra2WxOQMcbEKEsAxhgToywBGGNMjIqoPgBjTPRqaGigrKyMuro6r0OJWMnJyeTk5JCYmBjS/pYAjDG+UFZWRp8+fRg+fDgi4nU4EUdVqaiooKysjBEjRoT0GmsCMsb4Ql1dHQMHDrSTfxeJCAMHDuzUHZQlAGOMb9jJ//h09r9fSAlARGaJyDoR2Sgid7WzzxUiUiwiRSKyIGh7k4iscH8WB21/XES2BD03qVORGxPl3t34CR9urvA6DBPFOkwAIhIPzAc+D+QBs0Ukr9U+o4C7gTNVNR+4Nejpg6o6yf25uNXh7wh6bsVxfRJjosxdf13F158pZP+hRq9DiSkvvPACIsLHH3/sdSjdLpQ7gOnARlXdrKr1wCLgklb7zAXmq2olgKruCW+YxsSW8ppDlO49yN4D9fzp31u8DiemLFy4kLPOOouFCxd223s0NTV127E7I5QEMBQoDXpc5m4LNhoYLSLvisgHIjIr6LlkESlwt1/a6nX3icgqEXlQRHq19eYicqP7+oLy8vIQwjUm8gVKKgE4YWAqj7yzmcoD9R5HFBv279/Pv//9bx599FEWLVoEOCfr73znO4wfP54JEybw0EMPAbBs2TLOOOMMJk6cyPTp06mpqeHxxx9n3rx5h4934YUX8tZbbwGQlpbG7bffzsSJE3n//fe59957mTZtGuPHj+fGG2+kpTrjxo0bOf/885k4cSJTpkxh06ZNXHvttbzwwguHjztnzhxefPHF4/684RoGmgCMAs4BcoB3RORkVa0CTlDV7SJyIvCGiKxW1U04TUa7gCTgYeBO4N7WB1bVh93nmTp1qtWvNDEhUFpFQpzw29lTuHj+v/n925v43hfGeR1Wj/mfvxdRvGNfWI+ZNySdH1yUf8x9XnzxRWbNmsXo0aMZOHAgy5cv56OPPmLr1q2sWLGChIQE9u7dS319PVdeeSXPPvss06ZNY9++faSkpBzz2AcOHODUU0/lgQcecOLJy+Oee+4B4JprruGll17ioosuYs6cOdx1111cdtll1NXV0dzczA033MCDDz7IpZdeSnV1Ne+99x5PPPHEcf83CeUOYDuQG/Q4x90WrAxYrKoNqroFWI+TEFDV7e6/m4G3gMnu453qOAQ8htPUZIzBuQPIH5LOyTl9uWzyUJ54byu7qm2CVHdbuHAhV111FQBXXXUVCxcu5LXXXuOmm24iIcG5Xh4wYADr1q1j8ODBTJs2DYD09PTDz7cnPj6eyy+//PDjN998k1NPPZWTTz6ZN954g6KiImpqati+fTuXXXYZ4EzsSk1N5eyzz2bDhg2Ul5ezcOFCLr/88g7fLxShHGEZMEpERuCc+K8Crm61zwvAbOAxEcnAaRLaLCL9gVpVPeRuPxO4H0BEBqvqTnHGLV0KrDnuT2NMFGhsamZlaTVXTnOuu759/mj+vnIHv3ljAz+57GSPo+sZHV2pd4e9e/fyxhtvsHr1akSEpqYmROTwST4UCQkJNDc3H34cPCY/OTmZ+Pj4w9tvvvlmCgoKyM3N5Yc//GGH4/evvfZann76aRYtWsRjjz3WyU/Xtg7vAFS1EZgHLAHWAs+papGI3CsiLaN6lgAVIlIMvIkzuqcCGAcUiMhKd/tPVbXYfc0zIrIaWA1kAD8OyycyJsKt213DwYYmJg/rB0DugFRmTx/Gc8tK2frJAY+ji17PP/8811xzDdu2bWPr1q2UlpYyYsQIJk6cyB/+8AcaG53RWHv37mXMmDHs3LmTZcuWAVBTU0NjYyPDhw9nxYoVNDc3U1paykcffdTme7Wc7DMyMti/fz/PP/88AH369CEnJ+dwe/+hQ4eora0F4LrrruNXv/oV4DQfhUNI9xCq+jLwcqtt9wT9rsBt7k/wPu8BbV6yqOp5nQ3WmFgQKKkCYMqw/oe3zTtvJH8uKOOXr67nN7MnexVaVFu4cCF33nnnUdsuv/xy1q5dy7Bhw5gwYQKJiYnMnTuXefPm8eyzz3LLLbdw8OBBUlJSeO211zjzzDMZMWIEeXl5jBs3jilTprT5Xv369WPu3LmMHz+e7Ozso+4ynnrqKW666SbuueceEhMT+fOf/8yJJ55IVlYW48aN49JLW4+l6Tpp6XmOBFOnTlUrCGOi3e3PreTt9XtY9l/nHzWz8/5XPuZ3b23i5W9+hrwh6R5G2D3Wrl3LuHGx09HdWbW1tZx88skUFhbSt2/fdvdr67+jiCxX1amt97WlIIzxmUBJJZNy+39qWv9Nnz2J9OQEHli6zqPIjFdee+01xo0bxy233HLMk39n2WqgxvhI5YF6Nn9ygP+cmvOp5/qmJnLT2Sfx8yXrKNi6l6nDB3gQofHC+eefz7ZtbVZ1PC52B2CMj6woc9r/J+f2b/P5688cTkZaL+5fso5Iar4NVTR+pp7U2f9+lgCM8ZHAtkriBCbktH2bn5qUwDc/N5KPtuzlnQ2f9HB03Ss5OZmKigpLAl3UUg8gOTk55NdYE5AxPhIorWJsdjq9e7X/p3nVtGE8/M5mfr7kYz4zMoO4uOhYQjknJ4eysjJsyZeua6kIFipLAMb4RHOzsqKkiosnDTnmfkkJcXz7/NHc/ueV/HPNLv5jwuAeirB7JSYmhlzJyoSHNQEZ4xMby/dTc6iRycPabv8PdunkoYzOSuOBV9fR2NTc4f7GtMUSgDE+0bICaMsM4GOJjxNunzGGzeUH+Gth66W5jAmNJQBjfCJQUkXflEROzOgd0v4z8rKYmNuPX722nroGf6wvbyKLJQBjfKKwpJLJw/qFXNdVRPjuzDHsqK7jmQ9Lujk6E40sARjjA/vqGtiwZ3+74//bc+bIDM4cOZDfvbnRSkeaTrMEYIwPrCqtRhWmnNBx+39rd8wcS4WVjjRdYAnAGB8oLKlEBCbmdj4BTMrtx4y8LCsdaTrNEoAxPhAoqWRkZhrpyYldev13Zo5hf30jv397U5gjM9HMEoAxHlNVAqVVR63/31mjs/pY6UjTaSElABGZJSLrRGSjiNzVzj5XiEixiBSJyIKg7U0issL9WRy0fYSIfOge81kRSTr+j2NM5NlaUUtVbUNI4/+P5dvnj6ZZld+8sSFMkZlo12ECEJF4YD7weSAPmC0iea32GQXcDZypqvnArUFPH1TVSe7PxUHbfwY8qKojgUrghuP7KMZEpsJtLRPAun4HAFY60nReKHcA04GNqrpZVeuBRcAlrfaZC8xX1UoAVd1zrAO6heDPA553Nz2BUxjemJgTKK2kT68ERg1KO+5jzTtvJInxcfzy1fVhiMxEu1ASwFCgNOhxmbst2GhgtIi8KyIfiMisoOeSRaTA3d5ykh8IVLkF59s7JgAicqP7+gJbJdBEo0BJFRNz+4VlVc9BfZK5/szhLF65g+Id+8IQnYlm4eoETgBGAecAs4FHRKSlQfMEtxbl1cCvROSkzhxYVR9W1amqOjUzMzNM4RrjD7X1jXy8q+a42/+DWelIE6pQEsB2IDfocY67LVgZsFhVG1R1C7AeJyGgqtvdfzcDbwGTgQqgn4gkHOOYxkS9VWXVNDXrcY0Aaq2ldOTrH++hYOvesB3XRJ9QEsAyYJQ7aicJuApY3GqfF3Cu/hGRDJwmoc0i0l9EegVtPxMoVqfkz5vAf7qv/wrw4nF+FmMiTqDEKQE5qQsTwI4l2ktHmvDoMAG47fTzgCXAWuA5VS0SkXtFpGVUzxKgQkSKcU7sd6hqBTAOKBCRle72n6pqsfuaO4HbRGQjTp/Ao+H8YMZEgsKSSkZk9KZ/7/COgo7m0pEmfCSSrg6mTp2qBQUFXodhTFioKtPue53Pjsrgl1dOCvvx6xubOe+Bt+iXmsjib5wVNaUjTeeJyHK3L/YoNhPYGI+UVR7kk/2HmHxC+Nr/g7WUjlyzfR//XLOrW97DRDZLAMZ4pLClAliY2/+DXTp5KKMGWelI0zZLAMZ4JFBSRUpiPGOz+3Tbe1jpSHMslgCM8UigtIoJOX1JiO/eP8OZ+VY60rTNEoAxHqhraKJ4R/Vxr/8TCisdadpjCcAYDxTtqKahScM6A/hYrHSkaYslAGM80DIBrKcSAMB3Zoyx0pHmKJYAjPFAoKSKnP4pDOqT3GPvOXlYfysdaY5iCcAYDxSWVPZI+39rLaUj/89KRxosARjT43ZWH2RndR1TerD5p0VL6cjHrXSkwRKAMT1uxeH2/56/AwArHWmOsARgTA8rLKkkKSGOvMHpnry/lY40LSwBGNPDAiVVjB+STlKCd39+884bSUK88OBrVjoyllkCMKYH1Tc2s3p7dVgLwHSFUzpyBItX7mDtTisdGassARjTg9bu3MehxmbP2v+Dfe2zJ9GnVwK/WGKlI2OVJQBjelCgZQVQD0YAtRZcOnL5NisdGYtCSgAiMktE1onIRhG5q519rhCRYhEpEpEFrZ5LF5EyEflt0La33GOucH8GHd9HMcb/AqVVZKcnM6RfitehAEGlI1+x0pGxqMMEICLxwHzg80AeMFtE8lrtMwq4GzhTVfOBW1sd5kfAO20cfo6qTnJ/9nTlAxgTSZwJYN5f/bdITUrglvNG8qGVjoxJodwBTAc2qupmVa0HFgGXtNpnLjBfVSsBgk/mInIKkAUsDU/IxkSm8ppDlO496KsEADB7+jBy+qfw8yUf09xsdwGxJJQEMBQoDXpc5m4LNhoYLSLvisgHIjILQETigAeA77Rz7Mfc5p/vi0ibBUtF5EYRKRCRgvLy8hDCNcafVpQ6E8C8HgHUWnDpyFeKrHRkLAlXJ3ACMAo4B5gNPCIi/YCbgZdVtayN18xR1ZOBz7g/17R1YFV9WFWnqurUzMzMMIVrTM8rLKkkIU4YP7Sv16F8SkvpyF8stdKRsSSUBLAdyA16nONuC1YGLFbVBlXdAqzHSQinA/NEZCvwC+BaEfkpgKpud/+tARbgNDUZE7UCJZXkDUknOTHe61A+xUpHxqZQEsAyYJSIjBCRJOAqYHGrfV7AufpHRDJwmoQ2q+ocVR2mqsNxmoGeVNW7RCTB3Q8RSQQuBNaE4wMZ40eNTc2sKvN+AtixWOnI2NNhAlDVRmAesARYCzynqkUicq+IXOzutgSoEJFi4E3gDlWtOMZhewFLRGQVsALnjuKR4/gcxvja+t37qa1v8l0HcLDg0pELrHRkTEgIZSdVfRl4udW2e4J+V+A296e9YzwOPO7+fgA4pdPRGhOhClsmgOX69w4AnNKRZ5w0kPlvbuSKabmk9QrpFGEilM0ENqYHBEqqyEhLIneAPyaAHcsdM610ZKywBGCOy5/+vcWaC0IQKK1kUm5/2hnt7CtWOjJ2WAIwXba0aBf3vlTM/Us+tqGDx1BVW8/m8gO+bv9vzUpHxgZLAKZLSipquf3PK+mbkkhVbQMfbbXFxNoTKG2pABY5CWB0Vh8um2SlI6OdJQDTaXUNTXxjQSEAz910Or0S4lhatNvjqPwrUFJFnMDEnMhJAADfvsBKR0Y7SwCm0+77x1pWb6/mgS9NZEx2Hz47OpOlRbtsNcl2BEoqGZOdTu8IG1FjpSOjnyUA0ymLV+7gqQ+2MfczI5iRnw3AzPxsdlTXsXp7tcfR+U9zs7KipCqimn+CzTvXSkdGM0sAJmSbyvdz919WccoJ/fnurLGHt39u7CDi48SagdqwqXw/NYcafT0D+FgGpVvpyGhmCcCE5GB9Ezc/XUhSQhy/vXoyifFHvjr9eycxffgAlthKkp9S6KMKYF1lpSOjlyUAE5J7XlzD+j01/OqqyQzu++nJTDPzs9iwZz+by/d7EJ1/BUqq6JuSyIiBvb0OpcusdGT0sgRgOvRcQSl/Xl7GLeeO5OzRbS/J3dIfsMSagY4ScNv/4+L8PwHsWKx0ZHSyBGCOae3OfXz/hTWcfuJAvnX+6Hb3G9IvhQk5fVlabM1ALfbVNbB+T43v1/8JhZWOjE6WAEy79h9q5BvPFJKeksivZ08ivoOr2Bl5WQRKqti9zyYOAawqrUY1stv/gwWXjrS7gOhgCcC0SVW56y+r2FpxgIdmT2ZQn+QOXzPTbQZaWmzNQOCM/xeBSVGSAIJLR/5zjd3pRQNLAKZNT3+wjZdW7eT2GWM47cSBIb1m5KA0TszozVIbDQQ4S0CMzEwjPTnR61DCxkpHRhdLAOZTVpVV8aOX1nLumEy+fvZJIb9ORJiRn837myqoPtjQjRH6n6oSKKmMmuafFlY6MrpYAjBHqa5t4OZnCslIS+KXV0zq9OiVGflZNDYrb368p5sijAxbK2qprG1gcoROADuWmflZTMzpy69eW8+hRisdGclCSgAiMktE1onIRhG5q519rhCRYhEpEpEFrZ5LF5EyEflt0LZTRGS1e8zfSCQslB7lVJXb/7ySXdV1/HbOFPr3Tur0MSbl9GNQn14xPyks4E4Ai9QZwMciItwxcyw7qut45gOrBRHJOkwAIhIPzAc+D+QBs0Ukr9U+o4C7gTNVNR+4tdVhfgS802rb74G5wCj3Z1ZXPoAJn0f+tZnX1u7m7i+M6/KJKy5OmJGfxVvrymO6sHhhSSVpvRIYOSjN61C6xVmjjpSO3H+o0etwTBeFcgcwHdioqptVtR5YBFzSap+5wHxVrQRQ1cP3/yJyCpAFLA3aNhhIV9UP3HrCTwKXHtcnMcelYOtefvbKOmblZ/PVM4cf17Fm5mdzsKGJf8fwePFASRUTc/t2OHQ2klnpyMgXSgIYCpQGPS5ztwUbDYwWkXdF5AMRmQUgInHAA8B32jhmWQfHxD3GjSJSICIF5eXlIYRrOqti/yHmLQiQ0z+F+7804bjLFp46YiB9khNithmotr6Rj3fVRGXzTzArHRn5wtUJnIDTjHMOMBt4RET6ATcDL6tq2TFee0yq+rCqTlXVqZmZbS9DYLquqVm59dkV7K2tZ/7VU8IyZDEpIY7PjR3Ea2t3x+RQwVVl1TQ1a9SNAGrL7TOsdGQkCyUBbAdygx7nuNuClQGLVbVBVbcA63ESwunAPBHZCvwCuFZEfuq+PqeDY5oeMP/Njfxrwyf88KJ8xg/tG7bjzszPprK2gYJtlWE7ZqQIlDglICdFwRIQHRmTbaUjI1koCWAZMEpERohIEnAVsLjVPi/gXP0jIhk4TUKbVXWOqg5T1eE4zUBPqupdqroT2Ccip7mjf64FXgzLJzIhe3fjJzz42nounTSE2dNzO35BJ3x2dCZJCXEx2QwUKKlkREZvBnRhFFUkaikd+ZCVjow4HSYAVW0E5gFLgLXAc6paJCL3isjF7m5LgAoRKQbeBO5Q1YoODn0z8EdgI7AJ+GcXP4Ppgt376vjWogAnZaZx32UnH3e7f2u9eyXw2VEZLC3aHVPrxqgqhSVVTM6N/uafFi2lI59dVsqyrbZcdCQJqQ9AVV9W1dGqepKq3uduu0dVF7u/q6repqp5qnqyqi5q4xiPq+q8oMcFqjrePeY8jaWzhMcam5q5ZWGAA4ea+P2cKd1Wq3ZGfjbbqw5StCN2KkmVVR7kk/2HYqL9P9i3PjeKYQNS+cqfPuKjLZYEIoXNBI5Bv3x1PR9t2ct9l41nVFafbnuf88dlESfE1NpAgVKn/T8aZwAfy8C0Xiy68TSy+yZz3WMf8eHmjhoAjB9YAogxb3y8m9+9tYnZ03P54pScjl9wHAb0TmLa8AExVSSmcFslyYlxjM3uvsTqV4PSk1l042kM6ZfCdY8t4/1NlgT8zhJADCmrrOXbz65k3OB0fnBRfo+858z8bNbtrmHrJwd65P28FiitYkJOPxLiY/NPa1CfZBbOPY2c/ilc//hHvLcxdicDRoLY/JbGoPrGZuYtCNDUrPxuzhSSE+N75H1n5GcBxMRooLqGJop3VMdc+39rmX16sfDG0xg2IJXrH18W0zPC/c4SQIz433+uZUVpFff/5wRGZPRcgfKc/qmMH5oeE0Viinbso6FJo34GcCgy0nqxcO5pjMjozQ1PLONfG2wWvx9ZAogB/1y9k8fe3cp1ZwznCycP7vH3n5GXTWFJJXtqonuiUMsKoLE0BPRYBqb1YsHhJFDA2+stCfiNJYAot/WTA3z3+VVMzO3H974wzpMYZuZnowqvRvldQKCkiqH9UhiU3nH5zFgxoHcSC+eexsjMNOY+WcCb62K7ToTfWAKIYnUNTdz8TCFxccL8qyeTlODN/+7RWWkMH5ga9aOBAiWVTDnBmn9a6987iQVzT2XUoDRuenJ5zBcL8hNLAFHsf/5eTPHOffzyionk9E/1LA4RYWZ+Nu9v+oR9ddFZKnJXdR07quus+acd/VKTeOb/ncqY7D7c9NRyXl8b3RcDkcISQJT6W6CMhR+V8LWzT+Jz47K8DocZ+Vk0NEVvqcjD7f8xPgLoWPqlJvH0DacybnAfvvb08qhvEowElgCi0IbdNXzvr2uYPnwA35kx2utwAJic25/MPr1YGqXNQIHSKpIS4sgfEr4VVaNR39REnrzhVPKG9OXmZ5bHxPBgP7MEEGVq6xv5+jOFpCbF89DVk30zISkuTrggL4u31u2JylKRhdsqGT8k3bN+lkjSNyWRp26YTv6QvnzjmUJeWbPT65Biln1bo4iq8t9/W8Om8v38+qrJZPlsNMrM/GwO1Dfx3qbomhhU39jM6u3VMbf+z/FIT3aSwIScvnxjQYCXV1sS8IIlgCiyaFkpfw1s59bPjeasURleh/Mpp584kD69EliyJrqagT7etY9Djc02AayT+iQ7zUGTc/txy8IAL63a4XVIMccSQJQo2lHNDxYX8ZlRGcw7b6TX4bQpKSGOc91SkU3N0bP6d+E26wDuqrReCTz+1elMGdaPby1aweKVlgR6kiWAKLCvroFvPFNI/9REHrxyEvFx4S3uEk4z87OpOFBPQRQVDgmUVpGV3ovBff3V5BYp0nol8Pj10znlhP7cuijAiyusOmxPCSkBiMgsEVknIhtF5K529rlCRIpFpEhEFrjbThCRQhFZ4W7/WtD+b7nHXOH+DArPR4otqsqdz6+itPIgv716ChlpvbwO6ZjOHuOUioymtYECJVVMGdY/7FXVYknvXgk8fv00po8YwLefXcHfAmVehxQTOkwAIhIPzAc+D+QBs0Ukr9U+o4C7gTNVNR+41X1qJ3C6qk4CTgXuEpEhQS+do6qT3J/oHCDezR5/byv/XLOL784cw7ThA7wOp0NpvRI4a2QGS4p2RUWpyE/2H6Jkb601/4RBalICf7puGqeOGMhtz63kL8stCXS3UO4ApgMbVXWzqtYDi4BLWu0zF5ivqpUALSdzVa1X1UPuPr1CfD8TokBJJT95eS3njxvEjZ890etwQjYzP4uyyoMU74z8UpGBktisANZdWpLAGScN5DvPr+TPBaVehxTVQjkhDwWC/y+UuduCjQZGi8i7IvKBiMxqeUJEckVklXuMn6lqcC/PY27zz/elnftnEblRRApEpKC83FYTbFF5oJ55CwJkpSfzwJcmRVTzQ0upyGhYGyhQUklCnHDyUJsAFi4pSfE8+pVpnDUyg+/+ZRXPLbMk0F3CdUWeAIwCzgFmA4+ISD8AVS1V1QnASOArItKyLsEcVT0Z+Iz7c01bB1bVh1V1qqpOzczMDFO4ka25WbntuRWU1xxi/tVT6Jua6HVInTIwrRdTTxgQFbWCAyVV5A1J77ECO7EiOTGeR66dejgJLPqoxOuQolIoCWA7kBv0OMfdFqwMWKyqDaq6BViPkxAOc6/81+Cc7FHV7e6/NcACnKYmE4I/vLOZN9eV898XjmNihC4+NiM/i4931VBSUet1KF3W2NTMyrIqWwCum7QkgbNHZ3LXX1ez4ENLAuEWSgJYBowSkREikgRcBSxutc8LOFf/iEgGTpPQZhHJEZEUd3t/4CxgnYgkuPshIonAhTjJwXTgw80V/GLpOv5jwmCuOe0Er8Ppspn52UBkl4pcv3s/tfVN1v7fjZIT4/nDNadw7phMvve31Tz9wTavQ4oqHSYAVW0E5gFLgLXAc6paJCL3isjF7m5LgAoRKQbeBO5Q1QpgHPChiKwE3gZ+oaqrcTqEl7h9Aytw7igeCfNnizrlNYe4ZWGAYQNS+ekXT46odv/Wcgekkjc4PaITQKDUmQBmM4C7V3JiPP93zSl8buwg/vuFNTz5/lavQ4oaCaHspKovAy+32nZP0O8K3Ob+BO/zKjChjeMdAE7pQrwxq6lZufXZANUHG3jiq9PpkxxZ7f5tmZGfxa9f30B5zSEy+/h7/kJbCrdVMbB3ErkDUrwOJer1Sojnd1+ewjeeCXDPi0U0NyvXnTnC67Aing3LjBC/fn0D726s4EeXjGfc4HSvwwmLllKRr0VocZBAaSWTh/WL6DuxSNIrIZ7fzZnCjLwsfvj3Yv707y1ehxTxLAFEgHfWl/PQGxu4fEoOX5qa43U4YTM2uw/DBqRGZDNQVW09m8sPWPt/D0tKiGP+nCnMys/m3peK+eO/NnsdUkSzBOBzu6rruPXZFYwe1IcfXzo+qq42nVKRWby3sYKaCCsVGShtmQBmI4B6WmJ8HA9dPZnPj8/mx/9YyyPvWBLoKksAPtbQ1My8BYXUNTQxf84UUpKib6z5jPxs6puaeWtdZE3yC5RUEScwMccSgBcS4+P4zezJ/MfJg7nv5bX839ubvA4pIlkC8LFfLFlHwbZK/veLJzNyUJrX4XSLKcP6k5GWFMLxcNsAACAASURBVHHNQIGSSsZkp9O7V0jjKEw3SIyP49dXTeKiiUP46T8/5ndvbfQ6pIhj316ferV4N394ZzNfPm0Yl0xqvfJG9Ih3S0X+feVODjU20SvB/3c5zc3KitIqLpo4pOOdTbdKiI/jwSsmIsD9r6xDFb5xrj/rYfiR3QH4UOneWm5/bgXjh6bz3/+R1/ELItyM/Gz2H2rkvU0VXocSkk3l+6mpa7QZwD6REB/HL6+YyKWThvDzJev4zesbvA4pYtgdQJg0NSsNTc3UNzXT0NhMQ1PQ46ZmGhr1yO/uT32jHv24SWlobOYvhWUo8LurT4mJNWbOOGkgab0SWFq0i3PH+L8shK0A6j8J8XE8cMUk4kT45avraVbl1vNHex2W78VEAlhStIttFQdoaFLqG4NPwhp0wg563NRMY1OrE3ZjqxO6e7JueRzOCodJCXH8dvZkhg1MDd9BfaxXQjznjMnk1eLd/PhS9XVFM4DCkkr6piRyYkZvr0MxQeLjhJ9/aSJxccKvXttAs8K3zx8VVSPnwi0mEsCzy0p54+Mj9WYS4oTE+DgS44WkhDj3d+dxYnxc0DYhrVcCSS3PJ7iviQ96TUKrx20cs/Xrj/VcUnwcyYnxMXHlH2xmfjYvrdpJYUml7wvbBEqqmJTbjzifJ6pYFB8n3H/5BOIEfvP6BlSV2y4YbUmgHTGRAH4zezICh0+69mXwn3PGZJIUH8fSol2+TgA1dQ2s31PD50/O9joU0464OOGnX5xAnAgPvbGRZlW+M2NMxP3d7z/USOneWuen8iBXTcsN+6izmEgAaTZUz/f6JCdyxsiBLCnazfe+MM63f6yryqpRtQXg/C4uTvjJZc6CifPf3ERTM9w5y19JoK6hie1VBw+f4Mv21lJaWUvp3oOUVdZSWXv05MjTTxxI3pDwLgNjZ0bjGzPzs7n7r6v5eFeNb9c7KtzmrAAaqXUYYklcnHDfpeOJE/i/tzehqtz1+bE9lgQam5rZWV1H6d5ayioPuid352RfureWPTWHjto/KT6OnP4p5AxI5eScvuT2TyV3QIr7byr9u6HwkyUA4xvnj8vie7KaJUW7fJsAAqVVjByURt+UyF+NNRbExQk/vnQ8cSL84Z3NNKuG7Q6zuVkp33/IPak7V+7BJ/ud1XU0BY0OiRMY3DeF3AEpnD06k9wBqeT0TyF3QCq5/VMZ1KdXj/crWQIwvpHZpxenDOvP0qLdvhzCp6oESiq5IC+r452Nb4gI916ST5zAI//aQlMzfP/CjpOAqlJZ20BZy8k96Aq+bG8tZVUHqW9sPuo1mX16kds/hVNO6H/UFXxO/1QG90smMd5fU68sARhfmZmfzX0vr6V0by25A/w1DHZrhdMua+P/I4+I8MOL84mLE/707haaVfnBRXkcqG863NF6pJnGaYMvqzzI/kONRx2nX2oiuf1TGZPdh/Pzssh1m2yck3xKxI3eCykBiMgs4NdAPPBHVf1pG/tcAfwQUGClql4tIicAf8OZcZwIPKSq/+fufwrwOJCCU2zmW25hGRPDWhLAkqJd/L/PnOh1OEcJlDjt/7YCaGQSEe65MA/BSQJ/KSyjpu7oE3xqUvzhK/fTThx4VBNNzoAU0qOgEFOwDhOAiMQD84ELcIq/LxORxapaHLTPKOBu4ExVrRSRlumcO4HTVfWQiKQBa9zX7gB+D8wFPsRJALOAf4bxs5kINGxgKmOz+7C0aLcPE0AVab0SGDWoj9ehmC4SEb5/4ThyB6SwYc/+w1fuzkk+hQG9k3w1Uqi7hXIHMB3YqKqbAURkEXAJUBy0z1xgvqpWAqjqHvff+qB9euGuPSQig4F0Vf3AffwkcCmWAAzO2kC/fWMDn+w/REaaf0pFFpZUMjG3r+9nKptjExGut3KSQGiLwQ0FSoMel7nbgo0GRovIuyLygdtkBICI5LrF30uBn7lX/0Pd4xzrmC2vv1FECkSkoLw8staMN10zMz+LZoXXfVQqsra+kY931TA519r/TfQIV5d0AjAKOAeYDTwiIv0AVLVUVScAI4GviEinhlCo6sOqOlVVp2ZmZoYpXONneYPTyemfwpIi/ySA1WXVNDWrtf+bqBJKAtgO5AY9znG3BSsDFqtqg6puAdbjJITD3Cv/NcBn3NcHF7dt65gmRjmlIrP594ZPPjUKwyuFtgKoiUKhJIBlwCgRGSEiScBVwOJW+7yAc/WPiGTgNAltFpEcEUlxt/cHzgLWqepOYJ+InCZOj8u1wIvh+EAmOszIy6K+qZm3fVIqMlBSyfCBqQzoneR1KMaETYcJQFUbgXnAEmAt8JyqFonIvSJysbvbEqBCRIqBN4E7VLUCGAd8KCIrgbeBX6jqavc1NwN/BDYCm7AOYBNk6vABDOztj1KRqkqgtMqu/k3UCWkegKq+jDNUM3jbPUG/K3Cb+xO8z6vAhHaOWQCM72S8JkbExwnnj8vi5dU7qW9sJinBuxmUZZUHKa85xBRr/zdRxl/zko0JMnN8FjWHGnlv0yeexhEotfZ/E50sARjfOuOkDHonxbO02NvRQIGSSpIT4xiTbRPATHSxBGB8KzkxnnPGDOLV4t00h7PmZicFSqqYkNPPdwt5GXO87BttfG1GfhblNYcIlFZ68v51DU0U7ai28f8mKlkCML527thBJMaLZ5PCinbso6FJbQawiUqWAIyvpScncvpJGSwp2oUXi8W2rABqI4BMNLIEYHxvZn4W2ypqWb97f4+/d6CkiqH9UhiUntzj721Md7MEYHzvgrwsRPBkUligpNLa/03UsgRgfG9Qn2Qm5/ZjaXHPJoBd1XXsqK5jio3/N1HKEoCJCDPzs1mzfR9llbU99p5WAcxEO0sAJiLMzM8GYGkPjgYKlFaRFB9H3pD0HntPY3qSJQATEYZn9GZMVp8e7QcIlFSSPzSdXgmRVejbmFBZAjARY0Z+Fsu27mXvgfqOdz5O9Y3NrCqrtvZ/E9UsAZiIMTM/m2aF13qgVOTHu/ZxqLHZ2v9NVLMEYCJG/pB0hvZLYWkPNAMFrAKYiQGWAEzEEBFm5GfxzoZPONDNpSILSyrJSu/FkL42AcxEL0sAJqLMyMumvrGZd9Z3b6nIQEkVk3P741QsNSY6hZQARGSWiKwTkY0iclc7+1whIsUiUiQiC9xtk0TkfXfbKhG5Mmj/x0Vki4iscH8mhecjmWg2bXh/+qcmdutooE/2H6Jkb621/5uo12FJSBGJB+YDFwBlwDIRWayqxUH7jALuBs5U1UoRGeQ+VQtcq6obRGQIsFxElqhqlfv8Har6fDg/kIluCfFxnD8ui1eKdnVbqcgVbvv/lBOs/d9Et1D+eqYDG1V1s6rWA4uAS1rtMxeYr6qVAKq6x/13vapucH/fAewBMsMVvIlNM/Ozqalr5IPNFd1y/MKSShLihPFD+nbL8Y3xi1ASwFCgNOhxmbst2GhgtIi8KyIfiMis1gcRkelAErApaPN9btPQgyLSq603F5EbRaRARArKy7u33ddEhrNGZZCaFN9tawMFSqoYNzidlCSbAGaiW7junxOAUcA5wGzgERE53IAqIoOBp4DrVbXZ3Xw3MBaYBgwA7mzrwKr6sKpOVdWpmZl282CcUpFnj85kaVH4S0U2NSsry6ps/X8TE0JJANuB3KDHOe62YGXAYlVtUNUtwHqchICIpAP/AP5LVT9oeYGq7lTHIeAxnKYmY0IyMz+bPTWHWFFW1fHOnbBuVw219U02/t/EhFASwDJglIiMEJEk4Cpgcat9XsC5+kdEMnCahDa7+/8NeLJ1Z697V4A44+wuBdYcx+cwMebcMYNIiJOwjwZqqT1sI4BMLOgwAahqIzAPWAKsBZ5T1SIRuVdELnZ3WwJUiEgx8CbO6J4K4Args8B1bQz3fEZEVgOrgQzgx2H9ZCaq9U1N5PSTBrK0aHdYS0UGSqoY0DuJYQNSw3ZMY/yqw2GgAKr6MvByq233BP2uwG3uT/A+TwNPt3PM8zobrDHBZuRn8/0X1rBxz35GZfUJyzELSyqZMqyfTQAzMcFmApuINSMvCwhfqciq2no2lx+w9n8TMywBmIiVlZ7MpNx+LAlTkZgVpe4CcLnW/m9igyUAE9Fm5mezens1O6oOHvexCkuqiBOYYAnAxAhLACaizcx3moHCsUR0oKSS0Vl9SOsVUteYMRHPEoCJaCdmpjFqUNpxNwM1NysrSqus/d/EFEsAJuLNyM/io617qTyOUpGbyvdTU9doM4BNTLEEYCLezPxsmpqV1z/e0+VjWAUwE4ssAZiId/LQvgzpm3xcw0EDpZWkJydwYkbvMEZmjL9ZAjARzykVmc0768upre9aqchAidP+HxdnE8BM7LAEYKLCjLwsDnWxVGRNXQPrdtfY+j8m5lgCMFFh+ogB9EtNZGkXRgOtKqtG1dr/TeyxBGCiQkJ8HJ8bm8Vra3fT0NTc8QuCBEqcFUAn5dgdgIktlgBM1JiZn8W+ukY+3Ly3U68rLKli5KA0+qYmdlNkxviTJQATNT4zKpPkxLhOlYpUVQIllbb+j4lJlgBM1EhJ6nypyG0VtVTWNlj7v4lJlgBMVJmZn82ufXWs2l4d0v6Fbvv/lBPsDsDEnpASgIjMEpF1IrJRRO5qZ58rRKRYRIpEZIG7bZKIvO9uWyUiVwbtP0JEPnSP+axbPtKY43Le2EHEd6JUZKCkit5J8YwaFJ6CMsZEkg4TgIjEA/OBzwN5wGwRyWu1zyjgbuBMVc0HbnWfqgWudbfNAn4lIi2XWj8DHlTVkUAlcEMYPo+Jcf1SkzjtxAEhrw4aKK1kYm4/4m0CmIlBodwBTAc2qupmVa0HFgGXtNpnLjBfVSsBVHWP++96Vd3g/r4D2ANkuoXgzwNaCsU/gVMY3pjjNjM/m03lB9i4Z/8x96utb2TtzhqmWPu/iVGhJIChQGnQ4zJ3W7DRwGgReVdEPhCRWa0PIiLTgSRgEzAQqHILzrd3zJbX3SgiBSJSUF7e+VmeJvZcEGKpyNVl1TQ1q80ANjErXJ3ACcAo4BxgNvBIUFMPIjIYeAq4XlU7NUtHVR9W1amqOjUzMzNM4ZpoNrhvChNz+nbYDBRwS0BOsiGgJkaFkgC2A7lBj3PcbcHKgMWq2qCqW4D1OAkBEUkH/gH8l6p+4O5fAfQTkYRjHNOYLpuRn83Ksmp2VrdfKrJwWyXDB6YyMK1XD0ZmjH+EkgCWAaPcUTtJwFXA4lb7vIBz9Y+IZOA0CW129/8b8KSqtrT3o6oKvAn8p7vpK8CLx/E5jDnKzPxsAF4tbnttIFUlYBXATIzrMAG47fTzgCXAWuA5VS0SkXtF5GJ3tyVAhYgU45zY71DVCuAK4LPAdSKywv2Z5L7mTuA2EdmI0yfwaFg/mYlpIwelcVJm73b7AbZXHaS85pC1/5uYFlL1a1V9GXi51bZ7gn5X4Db3J3ifp4Gn2znmZpwRRsZ0ixn52Tz8zmaqauvpl3r0NJOWCmA2AsjEMpsJbKJWS6nIN9ooFVlYUklyYhxjsm0CmIldlgBM1JowtC/Z6W2XigyUVDFhaD8S4+1PwMQu+/abqBUXJ8zIz+Lt9eUcrG86vP1QYxPFO/ZZ+7+JeZYATFSbkZdNXUMz72w4MolwzfZ91Dc12wggE/MsAZioduqJA+ibcnSpyJYKYHYHYGKdJQAT1RLj4/jc2EG8/vFuGt1SkYHSKob2SyErPdnj6IzxliUAE/Vm5GdTVdvAR1ucUpGBbZV29W8MlgBMDPjs6Ax6JcSxpGgXu6rr2FFdZ+3/xmAJwMSA1KQEPjs6k6XFu63935gglgBMTJiZn83O6jqefH8bSfFx5A9J9zokYzxnCcDEhM+5pSLf31xB/tB0eiXEex2SMZ6zBGBiQv/eSUwfPgCAybnW/m8MWAIwMWRmvlMpbMoJ1v5vDIS4Gqgx0eCLp+Swu+YQ540d5HUoxviCJQATM9KTE7lz1livwzDGN6wJyBhjYlRICUBEZonIOhHZKCJ3tbPPFSJSLCJFIrIgaPsrIlIlIi+12v9xEdnSRqUwY4wxPaDDJiARiQfmAxfgFH9fJiKLVbU4aJ9RwN3AmapaKSLBjaw/B1KBm9o4/B3BtYKNMcb0nFDuAKYDG1V1s6rWA4uAS1rtMxeYr6qVAKp6uASTqr4O1IQpXmOMMWESSgIYCpQGPS5ztwUbDYwWkXdF5AMRmRXi+98nIqtE5EER6dXWDiJyo4gUiEhBeXl5W7sYY4zpgnB1AicAo4BzgNnAIyLS0WDru4GxwDRgAHBnWzup6sOqOlVVp2ZmZoYpXGOMMaEkgO1AbtDjHHdbsDJgsao2qOoWYD1OQmiXqu5UxyHgMZymJmOMMT0klASwDBglIiNEJAm4Cljcap8XcK7+EZEMnCahzcc6qIgMdv8V4FJgTaciN8YYc1w6HAWkqo0iMg9YAsQDf1LVIhG5FyhQ1cXuczNEpBhowhndUwEgIv/CaepJE5Ey4AZVXQI8IyKZgAArgK91FMvy5cs/EZFtXfqkkAF80sXXeiGS4rVYu08kxRtJsUJkxXu8sZ7Q1kZR1eM4ZuQQkQJVnep1HKGKpHgt1u4TSfFGUqwQWfF2V6w2E9gYY2KUJQBjjIlRsZQAHvY6gE6KpHgt1u4TSfFGUqwQWfF2S6wx0wdgjDHmaLF0B2CMMSaIJQBjjIlRlgCMMSZGWUUwEzIRue1Yz6vqL3sqls4QkQnAcIK+76r6V88CMj1KRP4OtNvZqaoX92A4IXHXUruWT39vvxnO94n6BCAiWTgLzgF8FLxUtZ+IyP3Aj4GDwCvABODbqvq0p4EdrY/XAXSWiPwJ579lEdDsblbAtwlARJYDfwIWtCyxbo7LL7wOoAteBj4AVnPkext2UT0KSESuwClI8xbOkhOfwadFaERkhapOEpHLgAuB24B3VHWix6FFNBEpVtU8r+PoDBEZCVwPXAkU4CyWuFR99McqIjW0fVUtgKpqeg+HFFVEpFBVp3T7+/joOxV2IrISuKDlqt9de+g1P55URWSNqo4XkT8Cz6vqKyKy0qexJgM3APlAcst2Vf2qZ0G1Q0QeBR4IrmAXKUQkDudi4Pc4a2w9BvxaVfd6GliEcisX/i+Qx9Hf2xM9C6odIvJtYD/wEnCoZXu4/99HeydwXKsmnwr8+5lfEpGPgVOA191kVedxTO15CsgGZgJv4ywR7teqb08C77s1rVeJyGoRWeV1UB1x+y0ewLmD/QvwJWAf8IaXcbVHRAaJyLCWH6/jacdjOMm0ETgX57vhpybWYPU4/+/fB5a7PwXhfpNovwP4OU7770J305XAKlVts/iM10RkAFCtqk0i0hvoo6q7vI6rNREJqOpkEVmlqhNEJBH4l6qe5nVsrYnIRpzmtKPaUlW1q6vKdju3D6AKeBT4i1szo+W5v6rqFz0LrhURuRgnUQ0B9uCsOrlWVfM9DawNIrJcVU8RkdWqenLwNq9ja01ENgPTVbVbVyuN2k5gt87Ab3A6gM9yNz+sqn/zLqr2iUgqcDMwDLgR5w9qDM4toN80uP9Wich4YBcwyMN4jqXcXbI8knxJVY+qpyEiI1R1i59O/q4fAafhNK1OFpFzgS97HFN7DrnNahvcJe63A2kex9SejUBtd79J1CYAVVURednN9L4d8RHkMZzbvDPcx9uBP+PPBPCwiPQHvo9THCgNuMfbkNoVEJEFwN85ui3Vz9+J54HWHYDP4zQP+k2DqlaISJyIxKnqmyLyK6+Dase3gFTgmziJ6zzgK55G1L4DwAoReZOjv7c2DLQTCkVkmqou8zqQEJykqleKyGwAVa1172J8R1X/6P76NuC7DrRWUnD+gGYEbfPlMFARGYvTsd5XRIKv9NMJ6rT0mSoRSQPewSnytAfn5OU7QeeB/TijrPzsBfenW0V7AjgV+LKIbMX5UrYMUZvgaVRtqxeRFNyhdSJyEkGZ3096apLK8RKReKBCVb/jdSwhGoMz6qcfcFHQ9hpgricRdewSnMEK3wbmAH2Bez2NqB0iMhX4L5x+iuDvra/OB+739jpVPbe73yvaE8BMrwPohB/gTADLFZFngDOB6zyNqH09MknleLmd6Wd6HUeoVPVF4EUROV1V3/c6nlCoavDV/hOeBRKaZ4A7iIzvbbOI9FXV6u58r6geBQQgImcBo1T1MXdoZZqqbvE6rraIyECcDjUBPujuEQBd1VOTVMJBRH4PDMXpTzl8svJjH4CIfFdV7xeRh2hjkpXf7rAA3Kaqn+EMAhB8PBFMRP6tqmd1vKf3RORFYDLwKkd/b60PIFQi8gNgKs6t9WNAIs64X79eFSYDlTj/X/JEBFV9x+OY2vKUiMylmyephEkyzvyP84K2+bIPAFjr/hv28d7d6H7gIlVd2+Ge3vuBO9Hydfw/IOCv9MB3NKoTAHAZThYtBFDVHSLiy/VsRORnOPMUWq9Z48cE0DJJ5b84cqWq+LBDWFX93tl3mKr+3f21VlX/HPyciHzJg5BCsTtCTv7gdPyOxbkQ9PW6UKr6hIgkAaPdTetUteFYr+mKaE8A9e5w0JaO1d5eB3QMlwJjgif9+NjtwEi/NlEFE5Ec4CGO3PX9C/iWqpZ5F1WH7sZpsupomx8UiMizOCNW/H5VPU1Vx3gdRChE5BycPpWtOM1quSLylXC3CER7AnhORP4A9HObLL4KPOJxTO3ZjHNlEgkJoEcmqYTJY8ACnKUUwJmk9BhwgWcRtUNEPg98ARgqIr8JeiodZ/kCP0rH+S74fpgt8J6I5EXIulAPADNUdR2AiIzGWdEgrHNBojIBiMhMVV2iqr8QkQtw1lAZgzNZqZ+30bWrFmfiR+v2Sd91/NFDk1TCJFNVHwt6/LiI3OpZNMe2A6f9/2KcSYEtanCGWfpOJDWx4QywWCEiW3C+t34eFp7YcvIHUNX17pIrYRWVo4BEpAmn7fzLqrq91XO+HMEiIl/HSciKc7V3EJy2QC/jaouItDl70qexvo5zxd+yHtRs4HpV/Zx3UR2biCR2R3tvd4iUJjZ3UuVngE+tAeXHdaHcOhbNHFmsbg4QH+4Vd6M1AQSA3+Fc8X87eP3/loXMPAuuFRFJAH6C0zy1DeeqZBjOSet7fjsRuJNUXuuJSSrhICIn4JygTsdJru8B31TVEk8DOwZ37sIPOTJhqeVK1Xed7CLyKk4T21Pupi8Dc1TVj01shxeB8zsR6QV8gyPrmP0L+F24+wijsgkI54/lERF5G2d6+n8A31DVWo5RGs4jP8eptDVCVWsARCQdp4rRzwFfNVf05CSV4yEiP3NXfZ2uPiz514FHcZp8luPUAfCzSGpi8/3SMCLyunt3eq/7/e3WMqvRmgCAw+1mp+OUWgyIyLVex9SGC4HRGnQrpqr73Cahj/FZAnDtB1a7V3/dNknlOH1BRO7Cv6NnjqVaVf/pdRAhqhCRL3N0E1uFh/Ecy6nAHBHZhn+XhhksImcAF4vIIpwYD1PVwnC+WbQmgMP/0VS1EbhLRF7B+ZJmehZV2zT45B+0sall+KoP9cgkleP0Cs6kujQR2Yf7xw7+naka5E23lsVfObqTPax//GHyVZwmtgc50sTm147hSFga5h6cVXZz+PTVv3L0hMbjFq19AJeq6qdW0nOXML5JVX/qQVhtEpEXgL+q6pOttn8ZuMKvzRc9MUklHETkRVW9xOs4OsMdXdWaqmpY//hjkYhMxOkMBqeI0Uov42mPiHxfVX/U7e8TjQkgkojIUJwrvYMcGfo3FWcZ48taj2Lyg7YmqQBhn6Ri/K/VfIUW1UCBu7idb4jIt3BWVW25e70Mp0jUQ95FdTQRGauqH4tImyMVw30XaAnAJ0TkPJy14AGKVfV1L+M5FnFKFl7depKK+qi0XsvCXyJSQ1DTDxHQBCQiWTgjw4ao6udFJA84XVUf9Ti0TxGRh3GWV2jpZ7kc2AIMBDarqm/6sMSpBX16ywqm7soA7/upD0BEHlbVG3vqLtASgOk0cWsBd7TNdI2I/BNnGPB/qepEd6hwwI9DGEXkA+BMVW1yHyfgDFk8C1itqnlexhdMRFbjLAdR5z5OBpb58b9rT4nWTmDTvQrcVRWDJ6n4dgVLd+5CFkcXAfHtPAAgQ1WfE5G7wRnI4E5u9KP+OCVBW4YE9wYGuIMY/LasyWPAhyLSUhf8Upwht77kjgYaztHf2yfbfUEXWAIwXfF1nEkqLcM+/4Uz8c53ROQWnGI7uzl6BUg/360ccGtDtCxieBpHTrB+cz/O8gpv4TSvfRb4idu88pqXgbWmqr905wa1zFq+XlUDXsbUHhF5CjgJWMGRuSAKhDUBWBOQiWoishE4VVX9Ojb9U9wOwIeA8cAanKHL/6mqqzwNrB0iMhiY7j5cpqo7vIwnGojIWiCvrSHi4WR3ACZkbsdUe19I9en6OqX49+q5TapaKCJn4yxgKPh4mK1rGkeGVjbjLGrnG0EDAeDIYABwzn9JqurH8+AaIBvY2Z1v4scPbvyrreLqpwHfBfb0cCyh2gy8JSL/4OhJVd06xb4rxCmv2JbRbnU4302+E5Gf4iSAZ9xN3xSnpvH3PAzrKKp6VBEoEUnDacK8Cfhbmy/yXgZQLCIfcfT3NqzzgiwBmJCp6uElit0r1O/jlFz8mo+XLihxf5LcHz+7yP13EHAG8Ib7+FycGba+SwA49QsmqWozgIg8AQQA3ySAFiLSD2dplWtxFrCb5uOmwR/2xJtYAjCdIiIzgf/GuSq5T1XbGq/sG6r6P17HEKqWtfVFZClO++9O9/Fg4HEPQ+tIP6ClHnRfLwNpi4hk4FSxuxL4EzDZzwsZAqjq2z3xPpYATMhEZBlOh+TPgffdbYdnLPpprRoR+TtH91co8Anwpqo+3farfCO35eTv2o2zRLgf/S/OQotvcmQU0F3ehvQp24BynGGgtcANTnkAh5+aA1v1V0DQ9xa4M9x3LDYKCbUU0gAADG9JREFUyITMHeoXXAQ+eKVCX61V4zZRtTYAZ736Darqt5PUYSLyW2AUR1bYvBLYqKq3eBdV+9w7lGnuw49UdZeX8bQmIj/kGMvA+/0u0V3D7DrgDFX9Uge7d+7YlgBMLHEnhS1X1Ulex3Isbodwy8iad1TVr52VLetZtRSvAcDWhQq/7qhmaE1AJqa4M1S9DqND7ogfP3b6HkVEfoZzh1LE0RPtLAGEkTj1gMN+vrYEYKKSiAxoY3N/nBEgRT0cTkjaaP89/BT+XcDuUmCMhrlUYaxqZyhwf5wk+3wbzx0XSwAmWi3n6H6Kls60t3CWsvCd1uPVI8RmIJGgsep+JSIjVHVLR9s8dlGrx4pTYe3XqvqPcL+Z9QGYLhGRCXx6oSrfN1mY8BCRh3BOTkOBicDrHD1hyU/lQYG229BFZLmfljHvaXYHYDpNRP6Es5ha63ZfSwCxo2X11+XA4lbP+eqqUkTG4tTa6NuqiSUdZyJjzLIEYLriND+t8256nqo+AU6VLVX9dfBzbuUtPxkDXIgzYS24iaUGp0JYzLImINNpIvIo8ICqFnsdi/FWO80qAVWd7FVM7XHXKHrf6zhC0VP9FXYHYLriSeB9EdmF0+7bMkrFl2vsW39F+InIbOBq4EQRCW4C6sORZSH8ptQtBtNSD+BfwLdUtczDmNrzF6D1mP/ngbD2V1gCMF3xKHANsJojfQC+ZP0V3eY9nKWKM4AHgrbXAL6sW4CzFMQCoGU27ZfdbRd4FlErPd1fYQnAdEW5qrbu+PMr66/oBqq6TUTKgLqeWrgsDAap6mNBjx8XEd8UrXf1aH+FJQDTFQERWQD8naOH/vnxqvp9Ecmz/orwc2dVN4tIX7+vrun6RES+zJE1lmbjjLH3DVV9EXixp/orLAGYrkjBOfHPCNrm12aViOqviED7gdUi8ipwoGWjH+cBAF/FKbX5IM739T3gek8jal+P9FfYKCAT1dyawLfRqr9CVbd5FlQUEZGv41xIKtAIHIQjw0T9wl0E8ElVneN1LKFwE+oC4Cl305eBOaoa1v4KSwCm00QkB+dKyvejKUTkfVU93es4oo2IJAA/wbmq3oZzZzUMp1P1e36sYSwi/7+9e4+ZqyjjOP79VUCa1mpNgKgE0EK5WAFtQSgXuRj5Q4WioAUSgoBRY0VBwStSNSIEEhJATMRQ0RAhCK0g0aThIi+9cCmUVsq9BYUIKCC2EiqWn3/MrGy3u+27++7uOWf3+SRves7s7pznbdozO/PMmbkLOML2f4qOZUskPWh7n4ay5d1exTaGgEInSj+bok6V8hVVchFpyud7ba8FkDQJuDi/VrbkKqR1ixblaav1w1Wl2RCmTl/yFdEDCG1r9k2kF99OukHSvCbFtn1q34MZIJIeB6a64QaSh1oesb1bMZG1Jum8ZuVl3BBG0s6kXvaBvJmvOMP2X7p5negBhE68WPbZFDW1fXZD17nx5p8LN0gq5bfK2o1e0sR8vq7YiJrLjej5to/u9bXG9foCYSCdCnwGeI70MNBxlHQ2haQdJc2X9EL+uSHnMMLYrJJ0cmNh/mLwSAHxbJGkaZIeID0U+JCkZZLeX3RcjWxvAHaWtE2vrxVDQGGg9Ws2xbDJ20DeSJr1sywXzyBNET7W9rNFxdaKpMXAd23fns8PI33TnlloYE1I+hWwJ2ml1Z7lK6IBCKNWtwZ8U2Wc+12lfEUVSTqCtHQBwCrbtxYZz+a0mFmzSVkZ9CtfETmA0I7aGvAHAXsB1+Xz44GyPmlbmXxFFdm+Dbit6DhGabWkc9m4N7i6wHha6le+InoAoW2SlgIH2/5vPt8aGLF9QLGRbapfsylC+UmaDPwAODgXjQBzbb9cXFTNSZpGaqhqe1v/AzjZdlf3s44GILRN0qPAgbZfyueTgaW2dy82shAGQ7/yFTEEFDpxAekBq9tJT4AeCswtNKIGVcxXhN6QdDOb/7fQ8+mWHZhQu/kD2L5D0oRuXyQagNA22/Mk/QH4cC76pu3nioypiSrmK0JvXFx0AB3oS74ihoBCR/I0wJ3ZeJetO4uLqLkq5StCqOlXviJ6AKFtki4EPsumu2yVrgEAJpN2U6ptUzgxl4UhIekYYEfbP83ndwPb5ZfPsf3bwoJrId/oez5MGQ1A6MQsYHfb67f4zuKVPl8Reu4cYHbd+VuB/YAJpEUMS9MA9DtfEQ1A6MRqYGvqVtcsq4rkK0JvbWP7r3Xnd9l+kfSMSNcTq2PU13xF5ABC2yTdAOwD3MrGSyyXcmZNVfIVoTckPWF71xavPWl7Sr9jKovoAYRO3JR/Sq9i+YrQG3dL+rztK+sLJX0BuKegmJrqd74iegBhoOWH1vauSL4i9ICk7YEFpN7q/bl4OikXMMv280XF1kjSImB2bchK0nLgSHK+wvaR3bxe9ABC2yTtBvyENL9+21q57fcVFlRrlclXhN6w/QIws2HhulvyOkZl09d8RTQAoRPzgPOAS4DDSXsBlHVviVeB5ZIqka8IvVORhes2mqJse07d6XZ0WTQAoRPjbd8qSbafBuZKWgZ8v+jAmqhMviIE+pyviAYgdGK9pHHA45LmAM+SHrAqHdtXFx1DCG04E1gg6USa5Cu6fbFIAoe2SdoPeBh4B/Aj4O3AhbbvLjSwJiqWrwgB2GSjnYd6la+IBiCMWd7Eerbta4qOpZGku3gzX/FJcr7CdhmHq0Loq7Im7kIJSZok6duSLpf0MSVzgCdIm8SX0fi8TaFsP217LvDxgmMKoRQiBxDa8WvgZWAJcDrwHdL6OsfaXl5kYJtRmXxFCP0WQ0Bh1CSttP2BfPwW4G/ATrZfKzay1qqUrwih36IHENrxeu3A9gZJz5T55g9g+958uA74XC1fAUQDEIZe9ADCqEnaAPy7dgqMJz1oJcC2JxUVWyNJk4AvA+8hPQewMJ9/HVhh+5gCwwuhFKIBCANJ0u94M19xJLA9qaH6aonzFSH0VTQAYSBVMV8RQr/FNNAwqDbKVwClz1eE0G/RAwgDqUr5ihCKEg1ACCEMqRgCCiGEIRUNQAghDKloAEIIYUhFAxBCCEMqGoBQaZJ+IWmvLbznl5KOa1K+S954Y3OfnSHp0lHEsXi0dY6VpFn1v7OkOyTNGEN9Y/p8qK5oAEKl2T7d9qoOP74LsNmbte37RrN/sO2Zo62zC2aRNrgJYUyiAQilIOlsSWfk40sk3ZaPj5B0Td5/YImk+yVdL2lifv3/314lnSbpMUn3SLpS0uV1lzhU0mJJq+t6AxcAh0haLunMFnEdJun3+XiupKvyNVfX4s2vrWujzlMkLZC0UNJTkuZIOkvSA5KWSnpnft8USX+UtEzSiKQ9JM0EjgYuyteYkqs9Pv/ej0k6JH9+W0nzJK3MdR+ey8dLulbSw5Lmk56RCEMoGoBQFiPAIfl4BjBR0ta5bAXwPeCjtj8E3AecVf9hSe8GzgUOAA4C9mio/13AwcAnSDdpgG8BI7b3tX3JKOPcAzgK2B84L8dYb7R1TgM+BewH/Bh41fYHSWsXnZzf83PgK7anA98ArrC9mLS43dn5Gk/m925le3/ga6Qd0CAtfue8JMYJwNWStgW+lK+3Z37v9FH+7mHAxHLQoSyWAdPzKp7rSRtizyA1ADeRhjwWSQLYhnSjrLc/8CfbLwFIuh6YWvf6AttvAKsk7TCGOG+xvZ600cwLwA7AMx3Uc7vttcBaSa8AN+fylcDeuYczE7g+/86QNgZv5cb85zLSMBSkBu8yANuPSHqa9HdyKHBpLl8haUUH8YcBEA1AKAXbr0taA5wCLCZ96z8c2BVYAyy0fcIYLrG+7lgt39VePRvo/P9QfT1v1J2/kescB/zT9r5t1jeWmMKQiSGgUCYjpKGOO/PxF4EHgKXAQZJ2BZA0QdLUhs/eC3xE0mRJWwGfHsX11gJv61bw3azT9r+ANZKOB8j7L+/T5jVGgJPy56cCOwGPkv5+T8zl04C9xxpvqKZoAEKZjJDG6pfYfh54jTSe/ndSz+A3ebhiCQ1j/LafBc4H7gEWAU8Br2zheiuADZIebJWw7UA36zwJOE3Sg8BDQG0Tm2uBs3Nid0rLT8MVwDhJK4HrgFPy8NXPSDmWh4EfkoaNwhCKxeDCwJA00fa63AOYD1xle37RcYVQVtEDCINkrqTlwJ9JeYMFBccTQqlFDyAEQNJRwIUNxWtsH1umOkPopmgAQghhSMUQUAghDKloAEIIYUhFAxBCCEMqGoAQQhhS/wOB9lD7RTF7/AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37chbRgZDXF",
        "colab_type": "code",
        "outputId": "24a5fbe1-104f-48b4-cd3f-cd6771307164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classified = []\n",
        "\n",
        "for prediction in tqdm(predictions):\n",
        "    classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 8/8 [00:00<00:00, 155.62it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMfc-h8xAYQu"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAky42lMV102",
        "outputId": "4ff0b79d-bcb8-45f4-b7c6-6b000fba9893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(classified):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(classified):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "correlation_matrix_df = pd.DataFrame(correlation_matrix)\n",
        "correlation_matrix_df.columns = initializer\n",
        "correlation_matrix_df.index = initializer\n",
        "display(correlation_matrix_df)\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zero</th>\n",
              "      <th>Ones</th>\n",
              "      <th>Random Normal</th>\n",
              "      <th>Random Uniform</th>\n",
              "      <th>Identity</th>\n",
              "      <th>Orthogonal</th>\n",
              "      <th>Glorot Normal</th>\n",
              "      <th>Glorot Uniform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Zero</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.698989</td>\n",
              "      <td>0.685356</td>\n",
              "      <td>0.674571</td>\n",
              "      <td>0.700468</td>\n",
              "      <td>0.691858</td>\n",
              "      <td>0.739021</td>\n",
              "      <td>0.690494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ones</th>\n",
              "      <td>0.698989</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.675784</td>\n",
              "      <td>0.688195</td>\n",
              "      <td>0.683395</td>\n",
              "      <td>0.747948</td>\n",
              "      <td>0.720518</td>\n",
              "      <td>0.730012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Normal</th>\n",
              "      <td>0.685356</td>\n",
              "      <td>0.675784</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.722631</td>\n",
              "      <td>0.690634</td>\n",
              "      <td>0.677281</td>\n",
              "      <td>0.691547</td>\n",
              "      <td>0.704061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Uniform</th>\n",
              "      <td>0.674571</td>\n",
              "      <td>0.688195</td>\n",
              "      <td>0.722631</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.653515</td>\n",
              "      <td>0.674710</td>\n",
              "      <td>0.695407</td>\n",
              "      <td>0.747516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Identity</th>\n",
              "      <td>0.700468</td>\n",
              "      <td>0.683395</td>\n",
              "      <td>0.690634</td>\n",
              "      <td>0.653515</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.674485</td>\n",
              "      <td>0.689775</td>\n",
              "      <td>0.654344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orthogonal</th>\n",
              "      <td>0.691858</td>\n",
              "      <td>0.747948</td>\n",
              "      <td>0.677281</td>\n",
              "      <td>0.674710</td>\n",
              "      <td>0.674485</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.738113</td>\n",
              "      <td>0.685035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Normal</th>\n",
              "      <td>0.739021</td>\n",
              "      <td>0.720518</td>\n",
              "      <td>0.691547</td>\n",
              "      <td>0.695407</td>\n",
              "      <td>0.689775</td>\n",
              "      <td>0.738113</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.699134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Uniform</th>\n",
              "      <td>0.690494</td>\n",
              "      <td>0.730012</td>\n",
              "      <td>0.704061</td>\n",
              "      <td>0.747516</td>\n",
              "      <td>0.654344</td>\n",
              "      <td>0.685035</td>\n",
              "      <td>0.699134</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Zero      Ones  ...  Glorot Normal  Glorot Uniform\n",
              "Zero                 NaN  0.698989  ...       0.739021        0.690494\n",
              "Ones            0.698989       NaN  ...       0.720518        0.730012\n",
              "Random Normal   0.685356  0.675784  ...       0.691547        0.704061\n",
              "Random Uniform  0.674571  0.688195  ...       0.695407        0.747516\n",
              "Identity        0.700468  0.683395  ...       0.689775        0.654344\n",
              "Orthogonal      0.691858  0.747948  ...       0.738113        0.685035\n",
              "Glorot Normal   0.739021  0.720518  ...            NaN        0.699134\n",
              "Glorot Uniform  0.690494  0.730012  ...       0.699134             NaN\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.6973141656378681\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}