{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weight_int_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "outputId": "b043dc2b-3c7a-4cd3-c101-5ae41bb5c096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import scipy\n",
        "from tensorflow.keras import initializers\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 9999\n",
        "IMAGE_SIZE = 32\n",
        "NUM_CLASSES = 10\n",
        "NUM_CHANNELS = 3\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"CIFAR10_weight_init\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9M4_-IaBOsn"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n9nJGd_BQ-r",
        "colab": {}
      },
      "source": [
        "run = \"run3\"\n",
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8QvEt97vF52"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "dd777646-26a3-444c-af95-157f2899e3f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4SYRuKZaIwb",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBci5ba9hiaQ",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIBGIrlkvOt0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def CIFAR10model(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqdcrD_vQ-Q"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "b5e5f939-aeb8-4223-8403-e49d898e21e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = []\n",
        "predictions = []\n",
        "initializer = [\"Zero\",\"Ones\",\"Random Normal\",\"Random Uniform\",\"Identity\",\"Orthogonal\",\"Glorot Normal\",\"Glorot Uniform\"]\n",
        "for i in range(len(initializer)):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "    print(f\"Weight init method: {initializer[i]} \")\n",
        "    model = CIFAR10model(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
        "    \n",
        "    for layer in model.layers: \n",
        "        if hasattr(layer, 'kernel_initializer'):\n",
        "            if(initializer[i] == \"Zero\"):\n",
        "                layer.kernel_initializer = initializers.Zeros()\n",
        "            elif(initializer[i] == \"Ones\"):\n",
        "                layer.kernel_initializer = initializers.Ones()\n",
        "            elif(initializer[i] == \"Random Normal\"):\n",
        "                layer.kernel_initializer = initializers.RandomNormal()\n",
        "            elif(initializer[i] == \"Random Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.RandomUniform()\n",
        "            elif(initializer[i] == \"Identity\"):\n",
        "                layer.kernel_initializer = initializers.Identity()\n",
        "            elif(initializer[i] == \"Orthogonal\"):\n",
        "                layer.kernel_initializer = initializers.Orthogonal()\n",
        "            elif(initializer[i] == \"Glorot Normal\"):\n",
        "                layer.kernel_initializer = initializers.GlorotNormal()\n",
        "            elif(initializer[i] == \"Glorot Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.GlorotUnifrom()\n",
        "          \n",
        "    es = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
        "    model.fit(x_train,y_train,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = EPOCHS,\n",
        "              validation_data = (x_val,y_val),\n",
        "              shuffle = True,\n",
        "              callbacks=[es])\n",
        "    models.append(model)\n",
        "    y_prob = model.predict(x_test) \n",
        "    predictions.append(y_prob.argmax(axis=-1))\n",
        "    acc = model.evaluate(x_test,y_testc)[1]\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 0\n",
            "Weight init method: Zero \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 4s 88us/step - loss: 2.2695 - accuracy: 0.1587 - val_loss: 2.2631 - val_accuracy: 0.1522\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.1011 - accuracy: 0.2384 - val_loss: 2.0811 - val_accuracy: 0.2671\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9990 - accuracy: 0.2782 - val_loss: 1.9667 - val_accuracy: 0.2887\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9329 - accuracy: 0.3043 - val_loss: 1.9072 - val_accuracy: 0.3181\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.8827 - accuracy: 0.3243 - val_loss: 1.8624 - val_accuracy: 0.3339\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8412 - accuracy: 0.3386 - val_loss: 1.8222 - val_accuracy: 0.3450\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8063 - accuracy: 0.3496 - val_loss: 1.7915 - val_accuracy: 0.3475\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7754 - accuracy: 0.3599 - val_loss: 1.7646 - val_accuracy: 0.3447\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7486 - accuracy: 0.3679 - val_loss: 1.7586 - val_accuracy: 0.3469\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7270 - accuracy: 0.3757 - val_loss: 1.7155 - val_accuracy: 0.3758\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7090 - accuracy: 0.3807 - val_loss: 1.7008 - val_accuracy: 0.3742\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6940 - accuracy: 0.3862 - val_loss: 1.6870 - val_accuracy: 0.3820\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6809 - accuracy: 0.3905 - val_loss: 1.6752 - val_accuracy: 0.3876\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6690 - accuracy: 0.3967 - val_loss: 1.6656 - val_accuracy: 0.3880\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6593 - accuracy: 0.3989 - val_loss: 1.6585 - val_accuracy: 0.3820\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6501 - accuracy: 0.4031 - val_loss: 1.6488 - val_accuracy: 0.3984\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6420 - accuracy: 0.4088 - val_loss: 1.6411 - val_accuracy: 0.3984\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6329 - accuracy: 0.4077 - val_loss: 1.6301 - val_accuracy: 0.4105\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6275 - accuracy: 0.4129 - val_loss: 1.6244 - val_accuracy: 0.4086\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6209 - accuracy: 0.4164 - val_loss: 1.6276 - val_accuracy: 0.4001\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6158 - accuracy: 0.4189 - val_loss: 1.6192 - val_accuracy: 0.4123\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6084 - accuracy: 0.4212 - val_loss: 1.6070 - val_accuracy: 0.4123\n",
            "Epoch 23/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6033 - accuracy: 0.4231 - val_loss: 1.6039 - val_accuracy: 0.4118\n",
            "Epoch 24/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5984 - accuracy: 0.4239 - val_loss: 1.6086 - val_accuracy: 0.4156\n",
            "Epoch 25/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5925 - accuracy: 0.4281 - val_loss: 1.6024 - val_accuracy: 0.4149\n",
            "10000/10000 [==============================] - 1s 68us/step\n",
            "Model: 0 added. Resulting score: 0.4194999933242798\n",
            "Train model 1\n",
            "Weight init method: Ones \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 2s 59us/step - loss: 2.2406 - accuracy: 0.1721 - val_loss: 2.2577 - val_accuracy: 0.1741\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0982 - accuracy: 0.2474 - val_loss: 2.0841 - val_accuracy: 0.2554\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9952 - accuracy: 0.2916 - val_loss: 1.9590 - val_accuracy: 0.2970\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.9183 - accuracy: 0.3221 - val_loss: 1.8908 - val_accuracy: 0.3241\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.8625 - accuracy: 0.3422 - val_loss: 1.8433 - val_accuracy: 0.3397\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.8198 - accuracy: 0.3550 - val_loss: 1.8032 - val_accuracy: 0.3502\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7844 - accuracy: 0.3650 - val_loss: 1.7738 - val_accuracy: 0.3596\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7553 - accuracy: 0.3715 - val_loss: 1.7496 - val_accuracy: 0.3693\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7329 - accuracy: 0.3786 - val_loss: 1.7301 - val_accuracy: 0.3676\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7144 - accuracy: 0.3837 - val_loss: 1.7169 - val_accuracy: 0.3737\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6987 - accuracy: 0.3905 - val_loss: 1.7152 - val_accuracy: 0.3705\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6852 - accuracy: 0.3926 - val_loss: 1.6904 - val_accuracy: 0.3825\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6753 - accuracy: 0.3965 - val_loss: 1.6798 - val_accuracy: 0.3845\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6640 - accuracy: 0.4013 - val_loss: 1.6691 - val_accuracy: 0.3873\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6545 - accuracy: 0.4040 - val_loss: 1.6646 - val_accuracy: 0.3887\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6463 - accuracy: 0.4079 - val_loss: 1.6569 - val_accuracy: 0.3909\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6385 - accuracy: 0.4097 - val_loss: 1.6510 - val_accuracy: 0.3987\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6313 - accuracy: 0.4126 - val_loss: 1.6400 - val_accuracy: 0.3951\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6253 - accuracy: 0.4150 - val_loss: 1.6369 - val_accuracy: 0.3983\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6183 - accuracy: 0.4179 - val_loss: 1.6267 - val_accuracy: 0.4042\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6129 - accuracy: 0.4195 - val_loss: 1.6235 - val_accuracy: 0.4084\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 1.6065 - accuracy: 0.4227 - val_loss: 1.6121 - val_accuracy: 0.4128\n",
            "Epoch 23/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6012 - accuracy: 0.4242 - val_loss: 1.6105 - val_accuracy: 0.4129\n",
            "Epoch 24/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5957 - accuracy: 0.4253 - val_loss: 1.6058 - val_accuracy: 0.4153\n",
            "Epoch 25/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5914 - accuracy: 0.4294 - val_loss: 1.6023 - val_accuracy: 0.4208\n",
            "10000/10000 [==============================] - 1s 69us/step\n",
            "Model: 1 added. Resulting score: 0.4302999973297119\n",
            "Train model 2\n",
            "Weight init method: Random Normal \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 2s 57us/step - loss: 2.2553 - accuracy: 0.1627 - val_loss: 2.2509 - val_accuracy: 0.1843\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.1179 - accuracy: 0.2397 - val_loss: 2.1106 - val_accuracy: 0.2486\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 2.0295 - accuracy: 0.2830 - val_loss: 1.9942 - val_accuracy: 0.2910\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9575 - accuracy: 0.3117 - val_loss: 1.9285 - val_accuracy: 0.3187\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.9040 - accuracy: 0.3249 - val_loss: 1.8856 - val_accuracy: 0.3255\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.8631 - accuracy: 0.3365 - val_loss: 1.8456 - val_accuracy: 0.3376\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8296 - accuracy: 0.3431 - val_loss: 1.8258 - val_accuracy: 0.3278\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.8001 - accuracy: 0.3523 - val_loss: 1.8055 - val_accuracy: 0.3366\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7767 - accuracy: 0.3550 - val_loss: 1.7707 - val_accuracy: 0.3499\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7548 - accuracy: 0.3611 - val_loss: 1.7540 - val_accuracy: 0.3530\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7370 - accuracy: 0.3656 - val_loss: 1.7466 - val_accuracy: 0.3461\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7230 - accuracy: 0.3698 - val_loss: 1.7205 - val_accuracy: 0.3647\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7094 - accuracy: 0.3743 - val_loss: 1.7099 - val_accuracy: 0.3668\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6979 - accuracy: 0.3784 - val_loss: 1.7014 - val_accuracy: 0.3674\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6885 - accuracy: 0.3818 - val_loss: 1.6894 - val_accuracy: 0.3735\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6797 - accuracy: 0.3865 - val_loss: 1.6850 - val_accuracy: 0.3661\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6714 - accuracy: 0.3875 - val_loss: 1.6768 - val_accuracy: 0.3770\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6645 - accuracy: 0.3901 - val_loss: 1.6685 - val_accuracy: 0.3781\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6571 - accuracy: 0.3932 - val_loss: 1.6641 - val_accuracy: 0.3843\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6511 - accuracy: 0.3962 - val_loss: 1.6618 - val_accuracy: 0.3877\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6457 - accuracy: 0.3993 - val_loss: 1.6564 - val_accuracy: 0.3902\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6405 - accuracy: 0.4010 - val_loss: 1.6449 - val_accuracy: 0.3929\n",
            "Epoch 23/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6342 - accuracy: 0.4036 - val_loss: 1.6438 - val_accuracy: 0.3955\n",
            "Epoch 24/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6302 - accuracy: 0.4058 - val_loss: 1.6317 - val_accuracy: 0.3974\n",
            "Epoch 25/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6241 - accuracy: 0.4078 - val_loss: 1.6337 - val_accuracy: 0.4020\n",
            "Epoch 26/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6202 - accuracy: 0.4091 - val_loss: 1.6276 - val_accuracy: 0.4039\n",
            "Epoch 27/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6156 - accuracy: 0.4103 - val_loss: 1.6235 - val_accuracy: 0.3993\n",
            "10000/10000 [==============================] - 1s 69us/step\n",
            "Model: 2 added. Resulting score: 0.4049000144004822\n",
            "Train model 3\n",
            "Weight init method: Random Uniform \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 2s 59us/step - loss: 2.2792 - accuracy: 0.1789 - val_loss: 2.2600 - val_accuracy: 0.1624\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.1414 - accuracy: 0.2237 - val_loss: 2.1161 - val_accuracy: 0.2232\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0355 - accuracy: 0.2545 - val_loss: 1.9963 - val_accuracy: 0.2661\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9553 - accuracy: 0.2923 - val_loss: 1.9259 - val_accuracy: 0.2951\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9024 - accuracy: 0.3146 - val_loss: 1.8832 - val_accuracy: 0.3124\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8635 - accuracy: 0.3299 - val_loss: 1.8495 - val_accuracy: 0.3272\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8314 - accuracy: 0.3393 - val_loss: 1.8245 - val_accuracy: 0.3210\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.8040 - accuracy: 0.3468 - val_loss: 1.7988 - val_accuracy: 0.3219\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7792 - accuracy: 0.3574 - val_loss: 1.7740 - val_accuracy: 0.3436\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7576 - accuracy: 0.3654 - val_loss: 1.7597 - val_accuracy: 0.3528\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7402 - accuracy: 0.3680 - val_loss: 1.7446 - val_accuracy: 0.3570\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7247 - accuracy: 0.3753 - val_loss: 1.7233 - val_accuracy: 0.3564\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7106 - accuracy: 0.3811 - val_loss: 1.7128 - val_accuracy: 0.3679\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6973 - accuracy: 0.3831 - val_loss: 1.6955 - val_accuracy: 0.3691\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6854 - accuracy: 0.3880 - val_loss: 1.6971 - val_accuracy: 0.3668\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6749 - accuracy: 0.3914 - val_loss: 1.6759 - val_accuracy: 0.3824\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6645 - accuracy: 0.3963 - val_loss: 1.6673 - val_accuracy: 0.3822\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.6548 - accuracy: 0.3997 - val_loss: 1.6589 - val_accuracy: 0.3850\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6472 - accuracy: 0.4040 - val_loss: 1.6459 - val_accuracy: 0.3993\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.6396 - accuracy: 0.4057 - val_loss: 1.6415 - val_accuracy: 0.3960\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.6325 - accuracy: 0.4091 - val_loss: 1.6587 - val_accuracy: 0.3921\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.6242 - accuracy: 0.4130 - val_loss: 1.6440 - val_accuracy: 0.3985\n",
            "10000/10000 [==============================] - 1s 71us/step\n",
            "Model: 3 added. Resulting score: 0.4072999954223633\n",
            "Train model 4\n",
            "Weight init method: Identity \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 2s 59us/step - loss: 2.2329 - accuracy: 0.1480 - val_loss: 2.2553 - val_accuracy: 0.1526\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 2.1072 - accuracy: 0.2217 - val_loss: 2.1007 - val_accuracy: 0.2452\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0178 - accuracy: 0.2785 - val_loss: 1.9779 - val_accuracy: 0.2864\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9442 - accuracy: 0.3143 - val_loss: 1.9159 - val_accuracy: 0.3233\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.8847 - accuracy: 0.3365 - val_loss: 1.8648 - val_accuracy: 0.3143\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8391 - accuracy: 0.3486 - val_loss: 1.8242 - val_accuracy: 0.3462\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 51us/step - loss: 1.8028 - accuracy: 0.3591 - val_loss: 1.7979 - val_accuracy: 0.3494\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7736 - accuracy: 0.3666 - val_loss: 1.7659 - val_accuracy: 0.3510\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7506 - accuracy: 0.3742 - val_loss: 1.7456 - val_accuracy: 0.3648\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7305 - accuracy: 0.3794 - val_loss: 1.7265 - val_accuracy: 0.3713\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7148 - accuracy: 0.3841 - val_loss: 1.7167 - val_accuracy: 0.3743\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7001 - accuracy: 0.3869 - val_loss: 1.7111 - val_accuracy: 0.3699\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6875 - accuracy: 0.3934 - val_loss: 1.6893 - val_accuracy: 0.3759\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6768 - accuracy: 0.3959 - val_loss: 1.6798 - val_accuracy: 0.3831\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6663 - accuracy: 0.3985 - val_loss: 1.6649 - val_accuracy: 0.3892\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6583 - accuracy: 0.4011 - val_loss: 1.6575 - val_accuracy: 0.3902\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6494 - accuracy: 0.4057 - val_loss: 1.6588 - val_accuracy: 0.3873\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6413 - accuracy: 0.4083 - val_loss: 1.6507 - val_accuracy: 0.3936\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6349 - accuracy: 0.4097 - val_loss: 1.6551 - val_accuracy: 0.3860\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6282 - accuracy: 0.4139 - val_loss: 1.6281 - val_accuracy: 0.4030\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6225 - accuracy: 0.4139 - val_loss: 1.6227 - val_accuracy: 0.4031\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6156 - accuracy: 0.4182 - val_loss: 1.6163 - val_accuracy: 0.4060\n",
            "Epoch 23/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6100 - accuracy: 0.4215 - val_loss: 1.6273 - val_accuracy: 0.4045\n",
            "Epoch 24/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6042 - accuracy: 0.4216 - val_loss: 1.6064 - val_accuracy: 0.4098\n",
            "Epoch 25/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5983 - accuracy: 0.4241 - val_loss: 1.6006 - val_accuracy: 0.4118\n",
            "Epoch 26/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5928 - accuracy: 0.4277 - val_loss: 1.6000 - val_accuracy: 0.4101\n",
            "Epoch 27/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5893 - accuracy: 0.4283 - val_loss: 1.5912 - val_accuracy: 0.4159\n",
            "Epoch 28/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5839 - accuracy: 0.4292 - val_loss: 1.5869 - val_accuracy: 0.4181\n",
            "Epoch 29/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5786 - accuracy: 0.4326 - val_loss: 1.5848 - val_accuracy: 0.4172\n",
            "Epoch 30/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5751 - accuracy: 0.4327 - val_loss: 1.5947 - val_accuracy: 0.4112\n",
            "Epoch 31/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5710 - accuracy: 0.4365 - val_loss: 1.5738 - val_accuracy: 0.4295\n",
            "Epoch 32/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5663 - accuracy: 0.4386 - val_loss: 1.5656 - val_accuracy: 0.4270\n",
            "Epoch 33/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5621 - accuracy: 0.4401 - val_loss: 1.5619 - val_accuracy: 0.4296\n",
            "Epoch 34/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5575 - accuracy: 0.4425 - val_loss: 1.5687 - val_accuracy: 0.4324\n",
            "Epoch 35/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5531 - accuracy: 0.4439 - val_loss: 1.5518 - val_accuracy: 0.4341\n",
            "Epoch 36/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5489 - accuracy: 0.4449 - val_loss: 1.5525 - val_accuracy: 0.4336\n",
            "Epoch 37/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.5452 - accuracy: 0.4460 - val_loss: 1.5478 - val_accuracy: 0.4354\n",
            "Epoch 38/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5425 - accuracy: 0.4472 - val_loss: 1.5403 - val_accuracy: 0.4435\n",
            "Epoch 39/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5376 - accuracy: 0.4475 - val_loss: 1.5376 - val_accuracy: 0.4452\n",
            "Epoch 40/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5335 - accuracy: 0.4501 - val_loss: 1.5447 - val_accuracy: 0.4404\n",
            "Epoch 41/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5310 - accuracy: 0.4521 - val_loss: 1.5304 - val_accuracy: 0.4477\n",
            "10000/10000 [==============================] - 1s 74us/step\n",
            "Model: 4 added. Resulting score: 0.4496999979019165\n",
            "Train model 5\n",
            "Weight init method: Orthogonal \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 2s 59us/step - loss: 2.1794 - accuracy: 0.1843 - val_loss: 2.2199 - val_accuracy: 0.2041\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0347 - accuracy: 0.2521 - val_loss: 2.0354 - val_accuracy: 0.2625\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.9678 - accuracy: 0.2840 - val_loss: 1.9445 - val_accuracy: 0.2929\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.9203 - accuracy: 0.3047 - val_loss: 1.9009 - val_accuracy: 0.3093\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.8802 - accuracy: 0.3226 - val_loss: 1.8713 - val_accuracy: 0.3056\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.8466 - accuracy: 0.3338 - val_loss: 1.8355 - val_accuracy: 0.3284\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8160 - accuracy: 0.3450 - val_loss: 1.8074 - val_accuracy: 0.3286\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7892 - accuracy: 0.3563 - val_loss: 1.7878 - val_accuracy: 0.3393\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7661 - accuracy: 0.3623 - val_loss: 1.7641 - val_accuracy: 0.3496\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7462 - accuracy: 0.3683 - val_loss: 1.7482 - val_accuracy: 0.3500\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7297 - accuracy: 0.3722 - val_loss: 1.7321 - val_accuracy: 0.3567\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7144 - accuracy: 0.3785 - val_loss: 1.7163 - val_accuracy: 0.3669\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7022 - accuracy: 0.3828 - val_loss: 1.7077 - val_accuracy: 0.3707\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6904 - accuracy: 0.3871 - val_loss: 1.6955 - val_accuracy: 0.3721\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6797 - accuracy: 0.3899 - val_loss: 1.6877 - val_accuracy: 0.3793\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6700 - accuracy: 0.3943 - val_loss: 1.6812 - val_accuracy: 0.3806\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6612 - accuracy: 0.3981 - val_loss: 1.6700 - val_accuracy: 0.3777\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6543 - accuracy: 0.4023 - val_loss: 1.6708 - val_accuracy: 0.3891\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6466 - accuracy: 0.4052 - val_loss: 1.6580 - val_accuracy: 0.3847\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6403 - accuracy: 0.4061 - val_loss: 1.6482 - val_accuracy: 0.3969\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6340 - accuracy: 0.4090 - val_loss: 1.6467 - val_accuracy: 0.3946\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6269 - accuracy: 0.4117 - val_loss: 1.6368 - val_accuracy: 0.4024\n",
            "Epoch 23/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6212 - accuracy: 0.4138 - val_loss: 1.6343 - val_accuracy: 0.3991\n",
            "Epoch 24/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6156 - accuracy: 0.4163 - val_loss: 1.6342 - val_accuracy: 0.3966\n",
            "Epoch 25/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6104 - accuracy: 0.4190 - val_loss: 1.6292 - val_accuracy: 0.4089\n",
            "Epoch 26/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6052 - accuracy: 0.4206 - val_loss: 1.6275 - val_accuracy: 0.4095\n",
            "10000/10000 [==============================] - 1s 71us/step\n",
            "Model: 5 added. Resulting score: 0.40700000524520874\n",
            "Train model 6\n",
            "Weight init method: Glorot Normal \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 2s 59us/step - loss: 2.2235 - accuracy: 0.1749 - val_loss: 2.2443 - val_accuracy: 0.1893\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0837 - accuracy: 0.2531 - val_loss: 2.0879 - val_accuracy: 0.2437\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0026 - accuracy: 0.2779 - val_loss: 1.9844 - val_accuracy: 0.2771\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9523 - accuracy: 0.3079 - val_loss: 1.9390 - val_accuracy: 0.2944\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9123 - accuracy: 0.3223 - val_loss: 1.8981 - val_accuracy: 0.3227\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.8764 - accuracy: 0.3338 - val_loss: 1.8648 - val_accuracy: 0.3322\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.8456 - accuracy: 0.3458 - val_loss: 1.8365 - val_accuracy: 0.3451\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.8162 - accuracy: 0.3545 - val_loss: 1.8166 - val_accuracy: 0.3364\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7911 - accuracy: 0.3621 - val_loss: 1.7889 - val_accuracy: 0.3504\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.7668 - accuracy: 0.3682 - val_loss: 1.7633 - val_accuracy: 0.3631\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7468 - accuracy: 0.3750 - val_loss: 1.7442 - val_accuracy: 0.3634\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.7285 - accuracy: 0.3825 - val_loss: 1.7275 - val_accuracy: 0.3661\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7129 - accuracy: 0.3852 - val_loss: 1.7153 - val_accuracy: 0.3683\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6992 - accuracy: 0.3880 - val_loss: 1.7005 - val_accuracy: 0.3795\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6867 - accuracy: 0.3944 - val_loss: 1.6854 - val_accuracy: 0.3840\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6743 - accuracy: 0.4000 - val_loss: 1.6788 - val_accuracy: 0.3842\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6630 - accuracy: 0.4015 - val_loss: 1.6679 - val_accuracy: 0.3936\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6542 - accuracy: 0.4060 - val_loss: 1.6622 - val_accuracy: 0.3978\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6445 - accuracy: 0.4083 - val_loss: 1.6510 - val_accuracy: 0.3963\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6352 - accuracy: 0.4133 - val_loss: 1.6471 - val_accuracy: 0.3970\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6283 - accuracy: 0.4144 - val_loss: 1.6320 - val_accuracy: 0.4085\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6199 - accuracy: 0.4187 - val_loss: 1.6227 - val_accuracy: 0.4108\n",
            "Epoch 23/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.6138 - accuracy: 0.4198 - val_loss: 1.6180 - val_accuracy: 0.4097\n",
            "Epoch 24/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6059 - accuracy: 0.4229 - val_loss: 1.6109 - val_accuracy: 0.4143\n",
            "Epoch 25/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5998 - accuracy: 0.4267 - val_loss: 1.6212 - val_accuracy: 0.4138\n",
            "Epoch 26/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5933 - accuracy: 0.4293 - val_loss: 1.6046 - val_accuracy: 0.4200\n",
            "Epoch 27/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5893 - accuracy: 0.4303 - val_loss: 1.5968 - val_accuracy: 0.4192\n",
            "Epoch 28/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.5819 - accuracy: 0.4331 - val_loss: 1.5865 - val_accuracy: 0.4232\n",
            "Epoch 29/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5755 - accuracy: 0.4360 - val_loss: 1.5834 - val_accuracy: 0.4273\n",
            "Epoch 30/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5711 - accuracy: 0.4375 - val_loss: 1.5841 - val_accuracy: 0.4261\n",
            "Epoch 31/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5661 - accuracy: 0.4402 - val_loss: 1.5757 - val_accuracy: 0.4255\n",
            "Epoch 32/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5609 - accuracy: 0.4418 - val_loss: 1.5679 - val_accuracy: 0.4285\n",
            "Epoch 33/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5556 - accuracy: 0.4450 - val_loss: 1.5696 - val_accuracy: 0.4278\n",
            "Epoch 34/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5515 - accuracy: 0.4448 - val_loss: 1.5641 - val_accuracy: 0.4336\n",
            "Epoch 35/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5457 - accuracy: 0.4480 - val_loss: 1.5562 - val_accuracy: 0.4365\n",
            "Epoch 36/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5411 - accuracy: 0.4491 - val_loss: 1.5472 - val_accuracy: 0.4426\n",
            "Epoch 37/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5372 - accuracy: 0.4507 - val_loss: 1.5440 - val_accuracy: 0.4434\n",
            "Epoch 38/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5339 - accuracy: 0.4532 - val_loss: 1.5390 - val_accuracy: 0.4451\n",
            "Epoch 39/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5305 - accuracy: 0.4530 - val_loss: 1.5359 - val_accuracy: 0.4473\n",
            "Epoch 40/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5257 - accuracy: 0.4555 - val_loss: 1.5317 - val_accuracy: 0.4468\n",
            "Epoch 41/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5210 - accuracy: 0.4575 - val_loss: 1.5438 - val_accuracy: 0.4455\n",
            "Epoch 42/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5182 - accuracy: 0.4589 - val_loss: 1.5358 - val_accuracy: 0.4474\n",
            "10000/10000 [==============================] - 1s 70us/step\n",
            "Model: 6 added. Resulting score: 0.45179998874664307\n",
            "Train model 7\n",
            "Weight init method: Glorot Uniform \n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/9999\n",
            "40000/40000 [==============================] - 2s 59us/step - loss: 2.2353 - accuracy: 0.1642 - val_loss: 2.2445 - val_accuracy: 0.1481\n",
            "Epoch 2/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0900 - accuracy: 0.2607 - val_loss: 2.0782 - val_accuracy: 0.2566\n",
            "Epoch 3/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 2.0058 - accuracy: 0.2968 - val_loss: 1.9727 - val_accuracy: 0.2910\n",
            "Epoch 4/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.9457 - accuracy: 0.3111 - val_loss: 1.9157 - val_accuracy: 0.3053\n",
            "Epoch 5/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.8895 - accuracy: 0.3248 - val_loss: 1.8636 - val_accuracy: 0.3229\n",
            "Epoch 6/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.8451 - accuracy: 0.3391 - val_loss: 1.8247 - val_accuracy: 0.3304\n",
            "Epoch 7/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.8092 - accuracy: 0.3508 - val_loss: 1.7941 - val_accuracy: 0.3480\n",
            "Epoch 8/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7795 - accuracy: 0.3597 - val_loss: 1.7650 - val_accuracy: 0.3502\n",
            "Epoch 9/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.7538 - accuracy: 0.3672 - val_loss: 1.7449 - val_accuracy: 0.3616\n",
            "Epoch 10/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7336 - accuracy: 0.3746 - val_loss: 1.7295 - val_accuracy: 0.3631\n",
            "Epoch 11/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7169 - accuracy: 0.3771 - val_loss: 1.7205 - val_accuracy: 0.3718\n",
            "Epoch 12/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.7028 - accuracy: 0.3812 - val_loss: 1.6979 - val_accuracy: 0.3773\n",
            "Epoch 13/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6903 - accuracy: 0.3855 - val_loss: 1.6888 - val_accuracy: 0.3779\n",
            "Epoch 14/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6807 - accuracy: 0.3895 - val_loss: 1.6795 - val_accuracy: 0.3818\n",
            "Epoch 15/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6715 - accuracy: 0.3929 - val_loss: 1.6707 - val_accuracy: 0.3857\n",
            "Epoch 16/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6639 - accuracy: 0.3936 - val_loss: 1.6636 - val_accuracy: 0.3905\n",
            "Epoch 17/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6562 - accuracy: 0.3978 - val_loss: 1.6652 - val_accuracy: 0.3900\n",
            "Epoch 18/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6494 - accuracy: 0.4020 - val_loss: 1.6553 - val_accuracy: 0.3952\n",
            "Epoch 19/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6433 - accuracy: 0.4031 - val_loss: 1.6464 - val_accuracy: 0.3994\n",
            "Epoch 20/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6367 - accuracy: 0.4061 - val_loss: 1.6393 - val_accuracy: 0.4025\n",
            "Epoch 21/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6316 - accuracy: 0.4086 - val_loss: 1.6330 - val_accuracy: 0.4087\n",
            "Epoch 22/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6262 - accuracy: 0.4103 - val_loss: 1.6279 - val_accuracy: 0.4075\n",
            "Epoch 23/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6213 - accuracy: 0.4123 - val_loss: 1.6251 - val_accuracy: 0.4109\n",
            "Epoch 24/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6161 - accuracy: 0.4154 - val_loss: 1.6194 - val_accuracy: 0.4086\n",
            "Epoch 25/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6112 - accuracy: 0.4178 - val_loss: 1.6147 - val_accuracy: 0.4149\n",
            "Epoch 26/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.6055 - accuracy: 0.4199 - val_loss: 1.6123 - val_accuracy: 0.4158\n",
            "Epoch 27/9999\n",
            "40000/40000 [==============================] - 2s 52us/step - loss: 1.6000 - accuracy: 0.4226 - val_loss: 1.6043 - val_accuracy: 0.4197\n",
            "Epoch 28/9999\n",
            "40000/40000 [==============================] - 2s 53us/step - loss: 1.5952 - accuracy: 0.4240 - val_loss: 1.6019 - val_accuracy: 0.4219\n",
            "Epoch 29/9999\n",
            "40000/40000 [==============================] - 2s 54us/step - loss: 1.5911 - accuracy: 0.4267 - val_loss: 1.5981 - val_accuracy: 0.4181\n",
            "Epoch 30/9999\n",
            "40000/40000 [==============================] - 2s 55us/step - loss: 1.5867 - accuracy: 0.4283 - val_loss: 1.5978 - val_accuracy: 0.4227\n",
            "10000/10000 [==============================] - 1s 76us/step\n",
            "Model: 7 added. Resulting score: 0.42320001125335693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fGT6jV-hcLbJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CurcmjMCcrJI"
      },
      "source": [
        "# Accuracy vs Weight initialization method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yvZLQyb5cg7R",
        "outputId": "c80aef5d-bde6-44d5-b7d0-a059b5fb43bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "accuracy_df[\"weight_init_method\"] = initializer\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy_\"+ run + \".csv\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>weight_init_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.4195</td>\n",
              "      <td>Zero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4303</td>\n",
              "      <td>Ones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.4049</td>\n",
              "      <td>Random Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.4073</td>\n",
              "      <td>Random Uniform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.4497</td>\n",
              "      <td>Identity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.4070</td>\n",
              "      <td>Orthogonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.4518</td>\n",
              "      <td>Glorot Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.4232</td>\n",
              "      <td>Glorot Uniform</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy weight_init_method\n",
              "0    0.4195               Zero\n",
              "1    0.4303               Ones\n",
              "2    0.4049      Random Normal\n",
              "3    0.4073     Random Uniform\n",
              "4    0.4497           Identity\n",
              "5    0.4070         Orthogonal\n",
              "6    0.4518      Glorot Normal\n",
              "7    0.4232     Glorot Uniform"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXq8Uj3lenzH",
        "outputId": "cd53c336-a340-431b-b866-acc612672d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy_df.plot(x=\"weight_init_method\", y=\"Accuracy\",rot = 90)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37chbRgZDXF",
        "colab_type": "code",
        "outputId": "237cc620-e856-4dfe-f4f8-a49153aa38c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classified = []\n",
        "\n",
        "for prediction in tqdm(predictions):\n",
        "    classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 8/8 [00:00<00:00, 102.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMfc-h8xAYQu"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAky42lMV102",
        "outputId": "6e7a2366-f8fa-4aa3-cf11-ba7397ca87ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(classified):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(classified):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "correlation_matrix_df = pd.DataFrame(correlation_matrix)\n",
        "correlation_matrix_df.columns = initializer\n",
        "correlation_matrix_df.index = initializer\n",
        "display(correlation_matrix_df)\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))\n",
        "correlation_matrix_df.to_csv(PATH + MODEL_NAME + \"_correlation_matrix_\" + run + \".csv\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zero</th>\n",
              "      <th>Ones</th>\n",
              "      <th>Random Normal</th>\n",
              "      <th>Random Uniform</th>\n",
              "      <th>Identity</th>\n",
              "      <th>Orthogonal</th>\n",
              "      <th>Glorot Normal</th>\n",
              "      <th>Glorot Uniform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Zero</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.661358</td>\n",
              "      <td>0.637995</td>\n",
              "      <td>0.596952</td>\n",
              "      <td>0.623051</td>\n",
              "      <td>0.616102</td>\n",
              "      <td>0.645671</td>\n",
              "      <td>0.646681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ones</th>\n",
              "      <td>0.661358</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.649982</td>\n",
              "      <td>0.656228</td>\n",
              "      <td>0.668664</td>\n",
              "      <td>0.662179</td>\n",
              "      <td>0.650513</td>\n",
              "      <td>0.686764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Normal</th>\n",
              "      <td>0.637995</td>\n",
              "      <td>0.649982</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.645922</td>\n",
              "      <td>0.609016</td>\n",
              "      <td>0.600057</td>\n",
              "      <td>0.613468</td>\n",
              "      <td>0.646726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Uniform</th>\n",
              "      <td>0.596952</td>\n",
              "      <td>0.656228</td>\n",
              "      <td>0.645922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.622443</td>\n",
              "      <td>0.611192</td>\n",
              "      <td>0.601100</td>\n",
              "      <td>0.657179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Identity</th>\n",
              "      <td>0.623051</td>\n",
              "      <td>0.668664</td>\n",
              "      <td>0.609016</td>\n",
              "      <td>0.622443</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.653755</td>\n",
              "      <td>0.689596</td>\n",
              "      <td>0.695284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orthogonal</th>\n",
              "      <td>0.616102</td>\n",
              "      <td>0.662179</td>\n",
              "      <td>0.600057</td>\n",
              "      <td>0.611192</td>\n",
              "      <td>0.653755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.606631</td>\n",
              "      <td>0.642535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Normal</th>\n",
              "      <td>0.645671</td>\n",
              "      <td>0.650513</td>\n",
              "      <td>0.613468</td>\n",
              "      <td>0.601100</td>\n",
              "      <td>0.689596</td>\n",
              "      <td>0.606631</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.632815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Uniform</th>\n",
              "      <td>0.646681</td>\n",
              "      <td>0.686764</td>\n",
              "      <td>0.646726</td>\n",
              "      <td>0.657179</td>\n",
              "      <td>0.695284</td>\n",
              "      <td>0.642535</td>\n",
              "      <td>0.632815</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Zero      Ones  ...  Glorot Normal  Glorot Uniform\n",
              "Zero                 NaN  0.661358  ...       0.645671        0.646681\n",
              "Ones            0.661358       NaN  ...       0.650513        0.686764\n",
              "Random Normal   0.637995  0.649982  ...       0.613468        0.646726\n",
              "Random Uniform  0.596952  0.656228  ...       0.601100        0.657179\n",
              "Identity        0.623051  0.668664  ...       0.689596        0.695284\n",
              "Orthogonal      0.616102  0.662179  ...       0.606631        0.642535\n",
              "Glorot Normal   0.645671  0.650513  ...            NaN        0.632815\n",
              "Glorot Uniform  0.646681  0.686764  ...       0.632815             NaN\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.6403521401310314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNnDeNX3Tjvd",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iySa4qVRTj_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(models, X, Y):\n",
        "    predictions = []\n",
        "\n",
        "    for m in tqdm(models):\n",
        "        predictions.append(np.argmax(m.predict(X), axis=1))\n",
        "\n",
        "    prediction = np.transpose(predictions)\n",
        "    prediction = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=prediction)\n",
        "\n",
        "    return accuracy_score(prediction, np.argmax(Y, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1apaRTmkTkHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8579105b-ea20-4212-e116-40897b860861"
      },
      "source": [
        "print(\"Accuracy of ensemble: \" + str(predict(models, x_test, y_testc)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 8/8 [00:03<00:00,  2.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of ensemble: 0.4414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}