{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "weight_int_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fde69AMuOpox",
        "outputId": "1a25937b-92ca-4e4f-d6ef-a9e6161fed0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from itertools import count\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.datasets import mnist\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from scipy.stats import pearsonr\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qYrab7qpOppj",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "IMAGE_SIZE = 28\n",
        "NUM_CLASSES = 10\n",
        "NUM_CHANNELS = 1\n",
        "MODEL_ADDITION_DELTA = 0.01\n",
        "MODEL_ADDITION_PATIENCE = 3\n",
        "MODEL_NAME = \"MNIST_weight_init\"\n",
        "PATH = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R9M4_-IaBOsn"
      },
      "source": [
        "# Set seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n9nJGd_BQ-r",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g8QvEt97vF52"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JtJIUBsFKeRO",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    \n",
        "    return imgs.reshape(imgs.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XypdmBJROpp9",
        "outputId": "58558453-4d7c-4bbf-a4bd-98144abf383f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mo8yHyg-Opqo",
        "colab": {}
      },
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_testc = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4SYRuKZaIwb",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBci5ba9hiaQ",
        "colab": {}
      },
      "source": [
        "# Split the data\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIBGIrlkvOt0"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLWph6_aOpr2",
        "colab": {}
      },
      "source": [
        "def MNISTmodel(imsize, num_classes, num_channels):\n",
        "    inputs = Input((imsize,imsize,num_channels))\n",
        "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
        "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
        "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Activation('softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVqdcrD_vQ-Q"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HjvZqLBJOpsw",
        "outputId": "59d6b008-0b93-4dd7-b749-5ebc0dd6da66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "accuracies = []\n",
        "predictions = []\n",
        "initializer = [\"Zero\",\"Ones\",\"Random Normal\",\"Random Uniform\",\"Identity\",\"Orthogonal\",\"Glorot Normal\",\"Glorot Uniform\"]\n",
        "for i in range(len(initializer)):\n",
        "\n",
        "    print(f\"Train model {i}\")\n",
        "    print(f\"Weight init method: {initializer[i]} \")\n",
        "    model = MNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)\n",
        "    \n",
        "    for layer in model.layers: \n",
        "        if hasattr(layer, 'kernel_initializer'):\n",
        "            if(initializer[i] == \"Zero\"):\n",
        "                layer.kernel_initializer = initializers.Zeros()\n",
        "            elif(initializer[i] == \"Ones\"):\n",
        "                layer.kernel_initializer = initializers.Ones()\n",
        "            elif(initializer[i] == \"Random Normal\"):\n",
        "                layer.kernel_initializer = initializers.RandomNormal()\n",
        "            elif(initializer[i] == \"Random Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.RandomUniform()\n",
        "            elif(initializer[i] == \"Identity\"):\n",
        "                layer.kernel_initializer = initializers.Identity()\n",
        "            elif(initializer[i] == \"Orthogonal\"):\n",
        "                layer.kernel_initializer = initializers.Orthogonal()\n",
        "            elif(initializer[i] == \"Glorot Normal\"):\n",
        "                layer.kernel_initializer = initializers.GlorotNormal()\n",
        "            elif(initializer[i] == \"Glorot Unifrom\"):\n",
        "                layer.kernel_initializer = initializers.GlorotUnifrom()\n",
        "          \n",
        "    es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', min_delta=0.01, patience=3)\n",
        "    model.fit(x_train,y_train,\n",
        "              batch_size = BATCH_SIZE,\n",
        "              epochs = EPOCHS,\n",
        "              validation_data = (x_val,y_val),\n",
        "              shuffle = True,\n",
        "              callbacks=[es])\n",
        "    models.append(model)\n",
        "    y_prob = model.predict(x_test) \n",
        "    predictions.append(y_prob.argmax(axis=-1))\n",
        "    acc = model.evaluate(x_test,y_testc)[1]\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"Model: {i} added. Resulting score: {acc}\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train model 0\n",
            "Weight init method: Zero \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 5s 105us/step - loss: 2.2383 - accuracy: 0.2219 - val_loss: 2.2467 - val_accuracy: 0.2068\n",
            "Epoch 2/10\n",
            " 2816/48000 [>.............................] - ETA: 2s - loss: 2.1648 - accuracy: 0.2905"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 4s 75us/step - loss: 2.0996 - accuracy: 0.3081 - val_loss: 2.0427 - val_accuracy: 0.3157\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.9634 - accuracy: 0.3476 - val_loss: 1.8966 - val_accuracy: 0.3738\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8458 - accuracy: 0.3881 - val_loss: 1.7886 - val_accuracy: 0.4082\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.7493 - accuracy: 0.4177 - val_loss: 1.7036 - val_accuracy: 0.4263\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6731 - accuracy: 0.4415 - val_loss: 1.6352 - val_accuracy: 0.4522\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.6121 - accuracy: 0.4566 - val_loss: 1.5793 - val_accuracy: 0.4696\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.5616 - accuracy: 0.4697 - val_loss: 1.5339 - val_accuracy: 0.4802\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.5191 - accuracy: 0.4842 - val_loss: 1.4933 - val_accuracy: 0.4942\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.4826 - accuracy: 0.4937 - val_loss: 1.4597 - val_accuracy: 0.4987\n",
            "10000/10000 [==============================] - 1s 96us/step\n",
            "Model: 0 added. Resulting score: 0.5009999871253967\n",
            "Train model 1\n",
            "Weight init method: Ones \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 84us/step - loss: 2.2958 - accuracy: 0.1665 - val_loss: 2.2783 - val_accuracy: 0.2340\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 2.1911 - accuracy: 0.2810 - val_loss: 2.1479 - val_accuracy: 0.3073\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 2.0813 - accuracy: 0.3168 - val_loss: 2.0191 - val_accuracy: 0.3259\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.9625 - accuracy: 0.3308 - val_loss: 1.8931 - val_accuracy: 0.3507\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8439 - accuracy: 0.3675 - val_loss: 1.7860 - val_accuracy: 0.3842\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7463 - accuracy: 0.4062 - val_loss: 1.6988 - val_accuracy: 0.4353\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.6706 - accuracy: 0.4400 - val_loss: 1.6303 - val_accuracy: 0.4619\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.6085 - accuracy: 0.4652 - val_loss: 1.5757 - val_accuracy: 0.4793\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.5558 - accuracy: 0.4859 - val_loss: 1.5242 - val_accuracy: 0.5016\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.5083 - accuracy: 0.5058 - val_loss: 1.4796 - val_accuracy: 0.5167\n",
            "10000/10000 [==============================] - 1s 95us/step\n",
            "Model: 1 added. Resulting score: 0.5142999887466431\n",
            "Train model 2\n",
            "Weight init method: Random Normal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 2.3065 - accuracy: 0.1165 - val_loss: 2.2770 - val_accuracy: 0.2276\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 2.1556 - accuracy: 0.2713 - val_loss: 2.0921 - val_accuracy: 0.2967\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 2.0122 - accuracy: 0.3270 - val_loss: 1.9398 - val_accuracy: 0.3362\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.8853 - accuracy: 0.3621 - val_loss: 1.8157 - val_accuracy: 0.3835\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7795 - accuracy: 0.3978 - val_loss: 1.7260 - val_accuracy: 0.4262\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.6964 - accuracy: 0.4290 - val_loss: 1.6525 - val_accuracy: 0.4467\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.6285 - accuracy: 0.4497 - val_loss: 1.5920 - val_accuracy: 0.4602\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 73us/step - loss: 1.5723 - accuracy: 0.4656 - val_loss: 1.5391 - val_accuracy: 0.4782\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.5244 - accuracy: 0.4784 - val_loss: 1.4958 - val_accuracy: 0.4910\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.4841 - accuracy: 0.4867 - val_loss: 1.4581 - val_accuracy: 0.5011\n",
            "10000/10000 [==============================] - 1s 94us/step\n",
            "Model: 2 added. Resulting score: 0.5013999938964844\n",
            "Train model 3\n",
            "Weight init method: Random Uniform \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 83us/step - loss: 2.2921 - accuracy: 0.1493 - val_loss: 2.2619 - val_accuracy: 0.1673\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 80us/step - loss: 2.1423 - accuracy: 0.2888 - val_loss: 2.0901 - val_accuracy: 0.2978\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.9973 - accuracy: 0.3531 - val_loss: 1.9109 - val_accuracy: 0.3838\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.8482 - accuracy: 0.3901 - val_loss: 1.7719 - val_accuracy: 0.4212\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.7270 - accuracy: 0.4307 - val_loss: 1.6673 - val_accuracy: 0.4580\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6365 - accuracy: 0.4625 - val_loss: 1.5905 - val_accuracy: 0.4786\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.5674 - accuracy: 0.4847 - val_loss: 1.5305 - val_accuracy: 0.5003\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.5123 - accuracy: 0.5008 - val_loss: 1.4819 - val_accuracy: 0.5187\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.4670 - accuracy: 0.5154 - val_loss: 1.4410 - val_accuracy: 0.5266\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.4279 - accuracy: 0.5264 - val_loss: 1.4047 - val_accuracy: 0.5388\n",
            "10000/10000 [==============================] - 1s 96us/step\n",
            "Model: 3 added. Resulting score: 0.554099977016449\n",
            "Train model 4\n",
            "Weight init method: Identity \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 83us/step - loss: 2.2456 - accuracy: 0.2134 - val_loss: 2.2561 - val_accuracy: 0.2435\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 2.1216 - accuracy: 0.3414 - val_loss: 2.0445 - val_accuracy: 0.3344\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.9505 - accuracy: 0.3589 - val_loss: 1.8590 - val_accuracy: 0.3673\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.8093 - accuracy: 0.3951 - val_loss: 1.7438 - val_accuracy: 0.4165\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7096 - accuracy: 0.4309 - val_loss: 1.6594 - val_accuracy: 0.4498\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.6331 - accuracy: 0.4583 - val_loss: 1.5947 - val_accuracy: 0.4696\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.5734 - accuracy: 0.4771 - val_loss: 1.5377 - val_accuracy: 0.4967\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.5224 - accuracy: 0.4922 - val_loss: 1.4925 - val_accuracy: 0.5011\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.4799 - accuracy: 0.5056 - val_loss: 1.4523 - val_accuracy: 0.5161\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.4427 - accuracy: 0.5152 - val_loss: 1.4169 - val_accuracy: 0.5253\n",
            "10000/10000 [==============================] - 1s 92us/step\n",
            "Model: 4 added. Resulting score: 0.5360000133514404\n",
            "Train model 5\n",
            "Weight init method: Orthogonal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 2.2752 - accuracy: 0.2000 - val_loss: 2.2667 - val_accuracy: 0.2124\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 2.1510 - accuracy: 0.2809 - val_loss: 2.0876 - val_accuracy: 0.3398\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 2.0064 - accuracy: 0.3480 - val_loss: 1.9298 - val_accuracy: 0.3694\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 1.8777 - accuracy: 0.3887 - val_loss: 1.8141 - val_accuracy: 0.3886\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 79us/step - loss: 1.7720 - accuracy: 0.4164 - val_loss: 1.7190 - val_accuracy: 0.4333\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.6877 - accuracy: 0.4410 - val_loss: 1.6445 - val_accuracy: 0.4620\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.6198 - accuracy: 0.4656 - val_loss: 1.5848 - val_accuracy: 0.4717\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.5641 - accuracy: 0.4837 - val_loss: 1.5345 - val_accuracy: 0.4874\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.5160 - accuracy: 0.4975 - val_loss: 1.4893 - val_accuracy: 0.5041\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4733 - accuracy: 0.5112 - val_loss: 1.4491 - val_accuracy: 0.5157\n",
            "10000/10000 [==============================] - 1s 101us/step\n",
            "Model: 5 added. Resulting score: 0.5189999938011169\n",
            "Train model 6\n",
            "Weight init method: Glorot Normal \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 2.2523 - accuracy: 0.1727 - val_loss: 2.2519 - val_accuracy: 0.2593\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 2.1050 - accuracy: 0.3288 - val_loss: 2.0359 - val_accuracy: 0.3338\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.9643 - accuracy: 0.3623 - val_loss: 1.8936 - val_accuracy: 0.3920\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.8506 - accuracy: 0.4058 - val_loss: 1.7925 - val_accuracy: 0.4166\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7584 - accuracy: 0.4304 - val_loss: 1.7095 - val_accuracy: 0.4356\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.6811 - accuracy: 0.4510 - val_loss: 1.6422 - val_accuracy: 0.4613\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.6161 - accuracy: 0.4709 - val_loss: 1.5804 - val_accuracy: 0.4841\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 78us/step - loss: 1.5601 - accuracy: 0.4877 - val_loss: 1.5280 - val_accuracy: 0.5025\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.5099 - accuracy: 0.5033 - val_loss: 1.4812 - val_accuracy: 0.5238\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 1.4664 - accuracy: 0.5168 - val_loss: 1.4391 - val_accuracy: 0.5188\n",
            "10000/10000 [==============================] - 1s 91us/step\n",
            "Model: 6 added. Resulting score: 0.5224999785423279\n",
            "Train model 7\n",
            "Weight init method: Glorot Uniform \n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 4s 84us/step - loss: 2.2758 - accuracy: 0.1528 - val_loss: 2.2686 - val_accuracy: 0.2033\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 2.1708 - accuracy: 0.2976 - val_loss: 2.1253 - val_accuracy: 0.2977\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 4s 75us/step - loss: 2.0470 - accuracy: 0.3344 - val_loss: 1.9715 - val_accuracy: 0.3553\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.9122 - accuracy: 0.3740 - val_loss: 1.8393 - val_accuracy: 0.3805\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.7942 - accuracy: 0.4040 - val_loss: 1.7349 - val_accuracy: 0.4132\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 4s 74us/step - loss: 1.7006 - accuracy: 0.4346 - val_loss: 1.6524 - val_accuracy: 0.4400\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.6270 - accuracy: 0.4561 - val_loss: 1.5872 - val_accuracy: 0.4645\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.5658 - accuracy: 0.4760 - val_loss: 1.5337 - val_accuracy: 0.4749\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 4s 77us/step - loss: 1.5157 - accuracy: 0.4893 - val_loss: 1.4840 - val_accuracy: 0.5007\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 4s 76us/step - loss: 1.4730 - accuracy: 0.5037 - val_loss: 1.4451 - val_accuracy: 0.5177\n",
            "10000/10000 [==============================] - 1s 94us/step\n",
            "Model: 7 added. Resulting score: 0.5231000185012817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fGT6jV-hcLbJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CurcmjMCcrJI"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yvZLQyb5cg7R",
        "outputId": "d101ac90-a53b-40c7-8cc8-fb275c6cddd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "accuracy_df = pd.DataFrame(accuracies, columns=[\"Accuracy\"])\n",
        "accuracy_df[\"weight_init_method\"] = initializer\n",
        "display(accuracy_df)\n",
        "\n",
        "accuracy_df.to_csv(PATH + MODEL_NAME + \"_accuracy.csv\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>weight_init_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5010</td>\n",
              "      <td>Zero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5143</td>\n",
              "      <td>Ones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5014</td>\n",
              "      <td>Random Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5541</td>\n",
              "      <td>Random Uniform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5360</td>\n",
              "      <td>Identity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.5190</td>\n",
              "      <td>Orthogonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.5225</td>\n",
              "      <td>Glorot Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.5231</td>\n",
              "      <td>Glorot Uniform</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accuracy weight_init_method\n",
              "0    0.5010               Zero\n",
              "1    0.5143               Ones\n",
              "2    0.5014      Random Normal\n",
              "3    0.5541     Random Uniform\n",
              "4    0.5360           Identity\n",
              "5    0.5190         Orthogonal\n",
              "6    0.5225      Glorot Normal\n",
              "7    0.5231     Glorot Uniform"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXq8Uj3lenzH",
        "outputId": "49a27c49-4147-4d11-d371-4b77ec3e3926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy_df.plot(x=\"weight_init_method\", y=\"Accuracy\",rot = 90)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFRCAYAAAB6y2ZlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3xV9fnA8c+TDQlhBmQHlA0JYICKo1p3VUTRuhG1amstVasVf45aba2jVlu1w6qIWnHgQK3VKu4JIWEvEc1gBkggjOzn98c5gUvIgtx7z7k3z/v1yot7vnecJ+Hmybnf8XxFVTHGGBO9YrwOwBhjTGhZojfGmChnid4YY6KcJXpjjIlyluiNMSbKxXkdQF1dunTR9PR0r8MwxpiIMn/+/M2qmlbffb5L9Onp6WRnZ3sdhjHGRBQRyWvoPuu6McaYKGeJ3hhjopwlemOMiXK+66M3xkS3yspKCgsLKSsr8zqUiJSUlESvXr2Ij49v9nMs0RtjwqqwsJB27dqRnp6OiHgdTkRRVbZs2UJhYSH9+vVr9vOs68YYE1ZlZWV07tzZkvxBEBE6d+58wJ+GLNEbY8LOkvzBO5ifnSV6E3WWrN3GO0s2eB2GMb5hid5EnfveWcE1/57PosISr0MxPvb6668jIqxYscLrUELOEr2JKjU1yoKCEmoUfjNrEZXVNV6HZHxq5syZHHXUUcycOTNk56iurg7Zax8IS/Qmqqwu2kFpWRWnDj+EFRtKefyTNV6HZHxox44dfPbZZzz55JO88MILgJOUb7zxRoYPH05GRgaPPPIIAPPmzWP8+PFkZmYyduxYSktLefrpp7n22mv3vN7pp5/ORx99BEBKSgq//vWvyczM5Msvv+Suu+5izJgxDB8+nKuuuoraXf1Wr17NCSecQGZmJqNHj+bbb79l8uTJvP7663te96KLLmL27Nkt/n5teqWJKjl5xQDcdPIgYkT4y5xvOHnYIRzWNcXjyEx9fvfmUpat2x7U1xzaI5XfnjGs0cfMnj2bU045hYEDB9K5c2fmz5/P3Llz+f7771mwYAFxcXFs3bqViooKzjvvPF588UXGjBnD9u3badOmTaOvvXPnTsaNG8eDDz7oxDN0KHfccQcAl1xyCW+99RZnnHEGF110EdOmTeOss86irKyMmpoarrjiCh566CEmTpzItm3b+OKLL5gxY0aLfyZ2RW+iSm5+CR3axtOvSzJ3ThhGm/hYbnl1ETU1tjey2WvmzJmcf/75AJx//vnMnDmT999/n6uvvpq4OOf6t1OnTqxcuZLu3bszZswYAFJTU/fc35DY2FgmTZq05/jDDz9k3LhxjBgxgg8++IClS5dSWlrK2rVrOeusswBnEVTbtm354Q9/yDfffENRUREzZ85k0qRJTZ6vOeyK3kSVnPxiRvXugIiQ1i6R204bwk2zFvHvr/O45Ih0r8MzdTR15R0KW7du5YMPPmDx4sWICNXV1YjInmTeHHFxcdTU7B3/CZzXnpSURGxs7J72a665huzsbHr37s2dd97Z5Bz4yZMn89xzz/HCCy8wffr0A/zu6mdX9CZqbNtdyTebdjC6T8c9becc3oujB3Th3v+uYF3Jbg+jM34xa9YsLrnkEvLy8vj+++8pKCigX79+ZGZm8s9//pOqqirA+YMwaNAg1q9fz7x58wAoLS2lqqqK9PR0FixYQE1NDQUFBcydO7fec9Um9S5durBjxw5mzZoFQLt27ejVq9ee/vjy8nJ27doFwJQpU3j44YcBp9snGCzRm6ixoMCZTjm6795ELyLcc9YIahRue33JnoEw03rNnDlzT5dJrUmTJrF+/Xr69OlDRkYGmZmZPP/88yQkJPDiiy/yy1/+kszMTE488UTKyso48sgj6devH0OHDmXq1KmMHj263nN16NCBK6+8kuHDh3PyySfv86nh2Wef5a9//SsZGRmMHz+eDRuctR/dunVjyJAhXHbZZUH7nsVvb/ysrCy1jUfMwXj4/VX8Zc43LL7zZFIS9+2VfPKz77j7rWX85fyRnDmyp0cRGoDly5czZMgQr8PwrV27djFixAhycnJo3759vY+p72coIvNVNau+x9sVvYkaOfklDOrWbr8kDzBlfDoje3fgd28uY+vOCg+iM6Zp77//PkOGDOGXv/xlg0n+YFiiN1GhpkbJzS9mVED/fKDYGOG+SRmUllVy15tLwxydMc1zwgknkJeXx3XXXRfU17VEb6LCms3OQqnRfTo0+JhBh7Tj58cexusL1vHhyk1hjM7U5bcu40hyMD+7ZiV6ETlFRFaKyGoRmVbP/VNEpEhEFrhfPw24rzqg/Y0DjtCYZsjJ238gtj6/OO5QDuuawq2vLmZHeVU4QjN1JCUlsWXLFkv2B6G2Hn1SUtIBPa/JefQiEgs8BpwIFALzROQNVV1W56Evquq1+70A7FbVkQcUlTEHKCe/mPZt4unXObnRxyXGxXLfpAzO+ccXPPDOCn535vAwRWhq9erVi8LCQoqKirwOJSLV7jB1IJqzYGossFpV1wCIyAvAmUDdRG+MZ3LyixnVpwMxMU3X6j68b0cuPSKdGV9+zxmZPchK7xT6AM0e8fHxB7Q7kmm55nTd9AQKAo4L3ba6JonIIhGZJSK9A9qTRCRbRL4SkYn1nUBErnIfk21/5c2B2l62/0Kpptx08iB6tG/Dza8soqzSHxUGjQmVYA3Gvgmkq2oG8B4QWIWnrzu380LgYRE5tO6TVfVxVc1S1ay0tLQghWRai4UFJajCqEYGYutKTozjnrNH8G3RTh77cHUIozPGe81J9GuBwCv0Xm7bHqq6RVXL3cMngMMD7lvr/rsG+AgY1YJ4jdlPTl4JIjCyd/MTPcAPB6Zx9qie/P2jb1m+PrgVFI3xk+Yk+nnAABHpJyIJwPnAPrNnRKR7wOEEYLnb3lFEEt3bXYAjsb59E2Q5+cUM7NqOdknxB/zc208fSvs28dz8yiKqbJMSE6WaTPSqWgVcC7yLk8BfUtWlInKXiExwHzZVRJaKyEJgKjDFbR8CZLvtHwL31jNbx5iDVruj1Oi+B3Y1X6tjcgJ3ThjGosJtTP/8++AGZ4xPNKtMsaq+Dbxdp+2OgNu3ALfU87wvgBEtjNGYBq3ZvJNtuysZ1bv5A7F1nZ7RndkL1vLgeys5aVg3+jYxRdOYSGMrY01Ey8l3dpQ62Ct6cCpc3j1xOHExMdzy6mJbyGOijiV6E9Fy84tJTYqjf5eWbRXYvX0bpp06mC++3cLL2YVBis4Yf7BEbyJabn4Jo/p0bNZCqaZcOLYPY/t14vf/Wcam7Y3vAmRMJLFEbyJWaVklKzeWHtD8+cbExAj3nj2Csqoa7phtFS5N9LBEbyLWwoJtqHJAK2Kb0j8thetOGMA7SzfwzpL1QXtdY7xkid5ErJz8YmehVJCu6GtdeXR/hnZP5fbZS9m2qzKor22MFyzRm4iVm1/MgK4ppB7EQqnGxMfGcP85GWzdWcE9by8P6msb4wVL9CYiqSq5BSUtmj/fmOE923Pl0f15MbuAz1dvDsk5jAkXS/QmIq3ZvJOSXZUtmj/flOtOGEC/Lsnc8upidldYhUsTuSzRm4iUk+culAriQGxdSfGx/PHsEeRv3cWf31sZsvMYE2qW6E1Eyi0ooV1SHIemtWyhVFN+0L8zF4ztw5OffcfCgpKQnsuYULFEbyJSTl4xI3s3b0eplrrlx4NJa5fIza8soqLKKlyayGOJ3kScHeVVrNpYGtJum0CpSfH8fuIIVmwo5Z8ffxuWcxoTTJboTcRZWFBCjcLovuFJ9AAnDu3GaRndeeSD1azeVBq28xoTDJboTcTJdStWjuwVuhk39bnzjGG0SYhl2iuLqamxCpcmcliiNxEnJ7+Ew7qm0L5tcBdKNSWtXSK3nz6U7Lxinvs6L6znNqYlLNGbiKKq5OYXMzrIZQ+aa9Lonhw9oAv3/XcFa0t2exKDMQfKEr2JKN9v2UXxrsqwDcTWJSLcc9YIahRufc02KTGRwRK9iSi1C6VGeZToAXp3astNJw/io5VFzF6wzrM4jGkuS/QmouTkF9MuMY4BXUO7UKopl45PZ2TvDvzuzaVs2VHuaSzGNMUSvYkoOfkljOwTnoVSjYmNEe4/J4Md5VXc9dYyT2MxpimW6E3E2FlexcoN2z3ttgk0sFs7rjn2MGYvWMcHKzZ6HY4xDbJEbyLGwkJnoVSwtg4MhmuOO5QBXVO49bUllJbZJiXGnyzRm4iRm+8UFRsdohr0ByMxLpb7zslgw/Yy7n/HKlwaf7JEbyJGTl4xh6Ylh32hVFNG9+nIlPHpPPtVHvO+3+p1OMbsxxK9iQi1O0p5NX++KTeeNIieHdpw8yuLKKu0TUqMv1iiNxEhb8sutu6s8M1AbF3JiXH88ewRrCnayaMfrPY6HGP2YYneRIQct5BZKLcObKljBqZx9uie/OPjb1m2brvX4RizhyV6ExFy8otJSYxjQNd2XofSqNtPG0qHtvHc/MoiqqptkxLjD81K9CJyioisFJHVIjKtnvuniEiRiCxwv35a5/5UESkUkUeDFbhpXXLzS8js3Z5YjxdKNaVjcgJ3ThjG4rXbeOrz77wOxxigGYleRGKBx4BTgaHABSIytJ6HvqiqI92vJ+rcdzfwSYujNa3SrooqVmwI345SLXXaiO6cMKQbf35vFXlbdnodjjHNuqIfC6xW1TWqWgG8AJzZ3BOIyOFAN+B/Bxeiae0WFmyjukYjJtGLCL+fOJz4mBimvWIVLo33mpPoewIFAceFbltdk0RkkYjMEpHeACISAzwI3NjYCUTkKhHJFpHsoqKiZoZuWovagdiRvf07EFvXIe2TmPbjwXy5Zgsvzito+gnGhFCwBmPfBNJVNQN4D5jhtl8DvK2qhY09WVUfV9UsVc1KS0sLUkgmWuTml9C/SzIdkxO8DuWAXDCmD+P6deIPby9n4/Yyr8MxrVhzEv1aoHfAcS+3bQ9V3aKqtbVanwAOd28fAVwrIt8DfwImi8i9LYrYtCq1O0r5df58Y2JihHsnZVBRVcMds5d4HY5pxZqT6OcBA0Skn4gkAOcDbwQ+QES6BxxOAJYDqOpFqtpHVdNxum+eUdX9Zu0Y05D8rbvYsrPC1/PnG9OvSzLXnTCQd5du5L+L13sdjmmlmkz0qloFXAu8i5PAX1LVpSJyl4hMcB82VUSWishCYCowJVQBm9Zlz0KpCLyir3Xl0f0Y1iOV22cvZdsuq3Bpwq9ZffSq+raqDlTVQ1X1D27bHar6hnv7FlUdpqqZqnqcqq6o5zWeVtVrgxu+iXa5+SUkJ8QysJu/F0o1Ji42hvsmZVC8q4Lf/8c2KTHhZytjja/l5BeT2buD7xdKNWV4z/ZcdUx/Xp5fyGffbPY6HNPKWKI3vrWroorl6yNnoVRTfnX8APp1SeaW1xaxq6LK63BMK2KJ3vjW4kJ3oVSEDsTWlRQfy71nj6Bg627+/L9VXodjWhFL9Ma3ctwdpUb6aEeplhrXvzMXjuvDU59/x4KCEq/DMa2EJXrjWzn5xfTrkkynCFso1ZRppw4mrV0iN89aREWVVbg0oWeJ3vjS3oVS0dFtEyg1KZ4/TBzByo2l/OPjb70Ox7QCluiNLxUW72bzjoqoGYit64Sh3Tg9ozuPfrCa1ZtKvQ7HRDlL9MaXahdKReMVfa07JwyjbWIsN7+ymJoaq3BpQscSvfGlnLxi2ibEMiiCF0o1pUtKIrefNpT5ecVM/+J7r8MxUcwSvfGlnPwSMnt1IC42ut+iZ4/uyfGDu3L/OyusC8eETHT/FpmItLuimuXrt0d1t00tEeGPk0bQNiGWG15aSKXtM2tCwBK98Z3Fa7dRFUE7SrVU13ZJ3HPWCBYVbuOxD1d7HY6JQpboje+0hoHYuk4d0Z2zRvXkkQ9Ws6jQFlKZ4LJEb3wnJ6+Y9M5t6ZyS6HUoYXXnhGGkpSRy/YsLKKus9jocE0Us0RtfUVVyC0oickeplmrfJp4Hzs3g26Kd3P/OSq/DMVHEEr3xlcLi3RSVljO6FXXbBDp6QBqTj+jLU59/xxffWjljExyW6I2v7O2fb31X9LWmnTqYfl2SuenlRWwvsx2pTMtZoje+kptfQpv4WAYfEr0LpZrSNiGOB3+Syfptu7n7TduRyrScJXrjK7n5xWT0ah/1C6WaMrpPR6459jBenl/I/5Zu8DocE+Fa92+T8ZWyymqWrtvO6L6tt9sm0NTjBzC0eyq3vLqYzTvKvQ7HRDBL9MY3WttCqaYkxMXw0HkjKS2r4tbXFqNqhc/MwbFEb3wjJ6/1LZRqyqBD2nHjyQN5d+lGXs1Z63U4JkJZoje+kZtfQp9ObenSyhZKNeWKo/ozNr0Td76xlLUlu70Ox0QgS/TGF1SVnPziVjt/vjGxMcKfzs2kRpWbXl5otevNAbNEb3xhbcluNpWW20BsA/p0bsttpw/li2+3MOPL770Ox0QYS/TGF3LynUJeo3pbom/I+WN6c9ygNO797wpWb9rhdTgmgliiN76Qm19MUnwMg7u33oVSTRER7puUQZuEWH790gKqrHa9aSZL9MYXcvJLyOjVgfhWvlCqKV1Tk/jDxBEsLNzG3z761utwTIRo1m+ViJwiIitFZLWITKvn/ikiUiQiC9yvn7rtfUUkx21bKiI/C/Y3YCJfWWU1y9Zts/nzzXRaRnfOHNmDv875hsWF27wOx0SAJhO9iMQCjwGnAkOBC0RkaD0PfVFVR7pfT7ht64EjVHUkMA6YJiI9ghS7iRJL122jslpt/vwBuGvCcDqnJHD9S1a73jStOVf0Y4HVqrpGVSuAF4Azm/PiqlqhqrVrtxObeT7TyuTkOQOxdkXffO3bxvPAOZms3rSDP71rtetN45qTeHsCBQHHhW5bXZNEZJGIzBKR3rWNItJbRBa5r3Gfqq6r+0QRuUpEskUku6io6AC/BRPpcvKL6d2pDWntbKHUgThmYBqX/KAvT37+HV9+u8XrcIyPBesK+00gXVUzgPeAGbV3qGqB234YcKmIdKv7ZFV9XFWzVDUrLS0tSCGZSLB3oZRdzR+MW348mL6d2nLjywsptdr1pgHNSfRrgd4Bx73ctj1UdUtAF80TwOF1X8S9kl8CHH1woZpotH5bGRu3lzOqt/XPHwyndv1Ip3b9W1a73tSvOYl+HjBARPqJSAJwPvBG4ANEpHvA4QRgudveS0TauLc7AkcB1qFo9qjdUcpWxB68w/t25Gc/PJSXsgt5f9lGr8MxPtRkolfVKuBa4F2cBP6Sqi4VkbtEZIL7sKnu9MmFwFRgits+BPjabf8Y+JOqLg72N2EiV05eCUnxMQzpnup1KBHtuhMGMqR7KtNeXcQWq11v6hC/1bjOysrS7Oxsr8MwYTLxsc9JiI3hpZ8d4XUoEW/5+u2c+ejn/GhwV/5+8WhExOuQTBiJyHxVzarvPpvuaDxTXlXNsnXbbf58kAzpnsoNJw3knaUbeH2B1a43e1miN55ZsnY7FdU1jLIZN0Fz5dH9yerbkTtmL2Wd1a43Lkv0xjO5tQOxdkUfNLExwoM/yaS6RrlpltWuNw5L9MYzOfnF9OzQhq6pSV6HElX6dk7mttOG8vnqLTz7VZ7X4RgfsERvPJObX2LTKkPkgrG9OXZQGn/873LWFFnt+tbOEr3xxPptu1m/rcy6bUJERLh/UgZJ8bHc8NJCq13fylmiN56wQmah1zU1ibvPHM6CghL+8bHVrm/NLNEbT+TkF5MYZwulQu2MzB6ckdmDh9//hiVrrXZ9a2WJ3ngiN7+YET3bkxBnb8FQu/vMYXRKTuAGq13fatlvmQm78qpqlqzdbgOxYdKhbQL3n5PBqo07+PN7q7wOx3jAEr0Ju6XrnIVSNhAbPscO6spF4/rwr0/X8PUaq13f2liiN2GXk+cslLIVseH1fz8eQp9Obfn1ywvZUV7ldTgmjCzRm7DLLSihZ4c2dLOFUmGVnBjHg+dmsq5kN7+32vWtiiV6E3a5ecVWyMwjWemduPqHh/LCvAI+WGG161sLS/QmrDZsK2PdtjKbP++h604YwOBD2vGbWYvZurPC63BMGFiiN2FVW8jMrui9kxgXy0PnjWTb7gpue30xftuTwgSfJXoTVjn5xSTExTCsR3uvQ2nVhnRP5foTB/L24g28sXCd1+GYELNEb8IqJ7/EFkr5xNXHHMrhfTty++tLWL/NatdHM/ttM2FTUVXD4rXbbP68T8TGCA+em0lltfKbWYusC8cj1TXK9rJK1pXsZm2INouJC8mrGlOPZeu3U1FlO0r5SXqXZG49bQi3vb6E577K45Ij0r0OyfdUlfKqGnaUV7GzvMr9t5qd5VWUum1726vY4d63I6AtsH13QFmKUX068No1RwY9Zkv0JmxqF0rZjBt/uWhcH/63bCN/eHs5Rw1Io1+XZK9DCrrqGmVnxd4kW1rmJOc9ibciIDGX7U3Cge07y6spLatkZ0U11c3cuatNfCzJiXGkJNb+G8chqUkkJ8bt156SGMch7UOztsQSvQmbnPxierRPCtmb2Ryc2tr1Jz/8Cb9+aQEvXX0EcbGR26u7o7yKT1cV8f7yTXz57WaKd1Xuc9XcmNgYITkhlhQ3Edcm4W7tkvZJzIHJOXnPv3ufl5IUR3JCHLExEuLvtnks0Zuwyc0vsW4bnzqkfRJ3TxzO1Jm5/POTNfziuMO8DumAFGzdxZzlG5mzYhNfrdlCZbWSmhTH0QPT6J6aFJCMnSSckhhLckLcPu3tkuJIjItBxB/JOZgs0Zuw2Li9jLUlu7nsyHSvQzENmJDZg/8t3cDD76/i2EFpvp4CW12jLCgo5v3lm5izfCOrNjrbJfZPS2bK+HSOH9KNrL4dI/qTSTBZojdhUbtQykoT+9vdZw5n7ndbueHFhbzxyyNJjIv1OqQ9Sssq+fSbzby/fCMfrSxi684KYmOEMekdue20IRw/pFtUji8EgyV6ExY5+SUkxMYwrIftKOVnHZMTuO+cDC6bPo8/v7eKW04d4mk8BVt38f7yjXwQ0CXTvk08xw5K4/gh3fjhwDTat4n3NMZIYInehEVOXjHDeqb66grR1O+4QV25YGwfHv9kDScM6caY9E5hO3d1jZKbX8ycFft2yRyalsxlR/bj+MFdOdy6ZA6YJXoTcrULpS7+QV+vQzHNdNtpQ/h89WZueGkB//3VMaQkhi5VlJZV8smqzcxZsbdLJi5GGJPeidtO680JQ7qRbl0yLdKs/z0ROQX4CxALPKGq99a5fwrwALDWbXpUVZ8QkZHA34FUoBr4g6q+GKTYTYRYvn475VU1Nn8+giQnxvHgTzL5yT+/5A//Wc4fzx4R1NfP37KLOSs2Mmf5Jr7+bm+XzHFul8wx1iUTVE0mehGJBR4DTgQKgXki8oaq1t254EVVvbZO2y5gsqp+IyI9gPki8q6qlgQjeBMZcvYMxFrpg0gyJr0TVx3Tn39+vIaThnXjuEFdD/q1qmuUnPxi5rizZL7ZtLdL5vIj+3H8kG6M7tPBumRCpDlX9GOB1aq6BkBEXgDOBJrcokZVVwXcXicim4A0wBJ9K5KTX8IhqUl0b9/G61DMAbrhxIF8tKKIm2ct4t3rjqFjckKzn7u9rJJPV21mzvKNfLhyE8W7KomLEcb268T5Y/tw/OCu1iUTJs1J9D2BgoDjQmBcPY+bJCLHAKuA61U18DmIyFggAfi27hNF5CrgKoA+ffo0L3ITMXLzi+1qPkIlxsXy5/MymfjY59w+ewmPXji60cfnb3FmycxZsZGv12ylqkbp0Dae4wZ15fghXTlmYBqpSdYlE27BGmF5E5ipquUicjUwA/hR7Z0i0h14FrhUVWvqPllVHwceB8jKyrISelFkU2kZhcW7mTI+3etQzEEa1qM9150wkAfeXclJw9YxIbPHnvtqu2TeX+70t692u2QO65rCFUf344Qh3RjV27pkvNacRL8W6B1w3Iu9g64AqOqWgMMngPtrD0QkFfgPcKuqfnXwoZpIlJPn9NJZ6YPIdvUx/ZmzfCO3v76Eod3bsWJDKXOWb+LDlZsocbtkxvXvxIVj+3D8kK707WxdMn7SnEQ/DxggIv1wEvz5wIWBDxCR7qq63j2cACx32xOA14BnVHVW0KI2ESM3v5j4WLGFUhEuLjaGB38ykh//5VNO+PMnAHRsG8+PBnXl+CHdOHpgF+uS8bEmE72qVonItcC7ONMrn1LVpSJyF5Ctqm8AU0VkAlAFbAWmuE//CXAM0NmdggkwRVUXBPfbMH6Vm1/CsB7tSYq3hVKRrl+XZB65YBQ5+cUcN7gro/t09E11RtM48duuMllZWZqdne11GCYIKqtrGHHnu1w4ti93nDHU63CMiWoiMl9Vs+q7z0ZITMgsX7+dssoaRtnWgcZ4yhK9CZk9O0pZxUpjPGWJ3oRMbkEJ3VIT6WE7ShnjKUv0JmRy8osZ3adjVO7YY0wksURvQqKotJyCrbutf94YH7BEb0Jiz45StlDKGM9ZojchkZNfQnysMLynf/cdNaa1sERvQiInv5ihtlDKGF+wRG+CrrK6hkWFJYzqbf3zxviBJXoTdCs3lFJWWWPz543xCUv0Juj27ChlM26M8QVL9CbocvKK6doukZ4dbEcpY/zAEr0Jupz8Ekb16WALpYzxCUv0Jqg27ygnf+sumz9vjI9YovfIpu1lLC7c5nUYQZeb7+woZQOxxviHJXoPbCot46y/fcHEv33OBys2eh1OUOXkFxMXI4ywhVLG+IYl+jDbWV7F5U/PY+vOCg5LS+Gaf+fsmaUSDXLyihnaI9UWShnjI5bow6iquoZrn89h2brtPHbRKP595TgOSU3i8qfnsXpTqdfhtVhVdQ2LCrdZ/7wxPmOJPkxUldtnL+XDlUX8fuIIfjS4G11SEnnm8nHExcQw+cm5rN+22+swW2TFhlJ2V1ZbxUpjfMYSfZj87aNvmTk3n2uOPZQLx/XZ096nc1tmXD6G7WVVXPrUXLbtqvQwypaxipXG+JMl+jB4LbeQB95dycSRPbjp5EH73T+sR3sen3w432/exRUz5lFWWe1BlC2Xk19Cl5REenW0hVLG+Ikl+hD7YvVmfjNrEdp7TmAAACAASURBVEf078z952Q2uIho/KFdePj8kczPL+ba53Opqq4Jc6Qtl5tfzGhbKGWM71iiD6GVG0q5+tn59OuSzD8uOZyEuMZ/3D8e0Z27Jgzj/eUbufW1JahqmCJtuS07yvl+yy6bP2+MD8V5HUC02rCtjCnT59I2MZanLxtL+zbxzXreJUekU1Razl8/WE1au0RurKerx49qF0pZaWJj/McSfQiUllUyZfpctu+u5KWfHUGPAyzudf2JAynaUc6jH66mS0oCU47sF6JIg6d2oVRGL0v0xviNJfogq6yu4Zp/57B60w6emjKGYT0OfIWoiHD3mcPZsqOC3721jC7tEjk9o0cIog2e3PwShnRPpU2CLZQyxm+sjz6IVJVpryzm028288ezR3DMwLSDfq242Bj+esEoxvTtxPUvLuDz1ZuDGGlwVVXXsLCwxOrPG+NTluiD6OH3v+GVnEKuO2EA52b1bvHrJcXH8q/JWfTvksLVz85nyVp/FkFbubGUXRXVjLL588b4UrMSvYicIiIrRWS1iEyr5/4pIlIkIgvcr58G3PeOiJSIyFvBDNxvXppXwF/mfMO5h/fiV8cPCNrrtm8bz4zLncHcKdPnkrdlZ9BeO1j2VKy0RG+MLzWZ6EUkFngMOBUYClwgIkPreeiLqjrS/XoioP0B4JKgROtTH68q4pbXFnP0gC7cc/aIoM8jP6R9EjMuH0t1jXLJk3MpKi0P6uu3VE5+MV1SEujdyRZKGeNHzbmiHwusVtU1qloBvACc2dwTqOocIPIrdjVgydptXPPcfAZ2a8ffLhpNfGxoesMO65rCU1PGUFRazpTpcykt80+phNz8Ekb16WgLpYzxqeZkpZ5AQcBxodtW1yQRWSQis0TkgDqoReQqEckWkeyioqIDeaqn1pbs5vKn59G+TTxPXzaGdknNmyt/sEb16cjfLh7Nyg2l/Oy5+ZRXeV8qYevOCr7bvNMKmRnjY8G6/HwTSFfVDOA9YMaBPFlVH1fVLFXNSks7+Jkq4bRtVyVTnprL7spqnr58LN1Sk8Jy3uMGdeW+SRl8vnoLN7y0kJoab1fPLiiwQmbG+F1z5tGvBQKv0Hu5bXuo6paAwyeA+1semn+VV1Vz9XPZfL9lJzMuH8vAbu3Cev5Jh/diy85y7nl7BV2SE7hzwjDPuk1y8kqIjREyetmOUsb4VXMS/TxggIj0w0nw5wMXBj5ARLqr6nr3cAKwPKhR+khNjfKbWYv4as1WHj5vJOMP7eJJHFcdcyhFpeX869Pv6JqaxC+OO8yTOHLyixl8SDvaJtjaO2P8qsnfTlWtEpFrgXeBWOApVV0qIncB2ar6BjBVRCYAVcBWYErt80XkU2AwkCIihcAVqvpu8L+V8HjgfyuZvWAdN508iImj6huqCJ9bTh3C5h0VPPDuSrqkJHDemD5NPymIqmuUhQUlnD26V1jPa4w5MM26DFPVt4G367TdEXD7FuCWBp57dEsC9JPnvsrj7x99y4Xj+nDNsYd6HQ4xMcL952SwZWcFt7y6mE7JiZw4tFvYzr9qYyk7K6oZ3dcGYo3xM1sZ20zvL9vIHbOXcPzgrtzlYZ94XfGxMfz9otGM6Nmea5/PIfv7rWE7d47tKGVMRLBE3wwLC0r45cxchvVozyMXjiIuRHPlD1ZyYhxPTRlDzw5tuPzpeazaGJ5lCzl5JXRKTqBPp7ZhOZ8x5uD4K2P5UP4WZ3u/zikJPDkly7eDjp1TEplx+ViS4mOZ/ORc1paEfqNx21HKmMhgib4RxTsrmDJ9LpXVytOXjaVru/DMlT9YvTu1ZcblY9lZ4Ww0XryzImTnKt5ZwZrNO62QmTERwBJ9A8oqq7nymWwKS3bzxKVZHNY1xeuQmmVI91SemJxF/tZdXD5jHrsqqkJyngUFVsjMmEhhib4eNTXKDS8tYH5+MQ/9ZCRj0jt5HdIBGde/M389fyQLC0q49vlcKkOw0XhOfjExgi2UMiYCWKKvxx/eXs7bizdw64+HcFpGd6/DOSinDO/O3ROH88GKTUx7ZXHQNxp3FkqlkpzozzELY8xe9ltax1OffceTn33HlPHpXHGU//dqbcxF4/qyubSCh95fRVq7RKadOjgor+sslNrGxFH+3t7QGOOwRB/gnSXrufs/yzh5WDduP31oVMwmmXr8YRTtKOMfH39LWrvEoPzx+mZTKTvKq6x/3pgIYYneNT9vK796YQEje3fgL+ePIjYm8pM8OBuN/26Cs9H43W8to0tKAmeObFnphpw8ZyDWZtwYExmsjx5YU7SDn87Ipnv7JJ6YnEVSfKzXIQVVbIzw0HkjGdevEze+vJBPVrWs5n9OfjGdkhNI72wLpYyJBK0+0W/eUc6U6fMQEZ6+bCydUxK9DikkkuJj+delWRzWtR0/e24+C93pkQcjN7+YUb1toZQxkaJVJ/pdFVVcMSObTaVlPHFpFuldkr0OKaRSk+KZcdkYOiUncNnT8/hu84FvNF6yq4Jvi3Yyuq912xgTKVptoq+uUabOXMCiwhL+cv6oVjOw2DU1iWevGIcAk5/6mk3byw7o+bnuJ4FRva1ipTGRolUmelXld28u5f3lG7nzjGGcPOwQr0MKq35dkpl+2Ri27Kjg0unz2H4AG43n5jkLpTIt0RsTMVplon/8kzU882UeVx3Tn0vHp3sdjicyenXgHxcfzjcbS7nqmWzKKpu30XhuQQmDbKGUMRGl1SX6Nxau44//XcFpGd2ZdkpwFhBFqmMGpvHgTzL5as1Wrn9xAdVNbDReU6MsyC9hVB+7mjcmkrSqRP/Vmi3c+NJCxqZ34sFzM4mJkrnyLXHmyJ7cfvpQ/rtkA799Y0mjpRK+2bSDUlsoZUzEaTWfv2u7KHp3asPjkw+PurnyLXHFUf0oKi3nHx9/S9d2SUw9fkC9j8vds6OUXdEbE0laRaLftL2MKdPnkRAXy9OXjaVD2wSvQ/Kdm08ZRFFpOX9+bxVdUhK5cNz+G43n5BfToW08/aJ8Gqox0SbqE/3O8iounzGPrTsreOnqI+ht297VS0S4d9IItu4s57bXF9MpOYFThu87Gyknv8QWShkTgaK6j76quoZfPJ/DsnXbeeyiUYyw2umNio+N4bGLRpPZuwNTX8jl6zVb9ty3bVclqzftsP55YyJQ1CZ6VeW215fw0coifj9xBD8a3M3rkCJC24Q4nrp0DL07tuGnz2SzYsN2ABYUujtK2YpYYyJO1Cb6Rz9YzQvzCvjFcYfW299sGtYxOYFnrhhHckIck5+cS8HWXeTkFSO2UMqYiBSVif6V+YU8+N4qzhrVkxtPGuR1OBGpZ4c2PHPFWMoqq7n0qbl8vKqIQd3akWILpYyJOFGX6D9fvZmbX1nEEf07c9+kDBs4bIGB3drx5JQxrC3ZzYKCEqs/b0yEiqpEv2LDdn727Hz6pyXzj0sOJyEuqr49T4xJ78SjF44mLkY46rAuXodjjDkIUfM5fMO2MqY8NY+2ic5c+fZt4r0OKWqcOLQbOXecSDvrtjEmIjXrkldEThGRlSKyWkSm1XP/FBEpEpEF7tdPA+67VES+cb8uDWbwgVKS4hjdtwPTp4ylR4c2oTpNq5WaFG/dYMZEqCYv0UQkFngMOBEoBOaJyBuquqzOQ19U1WvrPLcT8FsgC1Bgvvvc4qBEHyAlMY6/XXR4sF/WGGMiXnOu6McCq1V1japWAC8AZzbz9U8G3lPVrW5yfw845eBCNcYYczCak+h7AgUBx4VuW12TRGSRiMwSkd4H+FxjjDEhEqxpKW8C6aqagXPVPuNAniwiV4lItohkFxUVBSkkY4wx0LxEvxboHXDcy23bQ1W3qGq5e/gEcHhzn+s+/3FVzVLVrLS0tObGbowxphmak+jnAQNEpJ+IJADnA28EPkBEugccTgCWu7ffBU4SkY4i0hE4yW0zxhgTJk3OulHVKhG5FidBxwJPqepSEbkLyFbVN4CpIjIBqAK2AlPc524Vkbtx/lgA3KWqW0PwfRhjjGmANLZ1nBeysrI0Ozvb6zCMMSaiiMh8Vc2q7z6rEWCMMVHOd1f0IlIE5LXgJboAm4MUTqhFUqwQWfFGUqwQWfFGUqwQWfG2JNa+qlrvbBbfJfqWEpHshj6++E0kxQqRFW8kxQqRFW8kxQqRFW+oYrWuG2OMiXKW6I0xJspFY6J/3OsADkAkxQqRFW8kxQqRFW8kxQqRFW9IYo26PnpjjDH7isYremOMMQEs0RtjTJSzRG+MMVHONgE1+xGRGxq7X1X/HK5YDoSIZADpBLyvVfVVzwIyYSUib+LsZFcvVZ0QxnCaRUQ6AJPZ/307NZjniYpELyLdgDHu4VxV3eRlPI0RkfuB3wO7gXeADOB6VX3O08D21c7rAA6UiDyF87NcCtS4zQr4NtGLyHzgKeD5UGyv2Qr9yesADsLbwFfAYva+b4Mu4mfdiMhPgAeAjwABjgZuUtVZXsbVEBFZoKojReQs4HTgBuATVc30OLSIJiLLVHWo13EcCBE5DLgMOA/IBqYD/1Mf/VKKSCn1XyULoKqaGuaQooqI5Kjq6JCfx0fvqYMiIguBE2uv4kUkDXjfr4lTRJao6nAReQKYparviMhCP8YrIknAFcAwIKm2XVUv9yyoBojIk8CD9Wxa73siEoPzR//vQDVOwv+LlfQ+OCIyAPgjMJR937f9PQuqASJyPbADeAuo3byJYP/fR8NgbEydrpot+Pv7ektEVuDswjXH/cNU5nFMDXkWOARnk/ePcXYIK/U0ooY9A3wpIivdvYsXi8gir4Nqijuu8CDOp9JXgHOB7cAHXsbVEBHpKiJ9ar+8jqcB03H+aFYBx+G8N/zUNRqoAuf//ktgvvsV9Drt0XBF/wBO3+xMt+k8YJGq3uxdVI0TkU7ANlWtFpFkoJ2qbvA6rrpEJFdVR4nIIlXNEJF44FNV/YHXsdUlIqtxusH26etU1ZZUQg0pt4++BHgSeCVgO05E5FVVPduz4OpwNxZ6EOgBbAL6AstVdZingdXDrct+uIgsVtURgW1ex1aXiKwBxqpqSKtrRvRgrIgI8Fecgdij3ObHVfU176JqnIi0Ba4B+gBX4fziDML56OY3le6/JSIyHNgAdPUwnsYUubudRZJzVXVNYIOI9FPV7/yU5F13Az/A6RYdJSLHARd7HFNDyt3usG/c3fHWAikex9SQ1cCuUJ8kohO9qqqIvO3+1fbt7Io6puN8PBvvHq8FXsafif5xd6/f23H2CU4B7vA2pAblisjzwJvs29fp5/fFLKDuQNwsnG49v6lU1S0iEiMiMar6oYg87HVQDfgV0BaYivMH6kfApZ5G1LCdwAIR+ZB937c2vbKOHBEZo6rzmn6oLxyqqueJyAUAqrrL/WTiO6r6hHvzY8B3A1l1tMH5RTkpoM2X0ytFZDDOAHd7EQm8ck8lYPDQZ0pEJAX4BPi3iGzCSVK+E5ALduDMavKz192vkIqGRD8OuFhEvsd549VO+8rwNKqGVYhIG9wpayJyKAF/yf0kXIs5WkpEYoEtqnqj17E00yCcWTYdgDMC2kuBKz2JqGln4kwauB64CGgP3OVpRA0QkSzgVpxxhMD3ra9ygvu+naKqx4X6XNGQ6E/2OoAD9FuchVK9ReTfwJHAFE8jalhYFnO0lDuofaTXcTSXqs4GZovIEar6pdfxNIeqBl69z/AskOb5N3ATkfG+rRGR9qq6LZTnivhZNwAichQwQFWnu9MVU1T1O6/jaoiIdMYZ2BLgq1CPuB+scC3mCAYR+TvQE2e8Y09S8mMfvYj8RlXvF5FHqGcxkt8+MQG4XUz34QzGCz5eMCUin6nqUU0/0nsiMhsYBbzHvu9b66MPJCK/BbJwPg5PB+Jx5sz6+QovCSjG+fkPFRFU9ROPY6rPsyJyJSFezBEkSThrKH4U0ObLPnpguftv0OdLh9D9wBmqurzJR3rvt+6CxDn4f2D+VcLwHo34RA+chfMXMQdAVdeJiG9rtYjIfThz/evWZPFjoq9dzHEre688FR8OzKqq3wfd9lDVN92bu1T15cD7RORcD0Jqjo0RkuTBGYAdjHPR5+u6R6o6Q0QSgIFu00pVrWzsOQcjGhJ9hTvNsnZwM9nrgJowERgUuDjGx34NHObXrqVAItILeIS9n+Q+BX6lqoXeRdWkW3C6mppq84NsEXkRZ4aI36+Sx6jqIK+DaA4RORZnzON7nO6w3iJyabA/4UdDon9JRP4JdHC7GS4H/uVxTI1Zg3OlEQmJPiyLOYJkOvA8TgkBcBbzTAdO9CyiBojIqcCPgZ4i8teAu1Jxlu37USrOe8H301eBL0RkaITUPXoQOElVVwKIyECcVf5BXUsRsYleRE5W1XdV9U8iciJOfZBBOAt6OngbXaN24SyQqNt/6LsBOMK0mCNI0lR1esDx0yJynWfRNG4dTv/8BJzFc7VKcaYv+k4kdY3hTHRYICLf4bxv/TzlOr42yQOo6iq31EhQReysGxGpxunXvlhV19a5z7ezRUTk5zh/YBXn6m03OH11XsZVHxGpdzWhT2Odg3MFX1vz6ALgMlU93ruoGici8aHojw2FSOkacxcfHg3sV+PIj3WP3H0UathbdO0iIDbYFWIjOdHnAn/DuYK/PrD+fG0xLs+Cq4eIxAH34HQt5eFcZfTBSU7/57dfeHcxx/vhWMwRDCLSFycRHYHzR/QLYKqq5nsaWCPcuf93sndhT+2Vp+8Gu0XkPZyusWfdpouBi1TVj11je4qZ+Z2IJAK/YG+trk+BvwV7DC9iu25wfiH+JSIf4yzJPg34haruopHtxDz0AM7OTf1UtRRARFJxdsV5APBVN0M4F3O0hIjc51YqHas+3CquCU/idNXMx6lD72eR1DXm+7IoIjLH/bR5l/v+Den2nJGc6IE9fVpH4GzPlysik72OqQGnAwM14COUqm53u3JW4LNE79oBLHav5kK2mKOFfiwi0/DvbJXGbFPV/3odRDNtEZGL2bdrbIuH8TRmHHCRiOTh37Io3UVkPDBBRF7AiXEPVc0J5skiOdHv+cGoahUwTUTewXkjpnkWVcM0MMkHNFbXTg31obAs5mihd3AWn6WIyHbcX2rw78rNAB+6+ym8yr6D3UH9JQ+Sy3G6xh5ib9eYXwdoI6Esyh04VWF7sf/VvLLvwr8Wi+Q++omqul/VN7es7tWqeq8HYTVIRF4HXlXVZ+q0Xwz8xK/dDuFYzBEMIjJbVc/0Oo4D4c5mqktVNai/5K2RiGTiDMqCs1nOQi/jaYiI3K6qd4f8PJGa6CONiPTEuXLbzd4pdVk45XXPqjtzyA/qW8wBBH0xh/G/OvP9a20Dst0ibb4hIr/CqQJa+2n0LJwNiR7xLqp9ichgVV0hIvXODgz2pzpL9GEmIj/CqUUOsExV53gZT2PE2eruwrqLOdRHW7LVFrASkVICumyIgK4bEemGMxOrh6qeKiJDgSNU9UmPQ9uPiDyOU1agdhxkEvAd0BlYo6q+GWMSZ6/gI2orbrqr5b/0Ux+9iDyuqleF61OdJXrTIHH3im2qzRwcEfkvzvTaW1U1052Cm+vHqYEi8hVwpKpWu8dxOFMBjwIWq+pQL+MLJCKLccoglLnHScA8P/5cwyWSB2NN6GW7VQADF3P4tuKiO/e/G/tuNuHbefRAF1V9SURuAWdSgbsQ0I864mwlWTvVNhno5E4m8Fs5j+nA1yJSu3f0RJyprL7kzr5JZ9/37TMNPuEgWKI3jfk5zmKO2umUn+IsUvMdEfklzqYuG9m3YqGfP33sdPcmqC3I9wP2JlK/uR+nrMBHON1ixwD3uN0i73sZWF2q+md3fU3tKt7LVDXXy5gaIiLPAocCC9i7lkKBoCZ667oxUUFEVgPjVNWvc7v34w7EPQIMB5bgTAs+R1UXeRpYA0SkOzDWPZynquu8jCcaiMhyYGh9U6+Dya7ozX7cAaKG3njq0/oxBfj3arheqpojIj/EKcYn+Hj6qmsMe6cs1uAUZ/ONgAF52DsoD06eS1BVP+a7JcAhwPpQnsSP37jxXn2bbP8A+A2wKcyxNNca4CMR+Q/7Lj4K6dLygyHOtnz1GejuNua7RWoici9Oov+32zRVnD1v/8/DsPahqvtsOCQiKThdj1cDr9X7JO91AZaJyFz2fd8GdV2NJXqzH1XdUzrXveK8HWervp/5eMl+vvuV4H752Rnuv12B8cAH7vFxOCtOfZfocernj1TVGgARmQHkAr5J9LVEpANOSZHJOIXYxvi4S+/OcJzEEr2pl4icDNyGc5XxB1Wtb76vb6jq77yOoblqa7uLyP9w+mfXu8fdgac9DK0pHYDa/YLbexlIfUSkC86uaOcBTwGj/FyQD0BVPw7HeSzRm/2IyDycgcEHgC/dtj0r+PxUi0VE3mTf8QQFNgMfqupz9T/LN3rXJnnXRpzS1X70R5yigR+yd9bNNG9D2k8eUIQzvXIXcIVTnt7hp268OuMJEPC+BW4O9icQm3Vj9uNOoQvcDDywsp6varG4XUt1dcKpl/6NqvotGe0hIo8CA9hbEfI8YLWq/tK7qBrmfuIY4x7OVdUNXsZTl4jcSSMlyv3+qc+t0zUFGK+qQd0k3hK9iUru4qn5qjrS61ga4w7M1s5k+URV/TpoWFuvqXaTFACs7lHwhWKHPOu6MVHJXbHpdRhNcmfY+HHwdR8ich/OJ46l7LsgzRJ9EImzX2zQ87IlehPRRKRTPc0dcWZcLA1zOM1ST//snrvwbyG2icAgDfIWd61VA1NsO+L8MZ1Vz30tYoneRLr57DuOUDuo9RFOCQffqTvfO0KsAeIJmOvtVyLST1W/a6rNY2fUOVacHbv+oqr/CfbJrI/eNEpEMti/4JLvuxpMcIjIIzhJqCeQCcxh34U9ftpWEqi/j1tE5vupvHa42RW9aZCIPIVTFKxuv6wl+tajtlrpfOCNOvf56ipRRAbj7PXQvk7XSCrOgr9WyxK9acwP/FRn3ISfqs4AZ9cmVf1L4H3uTk5+Mgg4HWdhV2DXSCnOjlOtlnXdmAaJyJPAg6q6zOtYjLca6A7JVdVRXsXUELcGz5dex9Ec4RpPsCt605hngC9FZANOv2ztrBBf1ni38YTgE5ELgAuB/iIS2HXTjr3lEPymwN10pLYe/afAr1S10MOYGvIKUHfO/CwgqOMJluhNY54ELgEWs7eP3pdsPCFkvsApodsFeDCgvRTwZd18nBIIzwO1q0svdttO9CyiOsI9nmCJ3jSmSFXrDsD5lY0nhICq5olIIVAWrgJcQdBVVacHHD8tIr7ZvNwV1vEES/SmMbki8jzwJvtOqfPjVfKXIjLUxhOCz11lXCMi7f1eDdK1WUQuZm8NoQtw5qj7hqrOBmaHazzBEr1pTBucBH9SQJtfu0MiajwhAu0AFovIe8DO2kY/zqMHLsfZovEhnPfrF8BlnkbUsLCMJ9isGxMV3D1jb6DOeIKq5nkWVBQRkZ/jXBgqUAXshr3TL/3CLWb3jKpe5HUszeH+4XweeNZtuhi4SFWDOp5gid40SER64VwZ+X72goh8qapHeB1HtBGROOAenKvkPJxPSn1wBjf/z4973IrIZ8CPVLXC61iaIiILVTWzTtuCYFddta4b0xjfz14IEEnjCZHkAZyplP1UtRRARFKBP7n3+W2QE5y6PJ+700EDu5l8s/FIgLCMJ9gVvWlQfVcWobjaCAYRmV5Ps6rq5WEPJoqIyDfAQK2TKNwukhWqOsCbyBomIr+tr92PG4+ISF+cT81HsHc8Yaqq5gfzPHZFbxqzxe+zF2rV7sNqgk7rJnm3sVpEfHmVWJvQRSTFPd7hbUT1c/9Y3qOqE0J9rphQn8BEtMuBnwAbcBbNnINPZy+ISC8ReU1ENrlfr7hjDKZllonI5LqN7gXACg/iaZKIDBeRXJzFc0tFZL6IDPM6rrpUtRroKyIJoT6Xdd2YqBCu2Qutjbt94Ks4s2zmu81ZOFNvz1LVtV7F1hAR+QK4VVU/dI+PxblyHu9pYPUQkWeAITiVQUM2nmCJ3uwnoAZ5vfw4dzqSxhMikYj8CGfJPsAyVZ3jZTyNaWAmy35tfhCu8QTrozf1qa1BfiQwFHjRPT4X8OvK04gZT4hEqvoB8IHXcTTTGhG5nX0/3a3xMJ4GhWs8wa7oTYNE5CvgKFWtco/jgU9V9QfeRra/cM1eMP4nIh2B3wFHuU2fAneqarF3UdVPRIbj/EGq3ft4MzBZVYO637EletMgEVkJHKGqW93jjsBXqjrI28iMiQ7hGk+wrhvTmHtxFiJ9iLMi8hjgTk8jqiMSxxNMaIjImzT+Xgj5NMaDkFyb5AFU9SMRSQ72SSzRmwap6nQR+S8wzm26WVU3eBlTPSJxPMGExp+8DuAghGU8wbpuTKPc6XV92XfXpk+8i6h+kTSeYEytcI0n2BW9aZCI3Aecx/67Nvku0QMdcXbnqd3eLsVtM62EiJwJ9FLVx9zjr4E09+7fqOosz4JrgJvQQ969aIneNGYiMEhVy5t8pPd8P55gQu43wPkBx4nAGCAZpxifbxJ9uMcTLNGbxqwB4gmoBulXETKeYEIrQVULAo4/U9UtOGssgj7A2UJhHU+wPnrTIBF5BcgE5rBv6V9fzmSJlPEEExoislpVD2vgvm9V9dBwx+QXdkVvGvOG++V7ETaeYELjaxG5UlX/FdgoIlcDcz2KqV7hHk+wK3oTFdzFXRkRMp5gQkBEugKv43z6zHGbD8fpq5+oqhu9iq0uEfkcOL+2q0lEFgDH444nqOrxwTyfXdGbBonIAOCPOPPTk2rbVbW/Z0E1LGLGE0xoqOomYHydAmz/cev0+E1YxxMs0ZvGTAd+CzwEHIdTi96vexjsAhaISESMJ5jQiZACbPtM/VXVawMO0wgyS/SmMW1UdY6IiKrmAXeKyHzgDq8Dq0fEjCcYQ5jHEyzRm8aUi0gM8I2IuQv9YgAABThJREFUXAusxVmI5DuqOsPrGIw5ANcDr4vIhdQznhDsk9lgrGmQiIwBlgMdgLuB9sB9qvq1p4HVI8LGE4wB9tvQZWmoxhMs0ZtmczczPl9V/+11LHWJyGfsHU84A3c8QVX92M1kTFj5dWDNeEhEUkXkFhF5VEROEse1wGqczcL9qI27vZ2oap6q3gmc5nFMxviC9dGb+jwLFANfAj8F/g+nfsxZqrrAy8AaETHjCcaEm3XdmP2IyGJVHeHejgXWA31UtczbyBoWSeMJxoSbXdGb+lTW3lDVahEp9HOSB1DVee7NHcBlteMJgCV60+rZFb3Zj4hUAztrD4E2OAuSBFBVTfUqtrpEJBX4BdATZx79e+7xr4FFqnqmh+EZ4wuW6E1EE5HZ7B1POB7oivMH6Vc+Hk8wJqws0ZuIFonjCcaEm02vNJFun/EEwPfjCcaEm13Rm4gWSeMJxnjFEr0xxkQ567oxxpgoZ4neGGOinCV6Y4yJcpbojTEmylmiN74nIk+IyNAmHvO0iJxTT3u6u7lDY8/NEpG/NiOOL5r7mi0lIhMDv2cR+UhEslrwei16volsluiN76nqT1V12UE+PR1oNCmranZz9pZV1fHNfc0gmIiziYoxLWaJ3oSNiNwkIlPd2w+JyAfu7R+JyL/d2vdfikiOiLwsIinu/XuuRkXkChFZJSJzReRfIvJowCmOEZEvRGRNwNX9vcDRIrJARK5vIK5jReQt9/adIvKUe841tfG69+04gNecIiKvi8h7IvK9iFwrIjeISK6IfCUindzHHSoi74jIfBH5VEQGi8h4YALwgHuOQ92XPdf9vleJyNHu85NEZLqILHZf+zi3vY2IvCAiy0XkNZz1BaaVskRvwulT4Gj3dhaQIiLxbtsi4DbgBFUdDWQDNwQ+WUR6ALcDPwCOBAbXef3uwFHA6TjJGGAa8KmqjlTVh5oZ52DgZGAs8Fs3xkDNfc3hwNnAGOAPwC5VHYVTl2ey+5jHgV+q6uHAjcDfVPULnAJtN7nn+NZ9bJyqjgWuw9lNC5wCbuqWgbgAmCEiScDP3fMNcR97eDO/dxOFrEyxCaf5wOFuxclynE2Rs3AS/Rs4XRWfiwhAAk5CDDQW+FhVtwKIyMvAwID7X1fVGmCZiHRrQZz/UdVynM1MNgHdgMKDeJ0PVbUUKBWRbcCbbvtiIMP9xDIeeNn9nsHZHLohr7r/zsfpPgLnD9sjAKq6QkTycH4mxwB/ddsXiciig4jfRAlL9CZsVLVSRL4DpgBf4FzFHwccBnwHvKeqF7TgFOUBt6XBRx3Y61Rz8L8nga9TE3Bc475mDFCiqiMP8PVaEpNphazrxoTbpzhdFJ+4t38G5AJfAUeKyGEAIpIsIgPrPHce8EMR6SgiccCkZpyvFGgXrOCD+Zqquh34TkTOBXD35s08wHN8ClzkPn8g0AdYifPzvdBtHw5ktDReE7ks0Ztw+xSnL/1LVd0IlOH0dxfhXOnPdLsZvqROH7yqrgXugf9v745RGgqCOIx/f2tv4WGsrW0Ez2Avdl4gdqmTKl7CxsokimW8gmAbxuK9NIEgSCAvm+9XLuzsVsMwA7u8Ai/AF/D9x3kLYJ1kvmtw+g/7jHkN3CaZAx/A5qOUCXDXD1gvdu6GEXCWZAlMgZu+7fRENwP5BB7o2j06UT5qpqOS5LyqfvqKfgaMq2p26HtJQ2ZFr2Nzn+QNeKfr6z8f+D7S4FnR62QkuQQet5ZXVXU1pJjSvpnoJalxtm4kqXEmeklqnIlekhpnopekxv0C2dhotiwcEosAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O37chbRgZDXF",
        "colab_type": "code",
        "outputId": "b81772c1-156f-427c-8c9d-88da243d211b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classified = []\n",
        "\n",
        "for prediction in tqdm(predictions):\n",
        "    classified.append([1 if i==j else 0 for i,j in zip(prediction,y_test)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 8/8 [00:00<00:00, 230.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMfc-h8xAYQu"
      },
      "source": [
        "## Correlation between models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAky42lMV102",
        "outputId": "4e51efb0-e2fc-4e5e-a67c-2f6b09f1829f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "correlation_matrix = []\n",
        "\n",
        "for ix, x in enumerate(classified):\n",
        "  row = []\n",
        "  \n",
        "  for iy, y in enumerate(classified):\n",
        "    if (ix == iy):\n",
        "      row.append(np.nan)\n",
        "    else:\n",
        "      row.append(pearsonr(x,y)[0])\n",
        "\n",
        "  correlation_matrix.append(row)\n",
        "\n",
        "correlation_matrix = np.array(correlation_matrix)\n",
        "correlation_matrix_df = pd.DataFrame(correlation_matrix)\n",
        "correlation_matrix_df.columns = initializer\n",
        "correlation_matrix_df.index = initializer\n",
        "display(correlation_matrix_df)\n",
        "print(\"Average correlation: \" + str(np.nanmean(correlation_matrix.flatten())))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zero</th>\n",
              "      <th>Ones</th>\n",
              "      <th>Random Normal</th>\n",
              "      <th>Random Uniform</th>\n",
              "      <th>Identity</th>\n",
              "      <th>Orthogonal</th>\n",
              "      <th>Glorot Normal</th>\n",
              "      <th>Glorot Uniform</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Zero</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.656012</td>\n",
              "      <td>0.695999</td>\n",
              "      <td>0.628877</td>\n",
              "      <td>0.670397</td>\n",
              "      <td>0.662003</td>\n",
              "      <td>0.587106</td>\n",
              "      <td>0.606757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ones</th>\n",
              "      <td>0.656012</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.595566</td>\n",
              "      <td>0.595041</td>\n",
              "      <td>0.663734</td>\n",
              "      <td>0.665866</td>\n",
              "      <td>0.583943</td>\n",
              "      <td>0.611582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Normal</th>\n",
              "      <td>0.695999</td>\n",
              "      <td>0.595566</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.598614</td>\n",
              "      <td>0.628632</td>\n",
              "      <td>0.633554</td>\n",
              "      <td>0.580264</td>\n",
              "      <td>0.593106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Uniform</th>\n",
              "      <td>0.628877</td>\n",
              "      <td>0.595041</td>\n",
              "      <td>0.598614</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.663618</td>\n",
              "      <td>0.631046</td>\n",
              "      <td>0.586767</td>\n",
              "      <td>0.614461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Identity</th>\n",
              "      <td>0.670397</td>\n",
              "      <td>0.663734</td>\n",
              "      <td>0.628632</td>\n",
              "      <td>0.663618</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.674300</td>\n",
              "      <td>0.679811</td>\n",
              "      <td>0.638812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Orthogonal</th>\n",
              "      <td>0.662003</td>\n",
              "      <td>0.665866</td>\n",
              "      <td>0.633554</td>\n",
              "      <td>0.631046</td>\n",
              "      <td>0.674300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.595122</td>\n",
              "      <td>0.638787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Normal</th>\n",
              "      <td>0.587106</td>\n",
              "      <td>0.583943</td>\n",
              "      <td>0.580264</td>\n",
              "      <td>0.586767</td>\n",
              "      <td>0.679811</td>\n",
              "      <td>0.595122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.611994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Glorot Uniform</th>\n",
              "      <td>0.606757</td>\n",
              "      <td>0.611582</td>\n",
              "      <td>0.593106</td>\n",
              "      <td>0.614461</td>\n",
              "      <td>0.638812</td>\n",
              "      <td>0.638787</td>\n",
              "      <td>0.611994</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Zero      Ones  ...  Glorot Normal  Glorot Uniform\n",
              "Zero                 NaN  0.656012  ...       0.587106        0.606757\n",
              "Ones            0.656012       NaN  ...       0.583943        0.611582\n",
              "Random Normal   0.695999  0.595566  ...       0.580264        0.593106\n",
              "Random Uniform  0.628877  0.595041  ...       0.586767        0.614461\n",
              "Identity        0.670397  0.663734  ...       0.679811        0.638812\n",
              "Orthogonal      0.662003  0.665866  ...       0.595122        0.638787\n",
              "Glorot Normal   0.587106  0.583943  ...            NaN        0.611994\n",
              "Glorot Uniform  0.606757  0.611582  ...       0.611994             NaN\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average correlation: 0.6282775540596097\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}