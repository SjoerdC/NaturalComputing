{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10,mnist\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNISTmodel(imsize, num_classes, num_channels):\n",
    "    inputs = Input((imsize,imsize,num_channels))\n",
    "    x = Conv2D(filters=16, kernel_size=(3,3), activation='relu',strides = 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    x = Conv2D(filters=16, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
    "    x = Conv2D(filters=10, kernel_size=(1,1),strides=(1,1), padding='valid')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FashionMNISTmodel(imsize, num_classes, num_channels):\n",
    "    inputs = Input((imsize,imsize,num_channels))\n",
    "    x = Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', strides = 2)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2), strides=(2,2), padding = \"same\")(x)\n",
    "    x = Conv2D(filters=32, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
    "    x = Conv2D(filters = 10, kernel_size = (1,1),strides = (1,1), padding = 'valid')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFARmodel(imsize, num_classes, num_channels):\n",
    "    inputs = Input((imsize,imsize,num_channels))\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), activation='relu')(inputs)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=2)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', strides=2, padding='same')(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3,3), activation='relu', strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2D(filters=128, kernel_size=(1,1), activation='relu', padding='valid')(x)\n",
    "    x = Conv2D(filters=10, kernel_size=(1,1),strides=(1,1), padding='valid')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTmodel(IMAGE_SIZE,NUM_CLASSES,NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate = 1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_for_grayscale(x_train, x_test, imsize):\n",
    "    x_train = x_train.reshape(x_train.shape[0], imsize, imsize, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], imsize, imsize, 1)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CHANNELS == 1:\n",
    "    x_train, x_test = reshape_for_grayscale(x_train, x_test, IMAGE_SIZE)\n",
    "    print(\"Reshaped data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit( x_train,y_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     validation_data=(x_test,y_test),\n",
    "                     shuffle=True,callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_loss(history):\n",
    "    epoch = len(history.history['loss'])\n",
    "    epoch = range(1,epoch+1)\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_loss = history.history['loss']\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(epoch,val_loss,'--o', label = 'validation loss')\n",
    "    plt.plot(epoch, train_loss, '--o', label = 'training loss')\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(\"model'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
